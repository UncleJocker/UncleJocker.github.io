<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>自动机器学习代码详解</title>
    <url>/posts/4668cbbb.html</url>
    <content><![CDATA[<p>毕业论文基于auto-sklearn做了一些自动机器学习模型的应用，模型的原理可以点击<span class="exturl" data-url="aHR0cDovL2NvZGV3aXRoemhhbmd5aS5jb20vMjAxOC8wNy8yNi9BdXRvTUwv">这里<i class="fa fa-external-link-alt"></i></span>，我这儿讲一下我的代码怎么用，相当于是一个详细版的注释。</p>
<p>代码地址见<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xpZmVvZHlzc2V5L0FNRg==">https://github.com/lifeodyssey/AMF<i class="fa fa-external-link-alt"></i></span>。</p>
<a id="more"></a>
<p>进入到服务器amf目录下，输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> py3/bin/activate</span><br></pre></td></tr></table></figure>
<p>之后每一行的开头会显示(py3)字样，即代表进入虚拟环境。</p>
<p>之后直接输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python code.py</span><br></pre></td></tr></table></figure>
<p>即可开始运行程序。</p>
<p>以下是程序的详细说明，如果要修改代码，可以在服务器中直接使用vim进行修改，也可以在本地修改好之后用PSFTP推送到服务器上。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> autosklearn.regression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#前面这四行是引入相应的环境包</span></span><br><span class="line">rawdata=pd.read_excel(<span class="string">&#x27;rawdata.xlsx&#x27;</span>)<span class="comment">#单引号输入要读入文件的路径，文件的格式参考服务器中的rawdata.xlsx</span></span><br><span class="line">Y=rawdata[[<span class="string">&#x27;cpue&#x27;</span>]]<span class="comment">#单引号内写要预测的变量名</span></span><br><span class="line"></span><br><span class="line">Y=np.log10(Y+<span class="number">1</span>)<span class="comment">#这里采用了对数变换，可以去掉</span></span><br><span class="line">X=rawdata[[<span class="string">&#x27;lon&#x27;</span>,<span class="string">&#x27;lat&#x27;</span>,<span class="string">&#x27;sst&#x27;</span>,<span class="string">&#x27;chla&#x27;</span>,<span class="string">&#x27;doy&#x27;</span>]]<span class="comment">#单引号内输入要使用的变量名</span></span><br><span class="line">x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=<span class="number">0.3</span>,random_state=<span class="number">7</span>)<span class="comment">#test size代表了测试集在整个数据集中的占比，这里选取的是0.3即30%</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">automl = autosklearn.regression.AutoSklearnRegressor(</span><br><span class="line">    include_estimators=[<span class="string">&quot;random_forest&quot;</span>,<span class="string">&quot;decision_tree&quot;</span>,<span class="string">&quot;gradient_boosting&quot;</span>,<span class="string">&quot;xgradient_boosting&quot;</span>],</span><br><span class="line">    <span class="comment">#这里只放了几个我认为效果比较好的模型，模型种类参见https://github.com/automl/auto-sklearn/tree/master/autosklearn/pipeline/components/regression，如果想换用模型，把双引号内的名称更改即可；如果想删除或者添加，直接去掉相应的名称即可</span></span><br><span class="line">    exclude_estimators=<span class="literal">None</span>,</span><br><span class="line">    include_preprocessors=[<span class="string">&quot;no_preprocessing&quot;</span>, ],</span><br><span class="line">    exclude_preprocessors=<span class="literal">None</span>,</span><br><span class="line">    resampling_strategy=<span class="string">&#x27;cv&#x27;</span>,</span><br><span class="line">    resampling_strategy_arguments=&#123;<span class="string">&#x27;folds&#x27;</span>: <span class="number">10</span>&#125;,<span class="comment">#这里选了十折交叉验证来确定最优参数</span></span><br><span class="line">    )</span><br><span class="line">automl.fit(x_train, y_train.values.ravel())</span><br><span class="line"></span><br><span class="line">automl.sprint_statistics()</span><br><span class="line">automl.show_models()</span><br><span class="line">automl.refit(x_train, y_train.values.ravel())</span><br><span class="line"><span class="comment">#如果想输入新的自变量来做预测的话,将下面几句前面的#去除即可</span></span><br><span class="line"><span class="comment">#predata=pd.read_excel(&#x27;rawdata.xlsx&#x27;)#单引号内输入文件路径</span></span><br><span class="line"><span class="comment">#X=predata[[&#x27;lon&#x27;,&#x27;lat&#x27;,&#x27;sst&#x27;,&#x27;chla&#x27;,&#x27;doy&#x27;]]#单引号内输入选取的变量名</span></span><br><span class="line">y_pre = automl.predict(X)</span><br><span class="line">ypre=np.power(<span class="number">10</span>,ypre)<span class="number">-1</span><span class="comment">#变换回来</span></span><br><span class="line">ypre=pd.DataFrame(ypre)</span><br><span class="line">result=pd.concat([rawdata,ypre])<span class="comment">#如果输入新的自变量来做预测，将rawdata改为predata</span></span><br><span class="line">result.to_excel(<span class="string">&#x27;result.xlsx&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Automatic Machine Learning</tag>
        <tag>Fishery Forecasting</tag>
        <tag>Undergraduate Thesis</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.24-11.29</title>
    <url>/posts/d1210079.html</url>
    <content><![CDATA[<p>最近没有一点科研的状态</p>
<p>鸽了好多博客没写，文章没看</p>
<p>我好累 我好想放弃</p>
<p>我想 回家</p>
<p>好像那个被我找到的目标 又走远了</p>
<a id="more"></a>
<h1 id="phytoplankton-fluorescence-theory-current-literature-and-in-situ-measurement">Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement</h1>
<p>Book 'Real-time Coastal Observing Systems <em>for</em> Marine Ecosystem Dynamics <em>and</em> Harmful Algal Blooms', Chapter 7, 'Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement' edited by Marcel Baiin.</p>
<h1 id="fluorescence-component-in-the-reflectance-spectra-from-coastal-waters.-dependence-on-water-composition">Fluorescence component in the reflectance spectra from coastal waters. Dependence on water composition</h1>
<h1 id="fluorescence-component-in-the-reflectance-spectra-from-coastal-waters.-ii.-performance-of-retrieval-algorithms">Fluorescence component in the reflectance spectra from coastal waters. II. Performance of retrieval algorithms</h1>
<h1 id="impact-of-sub-pixel-variations-on-ocean-color-remote-sensing-products">Impact of sub-pixel variations on ocean color remote sensing products</h1>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Research Basis</tag>
        <tag>Ocean Color</tag>
        <tag>Ocean Optics</tag>
        <tag>Inherent Optical Properties</tag>
        <tag>Fluorescence</tag>
        <tag>Sub-pixel</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 9.28-10.4</title>
    <url>/posts/e4bb9d98.html</url>
    <content><![CDATA[<p>Annotated Bibliography 2020 9.28-10.4</p>
<p>I will try to read three or four papers every week and update my annotation.</p>
<p>Update 2020 9.30: At least two paper.</p>
<a id="more"></a>
<h1 id="downscaling-modis-images-with-area-to-point-regression-kriging">Downscaling MODIS images with area-to-point regression kriging</h1>
<p>Wang, Qunming, et al. "Downscaling MODIS images with area-to-point regression kriging." <em>Remote Sensing of Environment</em> 166 (2015): 191-204.</p>
<h2 id="method-description">Method description</h2>
<h3 id="problem-description">Problem description</h3>
<p><span class="math inline">\(Z_V^l(x_i)\)</span>: random variable of pixel V centered at xi (i =1,…,M,where M is the number of pixels) in coarse band l.</p>
<p><span class="math inline">\(Z_v^k(x_j)\)</span>: random variable of pixel v centered at xj (j =1,…,MF^2,where F is the spatial resolution (zoom) ratio between the coarse and fine bands) in fine band k</p>
<p>The notations v and Vdenote fine and coarse pixels, respectively.</p>
<p>Aim:predict <span class="math inline">\(Z_v^k(x)\)</span> for all fine pixels in all coarse bands.</p>
<p>Prediction: <span class="math display">\[
Z_v^l(x)=Z_{v1}^l(x)+Z_{v2}^l(x)
\]</span> <span class="math inline">\(Z_{v1}^l(x)\)</span>: regression</p>
<p><span class="math inline">\(Z_{v2}^l(x)\)</span> : ATPK</p>
<h3 id="regression">Regression</h3>
<p>For coarse band <span class="math inline">\(Z_V^l\)</span> , its corresponding fine band used as covariate is denoted as <span class="math inline">\(Z_v^{lk}\)</span></p>
<p>The regression prediction <span class="math inline">\(Z_{v1}^l(x)\)</span> is calculated as <span class="math display">\[
Z_{v1}^l(x)=a_lZ_v^{lk}(x)+b_l
\]</span> Key issue is to estimate <span class="math inline">\(a_l\)</span> and <span class="math inline">\(bl\)</span></p>
<p>The relationship in Eq. (2) is assumed to be uni- versal at different spatial resolutions, and the relationship built at coarse spatial resolutions can be applied at fine spatial resolution.</p>
<p>Based on this hypothesis, we get Eq.(3): <span class="math display">\[
Z_V^l(x)=a_lZ_V^{lk}x+b_l
\]</span> in which <span class="math inline">\(Z_V^{lk}\)</span> is the coarse image produced by upscaling the ancillary fine band <span class="math inline">\(Z_v^{lk}\)</span> to the same spatial resolution of the l-th coarse band, that is <span class="math display">\[
Z_V^{lk}=h_V^{l}(x)*Z_v^{lk}(x)=\int h_V^l(x-y)Z_v^{lk}(y)dy
\]</span> where <span class="math inline">\(h_V^l (y)\)</span> is the point spread function (PSF) for the l-th band and ∗ is the convolution operator</p>
<p>PSF:https://www.youtube.com/watch?v=Tkc_GOCjx7E</p>
<p>ordinary least squares (OLS) is applied for estimate <span class="math inline">\(a_l\)</span> and <span class="math inline">\(b_l\)</span></p>
<p>The ancillary information fromother data, such as elevation data and field measurement correlated to the observation, can also be favorably incorporated in regression modeling. Given T groups of covariates, <span class="math inline">\(Z_v^t(x)(t =1,…,T)\)</span>, the regression prediction <span class="math inline">\(Z_{v1} ^l (x)\)</span> in this more general case then becomes <span class="math display">\[
Z_{v1}^{l}(x)=\sum_{t=0}^Ta_{lt}Z_v^t(x),Z_{v}^{0}(x)=1\forall x
\]</span></p>
<h3 id="atpk">ATPK</h3>
<p>Residuals, denoted as <span class="math inline">\(Z_{V2}^l(x)\)</span>,from the regression process, that it, <span class="math display">\[
Z_{V2}^{l}(x)=Z_{V}^{l}-[a_l Z_V^{lk}(x)+b_l]
\]</span> The results ofregression cannot reproduce the spectral properties of the observed coarse data. Thus, regression alone is not sufficient for downscaling. The residuals at fine spatial resolution should be compen- sated for the regression prediction to honor the spectral properties. In the proposed ATPRK approach, based on the strong assumption <strong>that the residual is an intrinsically stationary process</strong>, ATPK acts as the second phase to downscale the residuals <span class="math inline">\(Z_{V2}^l (x)\)</span> to fine spatial resolution residuals <span class="math inline">\(Z_{v2} ^l (x)\)</span>.</p>
<p>Based on ATPK, the fine residual <span class="math inline">\(Z_{v2} ^l (x)\)</span> is a linear combination of N coarse residuals of band l <span class="math display">\[
Z_{v2}^{l}(x)=\sum_{i=1}^{N}\lambda_i Z_{V2}^l(x_i),s.t.\sum_{i=1}^N\lambda_i=1
\]</span> in which <span class="math inline">\(λ_i\)</span> is theweight for the <span class="math inline">\(i\)</span> th residual of the coarse pixel centered at <span class="math inline">\(x_i\)</span>.</p>
<p>The <span class="math inline">\(N\)</span> coarse residuals are from the <span class="math inline">\(N\)</span> coarse pixels surrounding the pixel center at <span class="math inline">\(x\)</span>,such as <span class="math inline">\(N\)</span>=5×5 window of coarse pixels.</p>
<p>As observed from Eq. (7), the ATPK part accounts for the spatial correlation between coarse pixels, which is not utilized in the regression part.</p>
<p>The objective of the ATPK part is to obtain the <span class="math inline">\(N\)</span> weights <span class="math inline">\({λ_1,…,λ_N}\)</span>. The weights are estimated by minimizing the prediction error variance. The corresponding kriging system is <span class="math display">\[
\begin{bmatrix}
C_{VV}^l(x_1,x_1) &amp; \cdots C_{VV}^l(x_1,x_N)&amp;1\\\\
\vdots&amp;\vdots&amp;\vdots \\\\
C_{VV}^l(x_N,x_1) &amp; \cdots C_{VV}^l(x_N,x_N)&amp;1\\\\
1 \cdots &amp;1 &amp; 0
\end{bmatrix}
\begin{bmatrix}
\lambda_1\\\\
\vdots\\\\
\lambda_N\\\\
\mu
\end{bmatrix}
=
\begin{bmatrix}
C_{vV}^l(x,x_1)\\\\
\vdots\\\\
C_{vV}^l(x,x_N)\\\\
1
\end{bmatrix}
\]</span> The term <span class="math inline">\(C_{VV} ^l (x_i, x_j)\)</span> is the coarse-to-coarse residual covariance between coarse pixels centered at <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> in band l, <span class="math inline">\(C_{vV}^ l (x, x_j)\)</span> is the fine-to-coarse residual covariance between fine and coarse pixels centered at <span class="math inline">\(x\)</span> and <span class="math inline">\(x_j\)</span>, respectively, and <span class="math inline">\(μ\)</span> is the Lagrange multiplier. The <span class="math inline">\(N\)</span> weights can be calculated according to Eq. (8). For this purpose, the two types of covariance in Eq. (8) need to be obtained in advance</p>
<p>Suppose <span class="math inline">\(s\)</span> is the Euclidean distance between centroids of any two pixels, and <span class="math inline">\(C_{vv} ^l (s)\)</span>is the fine-to-fine (called “punctual” in this paper, by assuming each fine pixel as a point) residual covariance between two fine pixels. The fine-to-coarse covariance $C_{vV}l (s) $and coarse-to-coarse covariance <span class="math inline">\(C_{VV}^ l (s)\)</span> are calculated by convoluting <span class="math inline">\(C_{vv}^ l (s)\)</span> with the PSF <span class="math inline">\(h_V ^l (s)\)</span>as follows <span class="math display">\[
C_{vV}^l(s)=C_{vv}^l(s)*h_V^l(s)
\]</span></p>
<p><span class="math display">\[
C_{VV}^l(s)=C_{VV}^l(s)*h_V^l(s)*h_V^l(-s)
\]</span></p>
<p>In Eq. (10), <span class="math inline">\(−s\)</span> means that the distance from point A within a pixel to point B within another pixel, denoted as <span class="math inline">\(−s\)</span>, is opposite to that from point B to point A (i.e., <span class="math inline">\(s\)</span>)</p>
<p>Note that the variable in the PSF should be a location, as indicated earlier in Eq. (4). However, s in Eqs. (9) and (10) is originally defined as a distance. Actually, in Eqs. (9) and (10), <span class="math inline">\(s\)</span> is defined for covariance <span class="math inline">\(C_{vv}^l\)</span>, which can be recognized as a 2-D image centered at {0,0}, with values in all directions and at multiple lag dis- tances. Thus, <span class="math inline">\(s\)</span> in Eqs. (9) and (10) is essentially a location in the image (e.g., <span class="math inline">\(s\)</span> = {1,1} means a point along the northeast direction with lag 1.414).</p>
<p>If we assume that the coarse pixel value is the average of the fine pixel values within it, then the PSF is <span class="math display">\[
h_V^l(x)=\begin{cases}\frac{1}{S_v},\quad if\quad x\in V(x)\\
0, \quad otherwise
\end{cases}
\]</span> where <span class="math inline">\(S_V\)</span> is the size of pixel <span class="math inline">\(V\)</span>,and <span class="math inline">\(V(x)\)</span> is the spatial support of pixel <span class="math inline">\(V\)</span> centered at <span class="math inline">\(x\)</span>. If the area of pixel <span class="math inline">\(v\)</span> is defined as 1, then <span class="math inline">\(S_V=F^2\)</span>.Given the PSF in Eq. (11), the computation of <span class="math inline">\(C_{vV}^l (x, x_j)\)</span>and <span class="math inline">\(C_{VV}^l(x_i, x_j)\)</span> are further simplified as <span class="math display">\[
C_{vV}^l(x,x_j)=\frac{1}{S_V}\int_\limits{u\in V(x_j)}C_{vv}^l(\boldsymbol{x}-\boldsymbol{u})d\boldsymbol{u}=\frac{1}{F^2}\sum_{m=1}^{F^2}C_{vv}^{l}(S_m)
\]</span></p>
<p><span class="math display">\[
C_{VV}^l(x_i,x_j)=\frac{1}{S_V}\int_\limits{u\in V(x_i)}C_{vV}^l(u,x_j)d\boldsymbol{u}\\\\
=\frac{1}{ {S_V}^2}\int_\limits{u\in V(x_i)}\int_\limits{u^\prime\in V(x_j)}C_{vv}^l(u-u^{\prime})d\boldsymbol{u}d\boldsymbol{u}^{\prime}\\\\
=\frac{1}{F^4}\sum_{m=1}^{F^2}\sum_{m=1}^{F^2}C_{vv}^l(s_{mm^\prime})
\]</span> In Eq. (12), <span class="math inline">\(s_m\)</span> is the distance between the centroid <span class="math inline">\(x\)</span> of fine pixel <span class="math inline">\(v\)</span> and the centroid of any fine pixel within the coarse pixel <span class="math inline">\(V\)</span> centered at <span class="math inline">\(x_j\)</span>,and <span class="math inline">\(s_{mm^\prime}\)</span>is the distance between the centroid of any fine pixel within the coarse pixel centered at <span class="math inline">\(x_i\)</span> and the centroid of any fine pixel within the coarse pixel centered at <span class="math inline">\(x_j\)</span>.</p>
<p>The critical problem of kriging weight estimation in ATPK becomes the estimation of punctual residual covariance <span class="math inline">\(C_{vv} ^l (s)\)</span>. It is derived by deconvolution (also termed deregularization in geostatistics) of the areal covariance, denoted as <span class="math inline">\(C_V ^l (s)\)</span>, of the known coarse residual image <span class="math inline">\(Z_{v2}^l\)</span>. Deconvolution aims to estimate the optimal punctual covariance, the regularized covariance of which approximates the known areal covariance.</p>
<p>Given a candidate pool of punctual covariances, each <span class="math inline">\(C_{vv}^l (s)\)</span> is convolved to the regularized areal covariance (denoted as <span class="math inline">\(C_V^{l\_R}(s)\)</span>). The optimal punctual covariance is determined as the one with the smallest difference between <span class="math inline">\(C_V^{l\_R}(s)\)</span> and CV l (s). The covariance, which is closely related to the semivariogram (their sum is a constant), can generally be characterized by three parameters, nugget, sill and range. The essence of punctual covariance estimation is the optimal parameter combination estimation. Note that in Eq. (8), the covariance matrix can be replaced by the semivariogram matrix and both give the same kriging weights. Therefore, the covariance modeling, including deconvolution and convolution, is essentially the semivariogram modeling</p>
<p>The candidate pool ofpunctual covariances is generated by referring to the known areal covariance <span class="math inline">\(C_V ^l (s)\)</span>. Specifically, for each of the three parameters of$ C_{vv}^ l (s)$, two multipliers are defined empirically to generate an interval for selecting the corresponding optimal parameter of <span class="math inline">\(C_{vv}^l (s)\)</span>. In this paper, the interval for punctual sill selection is set to between 1 and 3 times that of the areal sill, while the interval for punctual range selection is set to between 0.5 and 2.5 times that of the areal range. The step is set to 0.1. Regarding the punctual nugget, 21 × 21 = 441 steps of convolution need to be implemented to test each given nugget value. The computational cost increases linearly with the number of nugget candidates. To ease the computational burden, the assumption made in Atkinson et al. (2008) and Pardo-Igúzquiza et al. (2006, 2011) is adopted in this paper: there is zero nugget effect in the punctual covariance. As a result, the optimal punctual parameter combination is selected from the candidate pool containing 441 groups of parameters.</p>
<h3 id="atprk">ATPRK</h3>
<p>After both regression and ATPK are completed , their outputs (i.e., <span class="math inline">\(Z_{v1}^ l (x)\)</span>and <span class="math inline">\(Z_{v2}^ l (x))\)</span> are combined to produce the final downscaled result, as indicated in Eq. (1).The whole flowchart of the proposed ATPRK approach for downscaling MODIS imagery is shown in Fig. 1. For each coarse band l,ATPRK is performed in turn, and the final result is a fine spatial resolution seven-band MODIS image. The flowchart in Fig. 1 is easy to implement and can be revised by adding other available covariates, as illustrated in Eq. (5). <img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00020930132948176.png" alt="image-00020930132948176"></p>
<p>An important advantage of ATPK is the coherence characteristic (Kyriakidis, 2004; Kyriakidis &amp; Yoo, 2005) <span class="math display">\[
\int h_V^l(x-y)Z_{v2}^l(y)dy=Z_{V2}^l(x)
\]</span> This has been proved theoretically and demonstrated practically.</p>
<p>By compensating the downscaled residuals for regression prediction, we have that <span class="math display">\[
\int h_V^l(x-y)Z_v^l(y)dy=Z_V^l(x)
\]</span></p>
<h4 id="appendix-preserve-of-spectral-properties">Appendix: Preserve of spectral properties</h4>
<p>Without loss of generality, we consider the case of <span class="math inline">\(T\)</span> groups of ancillary variables, that is, the case in Eq. (5). According to Eq. (4), when building the regression model, each group of ancillary data <span class="math inline">\(Z_v^t(x)\)</span> is upscaled to <span class="math inline">\(Z_V ^t(x)\)</span>as follows <span class="math display">\[
Z_V^t(x)=\int h_V^l(x-y)Z_v^t(y)dy
\]</span> In APTK prediction <span class="math display">\[
\int h_V^l(x-y)Z_{v2}^l(y)dy=Z_{V2}^l(x)=Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)
\]</span> Therefore, we have <span class="math display">\[
\int h_V^l(x-y)Z_v^l(y)dy\\\\
=\int h_V^l(x-y)[Z_{v1}^l(y)+Z_{v2}^{l}(y)]dy\\\\
=\int h_V^l(x-y)Z_{v1}^l(y)dy+\int h_V^l(x-y)Z_{v2}^l(y)dy\\\\
=\int h_V^l(x-y)Z_{v1}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\int h_V^l(x-y)\sum _{t=0}^{T}a_{lt}Z_{v}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\sum_{t=0}^{T}a_{lt}\int h_V^l(x-y)Z_{v}^l(y)dy+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=\sum_{t=0}^{T}a_{lt}Z_V^t(x)+Z_V^l(x)-\sum_{t=0}^{T}a_{lt}Z_V^t(x)\\\\
=Z_V^l(x)
\]</span> This means that when the downscaled result <span class="math inline">\(Z_v^ l (x)\)</span> produced by the ATPRK approach is upscaled to the original coarse spatial resolution, it is identical to the original observed coarse image$ Z_V^l (x)$. Thus, the spectral properties of the coarse data are precisely preserved by ATPRK. This is a significant advantage of the new method ATPRK in image fusion.</p>
<h2 id="summary-and-annotation">Summary and Annotation</h2>
<p>To be honest, I didn't really understand it in detail, especially the deduction part. But fortunately, the author provided the source code in Matlab(https://github.com/qunmingwang), I can try to rewrite in the python and try to understand it more.</p>
<p>It might be the best method that could preserve the spectral properties(2020.9.30). Of course I need to do more literature review.</p>
<p>Another strength of this paper is that I now clearly undetstand what do I need to do for writing such kind of articles, including methods comparison(all most all the state-of-art and frequently used method), metrics(the most metrics I have seen) and classification(the essens of spectral resolution ).</p>
<p>In summary, ATPRK includes two parts: regression and ATPK. The former uses fine spatial resolution information from the fine band and the latter down- scales the residuals from regression that are then added back to the regression prediction.</p>
<h2 id="note-for-atprk-matlab-code">Note for ATPRK matlab code</h2>
<p>code repository:https://github.com/qunmingwang/Code-for-S2-fusion</p>
<p>This code is for Q. Wang, W. Shi, Z. Li, P. M. Atkinson. Fusion of Sentinel-2 images. Remote Sensing of Environment, 2016, 187: 241�C252.</p>
<p>This paper aims to downscale 20m Sentinel-2 band to 10m. And it compared the result with eight CS and MRA-based approaches.</p>
<p>This code chnage PSF to Gaussian filter. But it is proofed that the coherence characteristics of ATPK and ATPRK is not affected by the specific form of PSF.</p>
<h3 id="band-selection">Band Selection</h3>
<p>This paper extended the ATPRK using the synthesized and selected band schemes.</p>
<p>For accommodation of fine spatial reso- lution information from multiple fine bands, two schemes were proposed in Selva et al. (2015), that is, the synthesized band scheme and the selected band scheme.</p>
<p>The selected band scheme selects a fine band from the fine band set for each coarse band, which is determined as the one with the largest correlation with the visited coarse band.</p>
<p>The synthesized band scheme synthesizes a single fine band from the fine band set (i.e., fine multispectral image), such as averaging all fine multispectral bands (Selva et al. 2015).</p>
<p>However, the synthesized band scheme based on the simple averaging process fails to consider the relation between the visited coarse band and the four fine bands. In this paper, to fully account for the information in the four finebands, the synthesized band for each coarse band is determined adap- tively as a linear combination ofthe four fine bands.</p>
<p>So this is the why there exist the 'Selected band scheme.m' and 'Synthesized band scheme.m' as the first two file.</p>
<p>After band selection, as the selected band scheme only use panchromatic band and synthesized use multispectral bands, so the function are called 'ATPRK_PANsharpen' and 'ATPRK_MSsharpen', respectively.</p>
<h1 id="deriving-consistent-ocean-biological-and-biogeochemical-products-from-multiple-satellite-ocean-color-sensors">Deriving consistent ocean biological and biogeochemical products from multiple satellite ocean color sensors</h1>
<p>Menghua Wang, Lide Jiang, SeungHyun Son, Xiaoming Liu, and Kenneth J. Voss, "Deriving consistent ocean biological and biogeochemical products from multiple satellite ocean color sensors," Opt. Express <strong>28</strong>, 2661-2682 (2020)</p>
<p>This paper proposed a method that could derive consistent product from different new.</p>
<p>I need to consider sensor response function.</p>
<p>Consistency evaluation by scatter plot and density plot</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Remote Sensing</tag>
        <tag>Data Fusion</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第一周笔记 Machine Learning Foundation Week 1 Note in Cousera</title>
    <url>/posts/bc80cb40.html</url>
    <content><![CDATA[<p>An introduction for Machine learning</p>
<a id="more"></a>
<h1 id="what-is-machine-learning">What is machine learning</h1>
<h2 id="what-is-learning">What is learning</h2>
<p>learning: acquiring skill with experience accumulated from observations</p>
<p>machine learning: acquiring skill with experience accumulated/computed from data</p>
<p>skill: improve some performance measure(e.g.prediction accuracy)</p>
<h2 id="why-use-machine-learning">Why use machine learning</h2>
<ul>
<li>'define' trees and hand-program: difficult</li>
<li>learn from data(observations) and recognize: a 3-year-old can do so</li>
<li>'ML-based tree recognition system' can be easier to build than hand-programmed system</li>
</ul>
<p>ML: an alternative route to build complicated systems</p>
<h2 id="some-use-scenarios">Some Use Scenarios</h2>
<ul>
<li><p>when human cannot program the system manually</p>
<p>——navigation on Mars</p></li>
<li><p>when human cannot 'define the solution' easily</p>
<p>——speech/visual recognition</p></li>
<li><p>when needing rapid decisions that human cannot do</p>
<p>——high-frequency trading</p></li>
<li><p>when needing to be user-oriented in massive sacle</p>
<p>——consumer-targeted marketing</p></li>
</ul>
<h2 id="key-essence-of-ml">Key Essence of ML</h2>
<p>1. exists some 'underlying pattern' to be learned</p>
<p>——so 'performance measure' can be improved</p>
<p>2. but no programmable(easy) definition</p>
<p>——so 'ML' is needed</p>
<p>3. somehow there is data about the pattern</p>
<p>——so ML has some 'inputs' to learn from</p>
<p># Application of ML</p>
<h1 id="components-of-learning">Components of Learning:</h1>
<h2 id="basic-notations">Basic Notations</h2>
<ul>
<li><p>input: x $ $ <em>X</em></p></li>
<li><p>output: y $ $ <em>Y</em></p></li>
<li><p>unknow pattern to be learned $ $ target function: <em>f</em>: <em>X</em> $ $ <em>Y</em></p></li>
<li><p>data <span class="math inline">\(\Leftrightarrow\)</span> training examples: <span class="math inline">\(D =\{(x_1,y_1),(x_2.y_2),...,(x_n,y_n)\}\)</span></p></li>
<li><p>hypothesis <span class="math inline">\(\Leftrightarrow\)</span> skill with hopefully good performance :</p>
<p>$ g:X Y$</p></li>
</ul>
<h1 id="machine-learning-and-other-fields">Machine Learning and Other Fields</h1>
<h2 id="machine-learning-and-data-mining">Machine Learning and Data Mining</h2>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Data Mining</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>use <strong>huge</strong> data to find <strong>property that</strong> is interesting</td>
</tr>
</tbody>
</table>
<ul>
<li><p>if 'interesting property' same as 'hypothesis' that approximate target——ML=DM</p></li>
<li><p>if 'interesting property' related to 'hypothesis ' that approximate target——DM can help ML,and vice versa(often,but not always)</p></li>
<li><p>traditional DM also focuses on efficient computation in large database</p></li>
</ul>
<h2 id="machine-learning-and-artificial-intelligence">Machine Learning and Artificial Intelligence</h2>
<table>
<colgroup>
<col style="width: 53%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Artificial Intelligence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>compute <strong>something that shows intelligent behavior</strong></td>
</tr>
</tbody>
</table>
<ul>
<li>$ gf$ is something that shows intelligent behavior——ML can realize AI,among other routes</li>
<li>e.g. chess playing
<ul>
<li>traditional AI: game tree</li>
<li>ML for AI :learning from board data</li>
</ul></li>
</ul>
<p><strong>ML is one possible route to realize AI</strong></p>
<h2 id="machine-learning-and-statistics">Machine Learning and Statistics</h2>
<table>
<colgroup>
<col style="width: 52%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="header">
<th>Machine Learning</th>
<th>Statistics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>use data to compute hypothesis <em>g</em> that approximates target <em>f</em></td>
<td>use data to <strong>make inference about an unknown process</strong></td>
</tr>
</tbody>
</table>
<ul>
<li><em>g</em> is an inference outcome,<em>f</em> is something unknown——statistics <strong>can be used to achieve ML</strong></li>
<li>traditional statistics also focus on <strong>provable results with math assumptions</strong>,and care less about computation</li>
</ul>
<p><strong>statistics:many useful tools for ML</strong></p>
<h1 id="summary">Summary</h1>
<p>1. What is ML</p>
<p>-use data to approximate target</p>
<p>2. Application of ML</p>
<p>-alomost everywhere</p>
<p>3. Components of ML</p>
<p>-$ A$ takes <span class="math inline">\(D\)</span> and <span class="math inline">\(H\)</span> to get <span class="math inline">\(g\)</span></p>
<p>4. ML and other fields</p>
<p>-related to DM,AI and Stats</p>
<p># Appendix</p>
<p>預備知識</p>
<p>作業零 (機率統計、線性代數、微分之基本知識)</p>
<p>參考書籍</p>
<p>Learning from Data: A Short Course , Abu-Mostafa, Magdon-Ismail, Lin, 2013.</p>
<p>經典文獻</p>
<p>F. Rosenblatt. The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65(6):386-408, 1958. (第二講：Perceptron 的出處)</p>
<p>W. Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58(301):13–30, 1963. (第四講：Hoeffding's Inequality)</p>
<p>Y. S. Abu-Mostafa, X. Song , A. Nicholson, M. Magdon-ismail. The bin model, 1995. (第四講：bin model 的出處)</p>
<p>V. Vapnik. The nature of statistical learning theory, 2nd edition, 2000. (第五到八講：VC dimension 與 VC bound 的完整數學推導及延伸)</p>
<p>Y. S. Abu-Mostafa. The Vapnik-Chervonenkis dimension: information versus complexity in learning. Neural Computation, 1(3):312-317, 1989. (第七講：VC Dimension 的概念與重要性)</p>
<p>參考文獻</p>
<p>A. Sadilek, S. Brennan, H. Kautz, and V. Silenzio. nEmesis: Which restaurants should you avoid today? First AAAI Conference on Human Computation and Crowdsourcing, 2013. (第一講：ML 在「食」的應用)</p>
<p>Y. S. Abu-Mostafa. Machines that think for themselves. Scientific American, 289(7):78-81, 2012. (第一講：ML 在「衣」的應用)</p>
<p>A. Tsanas, A. Xifara. Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools. Energy and Buildings, 49: 560-567, 2012. (第一講：ML 在「住」的應用)</p>
<p>J. Stallkamp, M. Schlipsing, J. Salmen, C. Igel. Introduction to the special issue on machine learning for traffic sign recognition. IEEE Transactions on Intelligent Transportation Systems 13(4): 1481-1483, 2012. (第一講：ML 在「行」的應用)</p>
<p>R. Bell, J. Bennett, Y. Koren, and C. Volinsky. The million dollar programming prize. IEEE Spectrum, 46(5):29-33, 2009. (第一講：Netflix 大賽)</p>
<p>S. I. Gallant. Perceptron-based learning algorithms. IEEE Transactions on Neural Networks, 1(2):179-191, 1990. (第二講：pocket 的出處，注意到實際的 pocket 演算法比我們介紹的要複雜)</p>
<p>R. Xu, D. Wunsch II. Survey of clustering algorithms. IEEE Transactions on Neural Networks 16(3), 645-678, 2005. (第三講：Clustering)</p>
<p>X. Zhu. Semi-supervised learning literature survey. University of Wisconsin Madison, 2008. (第三講：Semi-supervised)</p>
<p>Z. Ghahramani. Unsupervised learning. In Advanced Lectures in Machine Learning (MLSS ’03), pages 72–112, 2004. (第三講：Unsupervised)</p>
<p>L. Kaelbling, M. Littman, A. Moore. reinforcement learning: a survey. Journal of Artificial Intelligence Research, 4: 237-285. (第三講：Reinforcement)</p>
<p>A. Blum. On-Line algorithms in machine learning. Carnegie Mellon University,1998. (第三講：Online)</p>
<p>B. Settles. Active learning literature survey. University of Wisconsin Madison, 2010. (第三講：Active)</p>
<p>D. Wolpert. The lack of a priori distinctions between learning algorithms. Neural Computation, 8(7): 1341-1390. (第四講：No free lunch 的正式版)</p>
<p>T. M. Cover. Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition. IEEE Transactions on Electronic Computers, 14(3):326–334, 1965. (第五到六講：Growth Function)</p>
<p>B. Zadrozny, J. Langford, N. Abe. Cost sensitive learning by cost-proportionate example weighting. IEEE International Conference on Data Mining, 2003. (第八講：Weighted Classification)</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第三周笔记 Machine Learning Foundation Week 3 Note in Cousera</title>
    <url>/posts/4df973c2.html</url>
    <content><![CDATA[<p><strong>Types of Learning</strong></p>
<a id="more"></a>
<h1 id="learning-with-different-output-space">Learning with Different Output Space</h1>
<h2 id="credit-approval-problem-revisited">Credit Approval Problem Revisited</h2>
<h2 id="more-binary-classification-problems">More Binary Classification Problems</h2>
<h2 id="multiclass-classification-coin-recognition-problem">Multiclass Classification: Coin Recognition Problem</h2>
<h2 id="regression-patient-recovery-prediction-problem">Regression: Patient Recovery Prediction Problem</h2>
<h2 id="structured-learning-sequence-tagging-problem">Structured Learning: Sequence Tagging Problem</h2>
<h1 id="learning-with-different-data-label">Learning With Different Data Label</h1>
<h2 id="supervised-coin-recognition-revisited">Supervised: Coin Recognition Revisited</h2>
<p>##　Unsupervised: Coin Recognition without <span class="math inline">\(y_n\)</span></p>
<p>unsupervised multiclass classification <span class="math inline">\(\Leftrightarrow\)</span>‘Clustering’:a challenging but useful problem</p>
<h2 id="unsupervised-learning-without-y_n">Unsupervised: Learning without <span class="math inline">\(y_n\)</span></h2>
<ul>
<li>Clustering</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRGVuc2l0eV9lc3RpbWF0aW9u">Density estimation<i class="fa fa-external-link-alt"></i></span></li>
<li>Outlier Detection</li>
</ul>
<h2 id="semi-supervisedcoin-recognition-with-some-y_n">Semi-supervised:Coin Recognition with Some <span class="math inline">\(y_n\)</span></h2>
<p>avoid expensive labeling</p>
<h2 id="reinforcement-learning">Reinforcement Learning</h2>
<h1 id="learning-with-different-protocol">Learning with Different Protocol</h1>
<h2 id="batch-learning">Batch Learning</h2>
<p>a very common protocol</p>
<h2 id="online-spam-filter-that-improves">Online: Spam Filter that ‘improves’</h2>
<h2 id="active-learning-learning-by-asking">Active Learning: Learning by ‘Asking’</h2>
<h1 id="learning-with-different-input-space">Learning with Different Input Space</h1>
<h2 id="concrete-features">Concrete Features</h2>
<p>human intelligence</p>
<h2 id="raw-features">Raw Features</h2>
<p>need human or machines to convert to concrete ones(feature engineering)</p>
<h2 id="abstract-features">Abstract Features</h2>
<p>again need feature conversion/extraction/construction</p>
<h1 id="summary">Summary</h1>
<ul>
<li>Learning with Different Output Space:classification,regression,structured</li>
<li>Learning with Different Data Label<span class="math inline">\(y_n\)</span>:supervised,un/semi-supervised,reinforecement</li>
<li>Learning with Different Protocol:batch,online,active</li>
<li>Learning with Different Input Space:concrete,raw,abstract</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第五周笔记-Machine-Learning-Foundation-Week-5-Note-in-Cousera</title>
    <url>/posts/fbd0b1b0.html</url>
    <content><![CDATA[<p><strong>Traning versus Testing</strong></p>
<p>Actually,I didn’t fully understand this part of course.However I don’t focus on the theory but application.</p>
<p>I will update this note if possible.</p>
<a id="more"></a>
<h1 id="recap-and-preview">Recap and Preview</h1>
<h2 id="recap-the-statistical-learning-flow">Recap: The ‘Statistical’ Learning Flow</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554528606498.png"></p>
<h2 id="two-central-questions">Two Central Questions</h2>
<p>1. can we make sure that <span class="math inline">\(E_{out}(g)\)</span> is close enough to <span class="math inline">\(E_{in}(g)\)</span>?</p>
<p>2. can we make <span class="math inline">\(E_{in}(g)\)</span> small enough?</p>
<p><span class="math inline">\(\Rightarrow\)</span> What role does <span class="math inline">\(\underbrace{M}\\{|\mathscr{H}|}\)</span> play for the two questions?</p>
<p>##　Trade-off on *M</p>
<table>
<colgroup>
<col style="width: 50%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="header">
<th>small M</th>
<th>large M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Yes <span class="math inline">\(\mathbb{P}[BAD]\leq2\cdot M\cdot exp(...)\)</span></td>
<td>1. No!<span class="math inline">\(\mathbb{P}[BAD]\leq2\cdot M\cdot exp(...)\)</span></td>
</tr>
<tr class="even">
<td>2. <span class="math inline">\(\color{Maroon}No!\)</span>,two few choices</td>
<td>2. Yes!many choices</td>
</tr>
</tbody>
</table>
<p>using the right M is important</p>
<h2 id="preview">Preview</h2>
<ul>
<li>Know: <span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot M\cdot exp(-2\epsilon^2N)\)</span></li>
<li>To do
<ul>
<li>establish a finite quantity that replaces M<span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot m_{\mathscr{H}}\cdot exp(-2\epsilon^2N)\)</span></li>
<li>justify the feasibility of learning for infinite M</li>
<li>study $m_{} <span class="math inline">\(to understand its trade-off for ‘right’\)</span>$,just like M</li>
</ul></li>
</ul>
<h1 id="effective-number-of-lines">Effective Number of Lines</h1>
<h2 id="where-did-m-come-from">Where Did <em>M</em> Come From</h2>
<p>The BAD event ：uniform bound fail<span class="math inline">\(\rightarrow\)</span> M<span class="math inline">\(\approx\infty\)</span></p>
<h2 id="where-did-uniform-bound-fail">Where Did Uniform Bound Fail</h2>
<p>overlapping for similar hypotheses</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509150052.png"></p>
<p>union bound over-estimating</p>
<p><strong>To acoount for overlap,can we group similar hypotheses by kind?</strong></p>
<h2 id="how-many-lines-are-there">How Many Lines Are There?</h2>
<p>In 2D,we can get smaller than <span class="math inline">\(2^N\)</span>lines</p>
<h2 id="effective-number-of-lines-1">Effective Number of Lines</h2>
<p>maximun kind of lines with respect to N inputs <span class="math inline">\(x_1\)</span>,<span class="math inline">\(x_2\)</span>,.....,<span class="math inline">\(x_N\)</span></p>
<p><span class="math inline">\(\iff\)</span>==effctive number of lines==</p>
<p>In 2D,the effective number of lines</p>
<ul>
<li><p>must be <span class="math inline">\(\leq 2^N\)</span></p></li>
<li><p>finite ‘grouping’ of infinitely-many lines <span class="math inline">\(\in H\)</span></p></li>
<li><p>wish:</p>
<p><span class="math inline">\(\mathbb{P}[|E_{in}(g)-E_{out}(g)|&gt;\epsilon]\leq 2 \cdot effctive(N)\cdot exp(-2\epsilon^2N)\)</span></p></li>
</ul>
<p>If</p>
<ol type="1">
<li><p>effective(N) can replace M and</p></li>
<li><p>effective(N) <span class="math inline">\(\ll 2^N\)</span></p>
<p>==learning possible with infinitie lines==</p></li>
</ol>
<h1 id="effective-number-of-hypotheses">Effective Number of Hypotheses</h1>
<h2 id="dichotomiesmini-hypotheses">Dichotomies:Mini-hypotheses</h2>
<h1 id="break-points">Break Points</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第四周笔记-Machine-Learning-Foundation-Week-4-Note-in-Cousera</title>
    <url>/posts/c7f63b06.html</url>
    <content><![CDATA[<p><strong>Feasibility of Learning</strong></p>
<a id="more"></a>
<h1 id="learning-is-impossible">Learning is Impossible?</h1>
<h1 id="probability-to-the-rescue">Probability to the Rescue</h1>
<h2 id="inferring-something-unknow">Inferring Something Unknow</h2>
<p>in sample<span class="math inline">\(\rightarrow\)</span>out sample</p>
<h2 id="possible-versus-probable">Possible versus Probable</h2>
<h2 id="hoeffdings-inequality">Hoeffding’s Inequality</h2>
<p>In big sample(<em>N</em> large),<span class="math inline">\(\boldsymbol{\upsilon}\)</span> is probably close to <span class="math inline">\(\boldsymbol{u}\)</span> (within <span class="math inline">\(\boldsymbol{\epsilon}\)</span>) <span class="math display">\[
\mathbb{P}[|v-u|&gt;\boldsymbol{\epsilon}]\leq2exp(-2\boldsymbol{\epsilon}^2N)
\]</span> called Hoeffding’s Inequality, for marbles,coin,polling</p>
<p>the statement <span class="math inline">\(v=u\)</span> is <strong>probably approximately correct</strong>(PAC)</p>
<ul>
<li><p>valid for all N and <span class="math inline">\(\boldsymbol{\epsilon}\)</span></p></li>
<li><p>does not depend on <span class="math inline">\(u\)</span>,no need to know<span class="math inline">\(u\)</span></p></li>
<li><p>larger sample size <em>N</em> or looser gap <span class="math inline">\(\boldsymbol{\epsilon} \rightarrow\)</span>higher probability for <span class="math inline">\(v=u\)</span></p>
<p>if large N,can probably infer unknown <span class="math inline">\(u\)</span> by know <span class="math inline">\(v\)</span></p></li>
</ul>
<h1 id="connection-to-learning">Connection to Learning</h1>
<h2 id="added-components">Added Components</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/微信截图_20190404101452.png"></p>
<p>for any fixed <em>h</em>, can probably infer unkown <span class="math inline">\(E_out(h)=\underset{X\approx P}{\varepsilon}[h(x)\ne f(x)]\)</span>by known$ E_in(h)=^N_{n=1}[h(x)f(x)]$</p>
<h2 id="the-formal-guarantee">The Formal Guarantee</h2>
<p>if <span class="math inline">\(E_{in}(h)\approx E_{out}(h)\)</span> and$E_{in}(h)smallE_{out}(h)samllhf $with respect to P</p>
<h2 id="verification-of-one-h">Verification of One h</h2>
<p>if <span class="math inline">\(E_{in}(h)\)</span> small for the fixed h and A pick the h as g<span class="math inline">\(\rightarrow\)</span> g=f PAC</p>
<p>if A force to pick THE h as g<span class="math inline">\(\rightarrow E_{in}(h)\)</span> almost always not small<span class="math inline">\(\rightarrow g\ne f\)</span> PAC</p>
<p>real learning:</p>
<p>A shall make choices<span class="math inline">\(\in \H\)</span> (like PLA) rather than being forced to pick one h.</p>
<h2 id="the-verification-flow">The ‘Verification’ Flow</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554345523532.png"></p>
<h1 id="connection-to-real-learning">Connection to Real Learning</h1>
<h2 id="bad-sample-and-bad-data">BAD Sample and BAD Data</h2>
<p>BAD Sample:<span class="math inline">\(E_{out}=\frac{1}{2}\)</span>,but getting all heads(<span class="math inline">\(E_{in}=0\)</span>)</p>
<p>BAD Data for One h:<span class="math inline">\(E_{out}(h)\)</span> and <span class="math inline">\(E_{in}h\)</span> far away</p>
<h2 id="bad-data-for-many-h">BAD data for Many h</h2>
<p>BAD data for many h <span class="math inline">\(\Leftrightarrow\)</span> no freedom of choice by A <span class="math inline">\(\Leftrightarrow\)</span> there exists some h such that <span class="math inline">\(E_{out}(h)\)</span> and <span class="math inline">\(E_{in}(h)\)</span> far away</p>
<h2 id="bound-of-bad-data">Bound of BAD Data</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554349806026.png"></p>
<h2 id="the-statistical-learning-flow">The Statistical Learning Flow</h2>
<p>if <span class="math inline">\(|\mathbb{H}|\)</span>= M finite, N large enough,for whatever g picked by A,<span class="math inline">\(E_{out}(g)\approx E_{in}(g)\)</span></p>
<p>if A finds one g with <span class="math inline">\(E_{in}(g)\approx 0\)</span>,PAC guarantee for<span class="math inline">\(E_{out}(g)\Rightarrow\)</span>learning possible</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1554350153964.png"></p>
<p>M=<span class="math inline">\(\infty\)</span>? - see you in the next lectures~</p>
<h1 id="吐槽">吐槽</h1>
<p>这个作业题是真的难啊，花了一个半小时才堪堪通过，尤其是最后几个写PLA和pocket算法的</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>Data fusion series note 1</title>
    <url>/posts/bd7e58b0.html</url>
    <content><![CDATA[<p>There are five main data fusion approaches according to 'Spatio-temporal fusion for remote sensing data: an overview and new benchmark'. Here I will read the STARFM.</p>
<a id="more"></a>
<h1 id="weight-function-based-methods-starfm">Weight function-based methods: STARFM</h1>
<p>The spatial and temporal adaptive reflectance fusion model (STARFM) is the first weight function-based STF method developed in the literature. This method first assumes that all the pixels in the coarse images are pure. It uses a weighted strategy to add the reflectance changes between two coarse images to the prior fine image so as to predict the target image. STARFM has been shown to be able to capture phenological changes. However, its performance in highly heterogeneous landscapes and in the task of capturing land-cover changes is limited.</p>
<h2 id="data-requirement">Data Requirement</h2>
<p>(MODIS and Landsat)Their orbital parameters are equal, and as such the viewing (near-nadir) and solar geometries are close to those of the corresponding Landsat acquisition.</p>
<h2 id="performance">Performance</h2>
<p>The STARFM has been tested over forested areas, cropland regions, and heterogeneous mixtures of crop and forest. Results show that the STARFM can capture phenology changes precisely, although the accuracy depends on the characteristic patch size of the landscape.</p>
<h2 id="theoretical-basis">Theoretical Basis</h2>
<p>Assumptions</p>
<ol type="1">
<li>Neglecting geolocation errors and differences in atmospheric correction</li>
<li>MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_k)\)</span> has been previously georeferenced and super sampled to the resolution and bounds of the Landsat surface reflectance image $L(x_i,y_j,t_k) $and thus shares the same image size, pixel size, and coordinate system.</li>
<li>if MODIS and Landsat surface reflectance are equal at a given time, then these values should be equal for the prediction date.</li>
<li>If the MODIS surface reflectance is constant over time, then the Landsat surface reflectance should not change as well.</li>
</ol>
<h3 id="basic-equations">Basic Equations</h3>
<p>Assumption 1</p>
<p>A heterogeneous coarse-resolution pixel at date <em>t</em> and surface reflectance (<span class="math inline">\(C_t\)</span>) can be aggregated from finer resolution homogeneous pixels of surface reflectance <span class="math inline">\(F^i_t\)</span> and percentage coverage <span class="math inline">\(A^i_t\)</span> according to <span class="math display">\[
C_t=\sum(F^i_t*A^i_t)\tag{1}
\]</span></p>
<p>where <span class="math inline">\(i\)</span> refers to the spatial index (location) of the fine- resolution pixel.</p>
<p>The key to finding an approximate solution is to find spectrally similar homogeneous neighboring pixels.</p>
<p>For a homogenous pixel at a coarser MODIS resolution, the surface reflectance measured by Landsat data can be ex- pressed as <span class="math display">\[
L(x_i,y_i,t_k)=M(x_i,y_i,t_i)+\varepsilon_k \tag{2}
\]</span> where <span class="math inline">\((x_i,y_j)\)</span> is a given pixel location for both Landsat and MODIS images, <span class="math inline">\(t_k\)</span> is the acquisition date for both MODIS and Landsat data, and <span class="math inline">\(ε_k\)</span> represents the difference between observed MODIS and Landsat surface reflectance (caused by differing bandwidth and solar geometry).</p>
<p>Assumption 2</p>
<p>Suppose we have n pairs input of $L(x_i,y_j,t_k) $and <span class="math inline">\(M(x_i,y_j,t_k)\)</span> and each pair is acquired on the same date, where <span class="math inline">\(k ∈ [1,n]\)</span>. The daily MODIS surface reflectance <span class="math inline">\(M(x_i,y_j,t_0)\)</span> at date <span class="math inline">\(t_0\)</span> is also a known value among inputs, then the predicted Landsat surface reflectance at date <span class="math inline">\(t_0\)</span> is <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ ε_0. \tag{3}
\]</span> Suppose the ground coverage type and system errors at pixel<span class="math inline">\((x_i,y_j)\)</span> does not change over prediction date <span class="math inline">\(t_0\)</span> and the date <span class="math inline">\(t_k\)</span>, we will have <span class="math inline">\(ε_0 = ε_k\)</span> and thus <span class="math display">\[
L(x_i,y_j,t_0)= M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k).\tag{4}
\]</span> Such ideal situation cannot be satisfied from MODIS and Landsat observations. Their relationships are complicated by several factors:</p>
<ol type="1">
<li>MODIS observation is not a homogeneous pixel and may include mixed land-cover types when considered at Landsat spatial resolution</li>
<li>Land cover may change from one type to another type during the prediction period</li>
<li>Land-cover status (phenology) and solar geometry bidirectional reflectance distribution function (BRDF) changes will alter the reflectance from prediction date <span class="math inline">\(t_0\)</span> to date <span class="math inline">\(t_k\)</span>.</li>
</ol>
<p>By introducing additional information from neighboring pixels, we compute the surface reflectance for the central pixel at date t0 with a weighting function <span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = \sum_{i=1}^{w} \sum_{j=1}^{w} \sum_{k=1}^{w}
W_{ijk}×(M(x_i,y_j,t_0)+ L(x_i,y_j,t_k) −M(x_i,y_j,t_k))\tag{5}
\]</span> where <span class="math inline">\(w\)</span> is the searching window size and <span class="math inline">\((x_{w/2},y_{w/2})\)</span> is the central pixel of this moving window.</p>
<p>To ensure that the right information from neighbor pixels is used, only spectrally similar (i.e., from the same spectral class) and cloud-free pixels from Landsat surface reflectance within the moving window are used to compute the reflectance.</p>
<p>The weight <span class="math inline">\(W_{ijk}\)</span> determines how much each neighboring pixel contributes to the estimated reflectance of the central pixel. It is very important and is determined by three measures as follows.</p>
<ol type="1">
<li><p>Spectral difference between MODIS and ETM+ data at a given location is <span class="math display">\[
S_{ijk} = |L(x_i,y_j,t_k) −M(x_i,y_j,t_k)| .\tag{6}
\]</span> A smaller value of <span class="math inline">\(S_{ijk}\)</span> implies that the fine spatial resolution pixel has closer spectral features to the averaged surrounding pixels; thus, the change at fine resolution should be comparable to that of the averaged surrounding pixels. Therefore, the pixel’s reflectance should be assigned a higher weight in (5).</p>
<p>A3</p></li>
<li><p>Temporal difference between the input and the predicted MODIS data is <span class="math display">\[
T_{ijk} = |M(x_i,y_j,t_k) −M(x_i,y_j,t_0)|\tag{7}
\]</span> This metric measures changes occurring between the prediction and the acquisition dates. A smaller <span class="math inline">\(T_{ijk}\)</span> means less vegetation change between time <span class="math inline">\(t_k\)</span> and <span class="math inline">\(t_0\)</span>; thus, the pixel should be assigned a higher weight.</p>
<p>A4</p>
<p>if changes are too subtle to be detected by the MODIS observation, this algorithm will not be able to predict any change when synthesizing the fine resolution imagery. Also, there may be situations where the STARFM algorithm cannot detect changes when two contradicting changes occur within a coarse-resolution pixel simultaneously and compensate for each other.</p></li>
<li><p>Location distance between central pixel <span class="math inline">\((x_{w/2},y_{w/2})\)</span> and candidate pixel <span class="math inline">\((x_i,y_j)\)</span> at date <span class="math inline">\(t_k\)</span> is <span class="math display">\[
d_{ijk} = \sqrt{(x_{w/2} − x_i )^2 + (y_{w/2} − y_j)^2}
\]</span> The spatial similarity is normally better for a closer pixel; thus, the closer candidate should be assigned a higher weight.</p></li>
</ol>
<h2 id="implementation-considerations">Implementation Considerations</h2>
<h3 id="how-to-weight-spatial-information">How to weight spatial information</h3>
<h4 id="spectrally-similar-neighbor-pixels">Spectrally Similar Neighbor Pixels</h4>
<p>The spectral similarity ensures that the correct spectral information is used from fine-resolution neighboring pixels: Unsupervised classification and using thresholds in surface reflectance directly. STARFM use the second approach.</p>
<p>"the purpose of the search process is to find pixels within the local moving window that are spectrally similar to the central pixel. Each central pixel becomes the center of the class, and the rules used to determine spectral similarity become local rules and thus vary from pixel to pixel. In contrast to the traditional classification, which applies the same classification rules over the whole region, our search process (second approach) will not be able to produce a unique classification map over the study area."</p>
<h4 id="combined-weighting-function">Combined Weighting Function</h4>
<p>Based one these assumptions:</p>
<ol type="1">
<li>coarse-resolution homogeneous pixels provide identical temporal changes as fine-resolution observations from the same spectral class</li>
<li>observations with less change from the prediction date provide better information for the prediction date</li>
<li>more proximal neighboring pixels normally provide better information for prediction.</li>
</ol>
<p>The final step is to combine these independent factors to create an ideal weight function that blends both temporal and spatial information</p>
<p>First, convert the actual distance to a relative distance through the function <span class="math display">\[
D_{ijk} =1.0+ d_{ijk}/A\tag{9}
\]</span> where <span class="math inline">\(A\)</span> is a constant that defines the relative importance of the spatial distance to the spectral and temporal distance.</p>
<p>The relative distance <span class="math inline">\(D_ijk\)</span> within searching area “<span class="math inline">\(w\)</span>” changes from 1to <span class="math inline">\([1 + (1/ \sqrt2) ∗ (w/A)]\)</span>. A smaller value of <span class="math inline">\(A\)</span> gives a larger dynamic range of <span class="math inline">\(D_{ijk}\)</span>.</p>
<p>The combined spectral, temporal, and spatial distance can be computed with <span class="math display">\[
C_{ijk} = S_{ijk} ∗ T_{ijk} ∗ D_{ijk}\tag{10}
\]</span> or in a logistic formula to make it less sensitive to the spectral differences <span class="math display">\[
C_{ijk} =ln(S_{ijk} ∗ B +1) ∗ ln(T_{ijk} ∗ B +1) ∗ D_{ijk}\tag{11}
\]</span> where <span class="math inline">\(B\)</span> is a scale factor (equal to 10 000 when using MODIS or LEDAPS reflectance products, which linearly scale reflectance from 0 to 10 000).</p>
<p>We use a normalized reverse distance as the weight function</p>
<p><span class="math display">\[
W_{ijk} =(1/C_{ijk}) /\sum_{i=1}^{w}\sum_{j=1}^{w}\sum_{k=1}^{n}(1/C_{ijk}).\tag{12}
\]</span></p>
<p>If the MODIS surface reflectance does not change, we have <span class="math inline">\(M(x_i,y_j,t_k)= M(x_i,y_j,t_0)\)</span>, then <span class="math inline">\(T_{ijk} =0\)</span> and <span class="math inline">\(C_{ijk} =0\)</span>, and weight <span class="math inline">\(W_{ijk}\)</span> is set to the maximum value. The predicted surface reflectance for central pixel of the moving window is then</p>
<p><span class="math display">\[
L (x_{w/2},y_{w/2},t_0) = M(x_i,y_j,t_0).
\]</span></p>
<p>This satisfies our other basic assumption: if MODIS and Landsat surface reflectance are equal at date <span class="math inline">\(t_k\)</span>, then they should be equal at date$ t_0$</p>
<h4 id="sample-filtering">Sample Filtering</h4>
<p>Additional filtering processes will then be applied to the candidates to remove poor- quality observations.</p>
<ol type="1">
<li><p>All poor-quality data are excluded from candidates according to the QA layer in the Landsat and MODIS surface reflectance products</p></li>
<li><p>Neighbor pixels are filtered out if they cannot provide better spectral and spatial information than the central pixel of the moving window</p>
<p>A good candidate should satisfy the following condition: <span class="math display">\[
S_{ijk} &lt; max (|L(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_k)|)\tag{13}
\]</span> and <span class="math display">\[
T_{ijk} &lt; max(|M(x_{w/2},y_{w/2},t_k) −M(x_{w/2},y_{w/2},t_0)|) \tag{14}
\]</span></p></li>
</ol>
<p>Suppose we know that the uncertainties from Landsat and MODIS surface reflectance are <span class="math inline">\(\sigma_l\)</span> and <span class="math inline">\(\sigma_m\)</span>, respectively. All surface reflectance measurements are independent. The uncertainty for the spectral difference (6) between MODIS and ETM+ is <span class="math display">\[
\sigma_{lm} = \sqrt{\sigma_l^2+\sigma_m^2}
\]</span> The uncertainty for temporal difference (7) between two MODIS inputs is <span class="math display">\[
\sigma_{mm} = \sqrt{\sigma_m^2+\sigma_m^2}=\sqrt{2}*\sigma_m
\]</span> Considering the uncertainties in the candidate selection, (12)can be revised as</p>
<p><span class="math display">\[
S_{ijk}&lt; max(|{L(x_{w/2},y_{w/2},t_k)−M(x_{w/2},y_{w/2},t_k)}
+σ_{lm}\tag{15}
\]</span></p>
<p>and(13)can be revised as</p>
<p><span class="math display">\[
T_{ijk} &lt;max(|M(x_{w/2},y_{w/2},t_{k}−M(x_{w/2},y_{w/2},t_0) + \sigma_{mm}\tag{16}
\]</span></p>
<h2 id="following-methods">Following methods</h2>
<p>http://www.chen-lab.club/?page_id=11432</p>
<p>ESTARFM,IFSDAF</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Data Fusion</tag>
        <tag>paper reading</tag>
        <tag>Research Basis</tag>
      </tags>
  </entry>
  <entry>
    <title>How to follow the research progress in your field?</title>
    <url>/posts/eaba55e.html</url>
    <content><![CDATA[<p>This is the note of my own experiences.</p>
<p>As summarized in my former blog, the new result always from pre-print website, social media, conference. Here I will summary some source in oceanography, especially ocean color, and also give some methods for following new articles.</p>
<a id="more"></a>
<h1 id="social-media">Social media</h1>
<p>Actually it’s hard to follow academic in social media, because there are a lot of redundant information.</p>
<h2 id="official-account-for-journal-and-research-institute">Official account for journal and research institute</h2>
<p>This is a good way. A lot of famous journal has official account in social media. They even have local language version account. In this way we can get new big result quickly. Such kind of big paper is hard for me, but I think it is necessary for me.</p>
<p>Some research institute also has official account such as Plymouth. They will also share research progress in social media</p>
<h1 id="preprint">Preprint</h1>
<p>In oceanography or earth science, we have Earth ArXiv(https://eartharxiv.org/discover). But as the quality of paper varies a lot. I do not recommend following progress in this site. Maybe you can search some keywords monthly or just some time you are free.</p>
<h1 id="conference">Conference</h1>
<p>Here are some conference I think worthy attention. Although we always could not get full content from abstract, we can contact the author for further discussion.</p>
<ol type="1">
<li>AGU, EGU and JpGU annual meeting</li>
<li>International Ocean Color Science Meetinghttps://iocs.ioccg.org/</li>
<li>IEEE IGARSS</li>
<li>ISPRS</li>
<li>Ocean Optics Conference</li>
<li>Ocean Science Meeting</li>
<li>Pan Ocean Remote Sensing Conference</li>
<li>SPIE, Space, Satellites and Sustainability(http://www.spie.org/ss101call)</li>
</ol>
<p>You can also follow some in this websitehttps://ioccg.org/resources/workshops-and-conferences/</p>
<h1 id="journal-subscription">Journal Subscription</h1>
<p>Search “Journal name+subscribe”, you will find the way to subscribe new articles. If this journal publish new article, they will send a email to alert you.</p>
<p>Hear are the journal I think worthy subscription</p>
<ul>
<li>Remote sensing of Environment</li>
<li>Earth System Science Data</li>
<li>Limnology and Oceanography</li>
<li>Journal of Geophysical Research: Ocean</li>
<li>Geophysical Research Letters</li>
<li>Nature Climate Change</li>
<li>Nature Geoscience</li>
<li>PNAS</li>
<li>Science Advance</li>
<li>Plos one</li>
<li>Optical express</li>
<li>Applied Optics</li>
<li>Applied Optics</li>
<li>Global Change Biology</li>
<li>Fish and Fisheries</li>
<li>Fishery Oceanography</li>
<li>Deep Sea Research</li>
<li>Frontiers in Marine Science</li>
<li>Scientific Reports</li>
<li>Remote Sensing</li>
</ul>
<h1 id="google-scholar-and-researchgate">Google Scholar and ResearchGate</h1>
<p>You can search the scientists who have the similar interest with you in google scholar or ResearchGate, and you will get the alerts for their new articles.</p>
<p>You can also set key words alerts in google scholar.</p>
<p>This methods always could give you new research earlier compared with subscription.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>JpGU-AGU Joint Meeting 2020 poster</title>
    <url>/posts/26d5d570.html</url>
    <content><![CDATA[<p>This year I attended the JpGU-AGU Joint Meeting 2020 and made a poster presentation.</p>
<p>https://confit.atlas.jp/guide/event/jpgu2020/subject/HTT15-P07/detail</p>
<a id="more"></a>
<h2 id="evaluation-and-comparison-of-karenia-mikimotoi-detection-in-the-seto-inland-sea-by-remote-sensing"><strong>Evaluation and comparison of <em>Karenia mikimotoi</em> detection in the Seto-Inland Sea by remote sensing</strong></h2>
<p>*<span class="exturl" data-url="aHR0cHM6Ly9jb25maXQuYXRsYXMuanAvZ3VpZGUvZXZlbnQvanBndTIwMjAvYXV0aG9yL0hUVDE1LVAwNy8wMzc5Njc=">Zhenjia Zhou<i class="fa fa-external-link-alt"></i></span>1, <span class="exturl" data-url="aHR0cHM6Ly9jb25maXQuYXRsYXMuanAvZ3VpZGUvZXZlbnQvanBndTIwMjAvYXV0aG9yL0hUVDE1LVAwNy8wMjUwMzY=">Joji Ishizaka<i class="fa fa-external-link-alt"></i></span>2 (1.GSES, Nagoya Univ., 2.ISEE, Nagoya Univ.)</p>
<p>Keywords:Seto-Inland Sea, Harmful Algae Blooms, Karenia mikimotoi, Remote Sensing</p>
<p>Harmful Algae Blooms (HABs) is a worldwide problem in coastal marine systems. Seto-Inland Sea is a semi-enclosed coastal area in Japan that suffered from HABs. Dinoflagellate <em>Karenia mikimotoi</em> is one of the most common species that form HABs in the Seto-Inland Sea. It could increase fish mortality, thereby causing economic losses for coastal aquaculture. A detection method based on the spectral difference in short wavelength was developed by limited field observation in the western part of the Seto-Inland Sea (Siswanto <em>et al.</em>, 2013). But the spectra in the short wavelength are always influenced by colored dissolved organic matters and non-algal particles as well as the error of atmospheric correction. Thus, it is necessary to evaluate the method with more filed observation data. Meanwhile, several methods for the detection of <em>Karenia brevis</em>, a HABs species belongs to the same genus and has similar optical properties with <em>Karenia mikimotoi</em>, were developed in the West Florida Shelf. These methods could be divided into chlorophyll-a based, apparent optical property based, inherent optical property based approach, etc. This research aims to compare results of different detection methods in the Seto-Inland Sea and evaluate them with the recent filed observation data.</p>
]]></content>
      <categories>
        <category>Papers And Thesis</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Harmful Algae</tag>
        <tag>International Conference</tag>
        <tag>Poster</tag>
      </tags>
  </entry>
  <entry>
    <title>MODIS OC data batch download</title>
    <url>/posts/8636bca2.html</url>
    <content><![CDATA[<p>This blog introduce a MODIS(also suitable for other available satellites) Ocean Color data batch download method without wget(since it doesn’t work on my laptop).</p>
<a id="more"></a>
<h2 id="requirement">Requirement</h2>
<p>1.Earthdata account</p>
<p>2.cygwim(https://www.cygwin.com/)</p>
<h2 id="step-by-step">Step by Step</h2>
<p>1.Login to Earthdata. Then enter <span class="exturl" data-url="aHR0cHM6Ly9zZWFyY2guZWFydGhkYXRhLm5hc2EuZ292L3NlYXJjaD9tPTAhLTAuMDcwMzEyNSEyITEhMCEwJTJDMiZhbXA7ZmRjPU9jZWFuJTIwQmlvbG9neSUyMERpc3RyaWJ1dGVkJTIwQWN0aXZlJTIwQXJjaGl2ZSUyMENlbnRlciUyMChPQi5EQUFDKSZhbXA7YWM9dHJ1ZQ==">https://search.earthdata.nasa.gov/search?m=0!-0.0703125!2!1!0!0%2C2&amp;fdc=Ocean%20Biology%20Distributed%20Active%20Archive%20Center%20(OB.DAAC)&amp;ac=true<i class="fa fa-external-link-alt"></i></span></p>
<p>2.Select desired satellite in the option ’Instruments’</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220141643.png"></p>
<p>3.Select desired region by spatial polygon, rectangular or coordinate.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220141833.png"></p>
<p>Then select desired product</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142022.png"></p>
<p>4.Screen the data by granule filters</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142153.png"></p>
<p>5.Click download all, then choose data access method and click download data in the end</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200220142309.png"></p>
<p>6.Click download access script</p>
<p><img src="/posts/blog\source_posts\MODIS-L2-OC-batch-download\20200220142411.png"></p>
<p>download the script</p>
<figure>
<img src="/posts/blog\source_posts\MODIS-L2-OC-batch-download\1582176279212.png" alt="1582176279212"><figcaption aria-hidden="true">1582176279212</figcaption>
</figure>
<p>open cygwin in the same download folder</p>
<p>enter:</p>
<p><code>chmod 777 download.sh</code></p>
<p><code>./download.sh</code></p>
<p>Then enter your password. Waiting for the result.</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>Note in writing and presentation</title>
    <url>/posts/3da0aceb.html</url>
    <content><![CDATA[<a id="more"></a>
<h1 id="英语的标点符号">英语的标点符号</h1>
<p>(这部分来自于微博)</p>
<p>今天批改学生的学期作业，发现英文标点符号使用的错误仍未能杜绝。这些年来，在标点符号的使用上，对每一班的学生，特别是有写作内容的课程，都要求学生遵守英文的标点规范。但是，到了学期末，仍然有不少同学不能完全掌握。做英语学位论文时，标点符号的问题更突显。究其原因，其一，同学们对英文标点的知识还没有完全掌握，意识还有待加强；其二，电脑输入时，因为技术问题，也因为自己的“偷懒”，不能自觉转换英汉两种语言标点符号的使用。</p>
<p>标点符号的使用反映语言素养，虽是细节，意义重大——是书面表达是否presentable的重要鉴定标准之一。有时候，我会开玩笑地跟学生说，你的标点符号的使用，反映着你英语教育方面的breeding（也是老师没有尽到责任）。我也常跟学生说，以后投递简历、各类申请书时，你英文写作技术规范的表现，很可能是给雇主留下深刻印象的关键性因素。所谓细节决定成败，这是一个典型表现。</p>
<p>标点符号的使用属于英文写作mechanics范畴，相关书籍或章节的介绍很多，几乎所有英语写作教材中都能读到，很容易查找。我这里只提几处典型的错误，中国学生常常意识不到。</p>
<p>1、空格问题。英语的逗号、句号、分号、问号、叹号等标点（除了上引号和破折号）之后，都要空一个字符。中学时期，作文为手写，这一点不容易判断出来；上了大学，英文写作常需要完成电子稿时，却看到电子稿到处红线和绿线。标点使用的空格错误，电脑会自动标注为红线，可见其错误的严重性。这个问题在新生班里是普遍存在的。</p>
<p>2、行文中出现英语中没有的标点符号，最典型的是顿号、六个点的省略号（英语的省略号是三个点，在英文状态下输入三个点，自然生成）、汉语的破折号、书名号等。</p>
<p>3、英语和汉语的标点符号混用严重，例如逗号、引号、破折号等。首先确保汉语为全角状态；英语为半角状态。然后，选中英文部分，将字体变成英文字体；选中中文部分，将字体变为中文字体。这样，标点符号随之改变。也可以自己手动逐一修改——这个方法最可靠，因为全部选定进行转换的话，有可能波及到不需要转换的部分。</p>
<p>4、英文没有汉语的书名号（《》）。汉语中，所有的作品都可以用书名号，例如文章的题目用书名号，电影名字、乐章标题、书名、期刊杂志名等。英文的书名、期刊名用斜体（手写时，为了区分，用下划线）。但是文章题目不用书名号，用引号——这一点最容易错。</p>
<p>5、网络惹的祸——英语中使用汉语的书名号。英语中本来没有汉语的那种书名号（《》），但因很多网络格式中没有斜体，因此，有些汉语使用者就开始用自己的书名号框住英语的书名。这是错误用法，未来是否会因为使用人太多而被接受也未可知。但是目前，如果英语作文中出现这种用法就是硬伤了。</p>
<p>6、下载的材料未作规范处理，标点规范不统一，给人留下很坏的印象。标点符号暴露了你的“抄袭”行为。网上下载资料之后，没有经过统一处理，最明显的地方就是引号的不同规范。有些同学不明白，为什么老师一眼就看出来自己论文中“抄袭”的部分。很多时候，老师只要看看不一样的标点规范，（然后选取相关部分在网上进行搜索，甚至不需要搜索）便能判断出来了。这一点告诉我们，不同字体的标点符号长得不一样哈——在一项任务中统一很重要。除了了解这一点之外，也建议每位同学找到自己喜欢的、常用的字体。</p>
<p>7、破折号的输入方法是大家不熟悉的。首先要确定我们是在英文状态下输入，不要使用汉语的破折号。有些同学先输入一个汉语的破折号，然后再去掉一半儿，以此来充当英语的破折号。其实它们不同，你可以从符号空间上的高低位置判断出来（英文的低于中文的。在英文状态下，一个单词之后连续输入两个连字符，再接着输入其它或空格，英文的破折号就自然生成了。（英语的破折号使用其实更为复杂，因为有“n-dash”和“m-dash”之分，他们的使用场合也不全一样。）</p>
<p>8、冒号和破折号的使用。汉语标题之后如果有副标题，我们一般使用破折号；英语的副标题之前常用冒号，偶尔也会用破折号。两者有细微区别。</p>
<p>9、还有一个经常出现的标点问题，也可视为病句——run-on sentences。就是像汉语那样，用逗号连接很多小句。在这个方面，一个操作简便的基本规范是，英语中，一个句子一般只有一个主要动词；如果出现另一个主要动词，那要看是否以从句形式出现，是否有表示逻辑关系的连接词来连接，如果没有任何此类情况，那么一个完整句子包括一个主要动词。一句话结束了，就要使用句号。（这里不包括因为修辞需要而出现的特殊情况。）</p>
<p>10、最后，再提一个学位论文中常出现的标点问题。英文学位论文的参考文献的标点符号使用上，因为信息往往不以句子形式呈现，所以上面的规范不适合。同学们的主要问题除了上面提到的论文题目和书名、期刊名的标点错误之外，还表现在规范的不统一。这一点上，同学们需要清楚，不同的出版机构采用的规范不尽相同，每个学校的格式要求也不一样，大家要使用自己学校认可的那一种规范，并且要统一。不是你文献中看到的格式有错误，而是在特定环境中的一个统一的问题）。这一问题也常伴随着大小写规范的选择和统一问题</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>学术写作</tag>
        <tag>学术发表</tag>
      </tags>
  </entry>
  <entry>
    <title>IOP inversion</title>
    <url>/posts/f5ee8139.html</url>
    <content><![CDATA[<p>This note is based on Lee 1998,1999,2002 and P. Werdell 2013</p>
<a id="more"></a>
<h1 id="qaa">QAA</h1>
<h2 id="the-reason-for-failure-of-qaa">The reason for failure of QAA</h2>
<p>After one year I found that I haven't finish the note. I will try to finish this.</p>
<p>But before that I think I found the reason for the failure of QAA</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021118142948938.png" alt="image-00021118142948938"><figcaption aria-hidden="true">image-00021118142948938</figcaption>
</figure>
<p>Address: http://www.ioccg.org/groups/Software_OCA/QAA_v6_2014209.pdf</p>
<p>This is the whole process of QAA v6. Compared with the former one, the main update is in step2.</p>
<p>This is because in the first version, in the oligotrophic water, the <span class="math inline">\(a_{ph}\)</span> is very low. Meanwhile the <span class="math inline">\(a_{CDOM}\)</span> has a very influence in the <span class="math inline">\(a_{total}\)</span> at 55xnm. So the <span class="math inline">\(a_{total}\)</span> is mainly determined by <span class="math inline">\(a_w\)</span>. As a result, lee used an emprical relationship from <span class="math inline">\(r_{rs}\)</span> to estimated <span class="math inline">\(a_{total}(55x)\)</span>. But in the coastal area, the <span class="math inline">\(a_{total}\)</span> is dominated other constituents besides water, it make a lot of difference. It is also the reason that the update mainly happened in step2.</p>
<h2 id="nir-base-qaa">NIR base QAA</h2>
<p>Some recent research use NIR wavelength for the step 2 as the non-water absorption at NIR is low.</p>
<p>Here is the 'A blended inherent optical property algorithm for global satellite ocean color observations'.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194200562.png" alt="image-00021210194200562"><figcaption aria-hidden="true">image-00021210194200562</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194014638.png" alt="image-00021210194014638"><figcaption aria-hidden="true">image-00021210194014638</figcaption>
</figure>
<p>Another two is in Taihu.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021210194504447.png" alt="image-00021210194504447"><figcaption aria-hidden="true">image-00021210194504447</figcaption>
</figure>
<figure>
<img src="/Users/zhenjia/Library/Application%20Support/typora-user-images/image-00021210194529712.png" alt="image-00021210194529712"><figcaption aria-hidden="true">image-00021210194529712</figcaption>
</figure>
<p>QAA-750 is somewhat almost same with NIR-QAA, but QAA750-ap found that in Taihu, the ap750 sometime is still can't negletable.</p>
<p>We don't have ap763, I hope we can have that dataset later.</p>
<h1 id="giop">GIOP</h1>
<p>This is another commly used Semi-analytical algorithm for IOP inversion.</p>
<h2 id="introduction">Introduction</h2>
<ul>
<li>SAA always differentiations only in the assumputions employed to define the eigenvectors and in the mathematical methods applied to calculate the eigenvalues</li>
<li>GIOP allows construction of different IOP models at runtime by selection from a wide assort-ment of published absorption and backscattering eigenvectors.</li>
</ul>
<h2 id="method">Method</h2>
<h3 id="model-development">Model Development</h3>
<p>Lee et al 2002, Rrs to rrs <span class="math display">\[
r_{rs}(\lambda,0^-)=\frac{R_{rs}(\lambda)}{0.52+1.7R_{rs}(\lambda)}
\]</span> rrs to IOP <span class="math display">\[
r_{rs}(\lambda,0^-)=G_1(\lambda)u(\lambda)+G_2(\lambda)u(\lambda)^2
\]</span></p>
<p><span class="math display">\[
u(\lambda)=\frac{b_b{(\lambda)}}{a(\lambda)+b_b(\lambda)}
\]</span></p>
<p>Common methods for estimating G?λ? include Gordon et al. [21], where G1 and G2 are spectrally fixed to 0.0949 and 0.0794 (see [7,23] for alternative coefficients), and the tabulated results ofMorel et al. [22], where G1 is estimated using solar and sensor geometries and an estimate of algal bio- mass and G2 is set to 0. GIOP supports all of these options.</p>
<p>IOP decomposition</p>
<p>each component can be expressed as the product of its concentration-specific absorption spectrum (eigenvector; a?) and its concentration or amplitude (eigenvalue; A): <span class="math display">\[
a(\lambda)=a_w(\lambda)+\sum_{i=1}^{N}A_{ph}a_{ph}^{*}(\lambda)+\sum_{i=1}^{N}A_{d}a_{d}^{*}(\lambda)+\sum_{i=1}^{N}A_{g}a_{g}^{*}(\lambda)
\]</span> Both <span class="math inline">\(a_{d}^*(\lambda)\)</span> and <span class="math inline">\(a_g^*(λ)\)</span> are commonly expressed as <span class="math display">\[
a_{d,g}^*(\lambda)=exp(-S_{d,g}\lambda)
\]</span> where Sd and Sg typically vary between 0.01 and 0.02 nm−1 in natural waters [24].</p>
<p>As the spectral shapes of NAP and CDOM absorption differ only in their exponential slopes, the two components are typically combined for satellite applications and Eq. (4) becomes</p>
<p><span class="math display">\[
a(\lambda)=a_w(\lambda)+\sum_{i=1}^{N}A_{ph}a_{ph}^{*}(\lambda)+\sum_{i=1}^{N}A_{dg}a_{dg}^{*}(\lambda)
\]</span> For total backscattering <span class="math display">\[
b_b(\lambda)=b_{bw}({\lambda})+\sum_{i=1}^NB_{bp}b_{bp}(\lambda)
\]</span> Bbp provides the eigenvalue and a power function often represents the eigenvector: <span class="math display">\[
b_{bp}^*(\lambda)=\lambda^{S_{bp}}
\]</span> where Sbp typically varies between −2 and 0 from small to large particles.</p>
<p>While commonly employed in the remote-sensing paradigm, we acknowledge the validity of the power function for b? bpλ remains debatable [25–27].</p>
<p>Using Rrsλ and eigenvectors as input, eigenvalues for absorption (A) and backscattering (B) can be estimated via linear or nonlinear least squares inversion of Eqs. (1)–(3).</p>
<p>Note that this model describes each component of absorption and back- scattering as a linear sum of subcomponents, presumably with unique spectral dependencies [sym- bolized by the summation over N in Eqs. (4), (6), and (7)]. In this way, the absorption characteristics for different phytoplankton populations and the scatter- ing characteristics of multiple size distributions of suspended particles can be represented, or Eq. (6) can be re-expanded to Eq. (4).</p>
<h3 id="model-configuration">Model configuration</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021124160320671.png" alt="image-00021124160320671"><figcaption aria-hidden="true">image-00021124160320671</figcaption>
</figure>
<p>Here explained the default configuration of GIOP.</p>
<ol type="1">
<li></li>
</ol>
<h1 id="evaluating-semi-analytical-algorithms-for-estimating-inherent-optical-properties-in-the-south-china-sea">Evaluating semi-analytical algorithms for estimating inherent optical properties in the South China Sea</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>paper reading</tag>
        <tag>Research Basis</tag>
        <tag>Ocean Optics</tag>
      </tags>
  </entry>
  <entry>
    <title>Tutorial for handling MODIS ocean color data</title>
    <url>/posts/ef746e52.html</url>
    <content><![CDATA[<p>This tutorial covers mainly two parts:</p>
<ol type="1">
<li>Using python to analyse MODIS ocean color data</li>
<li>Installation and application of SeaDA OCSSW</li>
</ol>
<a id="more"></a>
<h1 id="using-python-to-analyse-modis-ocean-color-data">Using python to analyse modis ocean color data</h1>
<h2 id="package-and-working-environment">Package and working environment</h2>
<p>This this the first difficult thing for a rookie.</p>
<h3 id="anaconda-pycharm">Anaconda &amp; Pycharm</h3>
<p>Anaconda contains most of the package</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>assert</title>
    <url>/posts/b1ef4fab.html</url>
    <content><![CDATA[<p>最近在读别人代码的时候发现了好多自己当时学python的时候没有学过的东西</p>
<a id="more"></a>
<h1 id="语法">语法</h1>
<p>Python assert用于判断一个表达式，在表达式条件为false的时候触发异常。</p>
<p>语法格式如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression</span><br></pre></td></tr></table></figure>
<p>等价于</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> expression:</span><br><span class="line">    <span class="keyword">raise</span> AssertionError</span><br></pre></td></tr></table></figure>
<p>后面也可以跟参数:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression [, arguments]</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">assert</span> expression [, arguments]</span><br></pre></td></tr></table></figure>
<h1 id="使用实例">使用实例</h1>
<blockquote>
<p>检查 先验条件 使用assert，检查 后验条件 使用 异常处理</p>
</blockquote>
<p>举个例子来说明一下，在开发中我们经常会遇到读取本地文件的场景。我们定义一个read_file方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span>(<span class="params">path</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> isinstance(file_path, str)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>read_file函数要求在开始执行的时候满足一定条件：file_path必须是str类型，这个条件就是*<strong>先验条件*</strong>，如果不满足，就不能调用这个函数，如果真的出现了不满足条件的情况，证明代码中出现了bug，这时候我们就可以使用assert语句来对file_path的类型进行推断，提醒程序员修改代码，也可以使用if...raise...语句来实现assert，但是要繁琐很多。在很多优秀的Python项目中都会看到使用assert进行先验判断的情况，平时可以多多留意。</p>
<p>read_file函数在被调用执行后，依然需要满足一定条件，比如file_path所指定的文件需要是存在的，并且当前用户有权限读取该文件，这些条件称为后验条件，对于后验条件的检查，我们需要使用异常来处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span>(<span class="params">file_path</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> isinstance(file_path, str)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> check_exist(file_path):</span><br><span class="line">        <span class="keyword">raise</span> FileNotFoundError()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> has_privilege(file_path):</span><br><span class="line">        <span class="keyword">raise</span> PermissionError()</span><br></pre></td></tr></table></figure>
<p>文件不存在和没有权限，这两种情况并不属于代码bug，是代码逻辑的一部分，上层代码捕获异常后可能会执行其他逻辑，因此我们不能接受这部分代码在生产环境中被忽略，这属于*<strong>后验条件*</strong>。并且，相比于assert语句只能抛出AssertionError，使用异常可以抛出更详细的错误，方便上层代码针对不同错误执行不同的逻辑。</p>
<p>再比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">assert</span> (<span class="string">&#x27;linux&#x27;</span> **<span class="keyword">in</span>** sys.platform), <span class="string">&quot;该代码只能在 Linux 下执行&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="其他异常处理">其他异常处理</h1>
<p>顺手补一下其他异常处理</p>
<h2 id="try...except">try...except</h2>
<p>这个语句主要是用来可能发生错误的语句里面，比如在跑一个循环的时候有的除以零，有的没有除以零，可以使用try except把除以零的赋值nan避免这个循环停止，让程序继续跑下去。</p>
<h2 id="try...finally">try...finally</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># try..finally模式</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  &lt;statement&gt;        <span class="comment">#运行别的代码</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">  &lt;statement&gt;        <span class="comment">#不管有无异常都会执行 </span></span><br></pre></td></tr></table></figure>
<p>try..finally模式是:</p>
<ol type="1">
<li>没有异常就先运行try所有语句,再运行finally所有语句.</li>
<li>要是有异常,try执行到异常就跳到finally,然后直接跳出将异常递交给上层的try.控制流并不通过所有try语句.</li>
<li>finally能跟在except/else后,优先先执行except/else再执行finally.</li>
</ol>
<p>由此可知, try…finally 模式更适合于嵌套在try..except内作为保证某些代码一定执行.因为try..except…else要是执行了except就不会执行else,无法保证某个代码必须执行.所以常见的整合模式为:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 两种模式的嵌套和结合</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  &lt;statement1&gt;        <span class="comment">#运行测试代码1</span></span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">     &lt;statement2&gt;        <span class="comment">#运行测试代码2</span></span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">     &lt;statement3&gt;        <span class="comment">#不管测试代码2有无异常都会执行</span></span><br><span class="line"><span class="keyword">except</span> &lt;name&gt;：</span><br><span class="line">    &lt;statement&gt;        <span class="comment">#测试代码1或2发生错误而被捕获,就会执行异常</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"> &lt;statement&gt;        <span class="comment">#测试代码1和2都没有发生错误就会执行</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">  &lt;statement4&gt;        <span class="comment">#无论两个try有无异常,都会运行一次.</span></span><br></pre></td></tr></table></figure>
<p>PS: 要是finally在except/else前面肯定会报错.因为try后直接给finally,然后会交给上层try.但没有上层try…</p>
<p>实例:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">   fh = open(<span class="string">&quot;testfile&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line">   <span class="keyword">try</span>:</span><br><span class="line">      fh.write(<span class="string">&quot;This is my test file for exception handling!!&quot;</span>)</span><br><span class="line">   <span class="keyword">finally</span>:</span><br><span class="line">      <span class="keyword">print</span> <span class="string">&quot;Going to close the file&quot;</span></span><br><span class="line">      fh.close()</span><br><span class="line"><span class="keyword">except</span> IOError:</span><br><span class="line">   <span class="keyword">print</span> <span class="string">&quot;Error: can&#x27;t find file or read data&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="raise">raise</h2>
<h3 id="与try一起使用">与try一起使用</h3>
<p>raise语句可以很好地用于抛出某个异常从而被try捕获. 更常用于结合if等进行条件检查.例如某变量假定[0,10],&lt;0时抛出一个错,&gt;10抛出另一个错误.</p>
<p>raise一般是<code>raise exception,args</code>,args一般采用一个值,来初始化异常类的args属性,也可以直接使用元组来初始化args.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">raise</span> &lt;name&gt;    <span class="comment">#手工地引发异常</span></span><br><span class="line"><span class="keyword">raise</span> &lt;name&gt;,&lt;data&gt;    <span class="comment">#传递一个附加的数据(一个值或者一个元组),要是不指定参数,则为None.</span></span><br><span class="line"><span class="keyword">raise</span> Exception(data)    <span class="comment">#和上面等效.</span></span><br><span class="line"><span class="keyword">raise</span> [Exception [, args [, traceback]]]  <span class="comment"># 第三个参数是用于跟踪异常对象,基本不用.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"> <span class="keyword">if</span> (i&gt;<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">raise</span> TypeError(i)</span><br><span class="line">   <span class="keyword">elif</span> (i&lt;<span class="number">0</span>):</span><br><span class="line">       <span class="keyword">raise</span> ValueError,i</span><br><span class="line"><span class="comment">#下面的e实际是返回错误的对象实例.</span></span><br><span class="line"><span class="keyword">except</span> TypeError,e:</span><br><span class="line">    <span class="keyword">print</span> str(e)+<span class="string">&quot; for i is larger than 10!&quot;</span></span><br><span class="line"><span class="keyword">except</span> ValueError,e:</span><br><span class="line">    <span class="keyword">print</span> str(e)+<span class="string">&quot; for i is less than 0!&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  <span class="keyword">print</span> <span class="string">&quot;i is between 0 and 10~&quot;</span></span><br></pre></td></tr></table></figure>
<h1 id="参考资料">参考资料</h1>
<p>https://stackoverflow.com/questions/40182944/difference-between-raise-try-and-assert</p>
<p>https://www.cnblogs.com/lsdb/p/11063568.html</p>
<p>https://blog.csdn.net/qq_29287973/article/details/78053764</p>
<p>https://www.runoob.com/python3/python3-assert.html</p>
<p>https://zhuanlan.zhihu.com/p/91853234</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>book reading note 4</title>
    <url>/posts/5ab69b8e.html</url>
    <content><![CDATA[<p>Chapter 10.1.-10.2 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="introduction">Introduction</h1>
<p>From this week we will start a new chapter, the oceans and global climate change: physical and biological aspects. Today I will talk about the introduction and physical part</p>
<p>The physical aspects contains the greenhouse effect and climate change</p>
<p>The oceans have a deep circulation, the thermohaline circulation. Water is heated in equatorial regions, and then moves poleward in major currents, giving off heat to the atmosphere. In subarctic regions cooling and ice formation cause water to become more dense. The water then sinks to form the “deep water.” This sinking is the beginning of a long journey close to the ocean floor. Some of the deep water travels south in the Atlantic basin, moves across to the Pacific basin, and there moves slowly northward in a journey that may take a thousand years.</p>
<p>The exchange mechanism contains two part, the physical part is related to the thermohaline circulation. At the regions of deep-water formation large quantities of carbon dioxide dissolved in the water sink to great depth and are removed from contact with the atmosphere. Conversely, at regions of upwelling, especially the large upwellings at the tropical divergence, heating of the cold upwelled water causes it to give off billions of tons of carbon dioxide. The exchange amount of CO2 is approximately balanced in the physical mechanism. But some biological process could also remove cp2 from atmosphere to the deep ocean. Over 99% of the carbon dioxide added to the earth’s atmosphere throughout its history has been taken up by phytoplankton and sedimented to the sea floor to form the calcareous rocks and the fossil fuels. This biological mechanism is known as the biological pump.</p>
<p>In the past 150 years, the co2 concentration in the atmosphere is absolutely rising, so here an important problem is that How much excess CO2 can be absorbed by ocean?</p>
<p>In order to answer this question, this chapter will talk about the the mechanism of global warming and the present-day global carbon cycle first. Then explore the relative importance of oceanic sources and sinks compared with industrial activities and terrestrial biota. Finally, consider what changes might be expected to occur in physical and biological mechanisms for circulating carbon in the ocean if the expected rise in global atmospheric temperature occurs</p>
<h1 id="physical-aspects">Physical aspects</h1>
<h2 id="the-greenhouse-effect">The greenhouse effect</h2>
<h3 id="the-process">The process</h3>
<p>So here we come to our first part, about the physical aspects. First lets talk about the process of greenhouse effect.</p>
<p>The average surface temperature of earth surface is about 15 Celsius degree. If there were no water vapor, carbon dioxide, or methane in the atmosphere, the surface temperature would be below freezing by ~18 °C and all the rivers, lakes, and oceans would be frozen solid. The reason for the higher, more habitable temperature is the fact that these greenhouse gases delay heat from leaving the earth by trapping it in the lower atmosphere.</p>
<p>all the heat received on the earth comes originally from the sun’s surface via electromagnetic radiation with wavelengths between 0.2 and 2.4 Micrometre, often called the short-wave radiation. approximately 31% of this incoming radiation is reflected back into space, ~20% is absorbed by the ozone, water vapor, clouds, and dust in the atmosphere, and ~49% is absorbed by the land and water at the earth’s surface.</p>
<p>All these absorbers in turn radiate heat in the form of electromagnetic radiation. The back radiation is at wavelengths between 5 and 100 Micrometre: long-wave radiation according to Planck’s radiation law. As I talked before, the radiation from the sun, the short-wave radiation, only 20% of them is absorbed by atmosphere. But here 90% long-wave radiation is absorbed by greenhouse gases inside atmosphere. The amount of heat trapped and the resulting temperature of the atmosphere clearly vary directly with the concentrations of these gases. If the gases are very concentrated, as on the planet Venus, the temperature is very high (+400 Celsius degree) and if they are low, as on Mars, the temperature is very low (−50 Celsius degree)</p>
<p>The greenhouse gases in the atmosphere. ranged from naturally occurred to human-produced, are carbon dioxide, water vapor, methane,ozone, nitrous oxide, chlorofluorocarbon.</p>
<p>The warming effect of each of these gases is different because their concentrations are different and because they absorb radiation with different efficiencies at different wavelengths. Under clear-sky conditions, Kiehl and Trenberth (1997) estimate that 60% of the warming effect is due to water vapor, 26% to carbon dioxide, 8% to ozone, and 6% to methane and nitrous oxide. The other gases, such as chlorofluorocarbons, contribute ~1% or less to the total warming effect. For life in the oceans, the most important element in these gases is the carbon (C) in the carbon dioxide (CO2).</p>
<h3 id="the-carbon-cycle">The carbon cycle</h3>
<p>Estimations of the magnitudes of the carbon reservoirs and fluxes in the global carbon cycle are constantly being updated. Here is an estimation conducted by Sarmiento and Gruber in 2002. The value here shows carbon flux. value without underline is pre-industrial value and with underline is anthropogenic value. In the atmosphere, for example, there were ~590 Petagram of carbon in the pre-industrial era but today the value is ~161 Petagram higher for an increase of ~30%.</p>
<p>For the carbon between ocean and atmosphere, we can see that 90.6 Pg carbon come from ocean to the atmosphere while 91.9 Pg come back, which result in net increase in the ocean 1.3 Pg C y^-1</p>
<p>When the co2 dissolve in the ocean, only 1% dissolved carbon retains CO2 structure that participate in the exchange with the atmosphere.</p>
<p>The Dissolved Inorganic Cabon(DIC) is also called total CO2.Here are two examples of vertical distributions of total CO2. In the surface layer the total co2 is low and increase until 1000m, then stay roughly constant until the bottom. On obvious result is that higher concentration in the deeper water. Also evident in this figure is the greater concentration below 1000 m in the North Pacific than in the North Atlantic. Such difference is thought to reflect the greater length of time since the deep Pacific has been in contact with the atmosphere and thus the greater length of time it has had to accumulate carbon from sinking plant and animal detritus.</p>
<h2 id="climate-change">Climate change</h2>
<h3 id="carbon-dioxide">Carbon dioxide</h3>
<p>The increasing greenhouse gases will absolutely increase the greenhouse effect. Here shows the atmosphere carbon dioxide concentration since 900. Before 1985, the concentration was obtained by analyzing air trapped in glaciers. And after 1985, the concentration was measured directly at Mauna Loa, Hawaii.</p>
<p>We can see that from 900 to 2850, the concentration is about 280 Parts Per Million (ppm).In 2001, the concentration is about 37Parts Per Million, about 30% increase in 150 years. And this might be the highest concentration in the past 420 000 years.</p>
<p>In the rising co2, about two thirds of them is anthropogenic co2 from burning of coal, oil and gas. Remaining thirds are from the release of co2 from deforestation.</p>
<p>The co2 is responsible for about 60% percent of greenhouse effect since 1850, while methane and nitrous , trace gases takes the rest 40%.</p>
<p>Such rising concentration give use two questions:</p>
<p>What effects are these increases having on the world’s temperature, precipitation, sea level, ice cover, and biological processes?</p>
<p>What about the future if the greenhouse effect continues to increase?</p>
<p>These two question will be discussed later in this chapter.</p>
<p>Here is another figure shows The annual flux of carbon dioxide into the atmosphere from fossil fuel emissions and the annual increase in carbon dioxide observed in the atmosphere, 1958–2000.</p>
<p>One interesting thing is that about half the amount of CO2 estimated to have been put into the atmosphere by human activities.</p>
<p>Before 1950, about 2.5 pg y-1 emission but only 1.5 increase. Recently about 7 emission but only 4 pg in the atmosphere. The missing part of emission is now known to be dissolving in the oceans or being incorporated into the terrestrial biomass</p>
<p>For the missing part in the ocean, now it is possible to identify the source of co2 in the ocean , because the 13C/12C ratio is lower in fossil-fuel CO2. And they found that the anthropogenic co2 most are limited in Upper few hundred meters of the ocean. In the deep ocean, the anthropogenic co2 was only found in the deep North Atlantic, where the co2 was renewed by contacting with atmosphere</p>
<p>Another interesting thing here, the peak of annual accumulation coincide with El Niño events. Here the red bar shows the time of ei nino events. The only one exception is 1992-3,minimum accumulation rate. which is the minimum accumulation rate. The exception might because Eruption of Mount Pinatubo in the early 1990s cooled the atmosphere.</p>
<p>But the peak coincidence remain controversial. One possible reason is that the warmer water in the equatorial Pacific during El Niño events would lead to an increased flux of CO2 into the atmosphere. Observations however indicate the flux is probably decreased during El Niños in the equatorial region because of the decrease in upwelling along the equator of water with higher CO2 content.</p>
<p>Another reason might be the response of terrestrial biosphere. But this is still poorly understood.</p>
<h3 id="temperature">Temperature</h3>
<p>Temperature is the key variable to monitor effect of greenhouse gases.</p>
<p>Here this figure shows the Surface temperature of the earth, including land and marine data.</p>
<p>we can see that the temperature fluctuated about a constant level between 1860 and 1910, and then rise 0.3℃ by 1940s, but it is still stable until 1970s. After 1970 the temperature increase quickly. 1998 is the warmest year. The Total increase in past 150 years is about 0.6 ± 0.2 °C.</p>
<p>But the warming is not the same everywhere and in a few locations surface temperature actually decreased while other regions experienced strong increases.</p>
<p>Also in this figure, the grey band shows temperature range by model simulation</p>
<p>We can see that the model result have good agreement with past observed temperature. And base on the prediction of these model, the temperature will Increase from 1.5℃ to 5.5℃ over the next 100 years, in average is about 3.</p>
<p>Here this figure shows a longer time series of surface temperature in the northern hemisphere. The time series was constructed from instrumental record(Jones et al., 2001) and proxy data from variation in tree rings, corals, and ice cores.</p>
<p>We can see that 1000-1900: the temperature decrease about 0.02℃→earth’s orbit and rotation.</p>
<p>But Over the past century, there have been significant temperature anomalies due to the growth of co2</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>book-reading-note2</title>
    <url>/posts/44f3f721.html</url>
    <content><![CDATA[<p>Chapter 7.1-7.2.4 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="tides-tidal-mixing-and-internal-waves">Tides, tidal mixing, and internal waves</h1>
<h2 id="introduction">Introduction</h2>
<p>This chapter focus on the tides, tidal mixing and internal waves and today I will talk from the introduction to the physics of tidal currents.</p>
<p>Tides are created by the gravitational pull of the moon and the sun. The changing water level leads to interesting patterns of intertidal organisms( place a figure of intertidal zone ) but it is not the emphases of this chapter.</p>
<p>Besides the intertidal zone, the tides also generate currents in the water that interact with the bottom to produce turbulence. And if the currents are sufficiently strong, the turbulence could prevent any stratification , thus the wholes area may be permanently tidally mixed. There are some researches shows that a great number of stocks only live in such strong tidal mixing area. In this chapter we will explore the possible significance of this observation.</p>
<p>And if the tidal mixing is not so strong, the water column becomes stratified, the interaction of the tidal currents with the bottom topography could lead to the formation of internal waves. Internal waves could cause vertical mixing and redistribution of nutrients, which is important effects on phytoplankton production. Some times as the internal wave decays, they produce solitary waves and bores,which could have a strong influence of on the distribution of zooplankton and larval fishes.</p>
<p>Around the shallow bank, the interaction between tidal currents and bottom topography could generate unidirectional currents that form gyres. The combination of tidally mixed water over the top of a bank and a gyre around its periphery is thought to provide conditions particularly suitable for the eggs and larvae of fish. In this chapter we shall explore some of these interesting consequences of tidally induced water movement.</p>
<p>(Needs some more figures and references to tell the story)</p>
<h2 id="the-physics-of-tides">The physics of tides</h2>
<h3 id="tide-generating-forces-and-the-equilibrium-tide.">Tide-generating forces and the equilibrium tide.</h3>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200207160250.png"></p>
<p>First part is the physics of tides. Lets start from the most simple occasion. Here the earth and the moon are seen from above the north pole of the earth</p>
<ol type="1">
<li>The water on the earth only receive the gravitational pull of the moon, remove the sun and the centripetal force from earth.</li>
<li>The earth and moon are assumed to be stationary except for the earth’s rotation.</li>
<li>The earth doesn’t have continents and is covered with a uniform layer of water.</li>
<li>Without the Coriolis force and friction force.</li>
</ol>
<p>Our observer is located in O. It is clear that the , the highest tide will always under the moon and the lowest tide will be on the opposite side to the moon as a result of gravitational pull of moon and centripetal force from earth. With the earth rotate, our observer will see one high tide and one low tide a day.</p>
<p>This elementary model could produce a tide but it is not a very good model because most places on the earth usually have two high and two low tides during the day.</p>
<p>One thing that need to consider is the rotation of the earth moon pair, about 29.5 day once. Because the earth’s mass is roughly 80 times that of the moon the common center of rotation is inside the earth about 1600 km below the surface along a line from the moon to the earth. The the common center of rotation is inside the earth about 1600 km below the surface along a line from the moon to the earth. And in order to make the earth and moon rotate around the center of mass, both of them will receive a centripetal force from the center of mass. This force is supplied by the gravity between earth and moon. But for us, the earth is stationary, that mean we choose our earth as reference system. So in order to make our earth stationary, we need add a fictitious force or inertial force. As a result, the water in our earth now receive two force, one is the gravity from moon, another is inertial force which backwards the center of mass.</p>
<p>Therefore, the shape of water on our earth likes a rugby.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200207212741.png"></p>
<p>And this bulge is called tide bulge.</p>
<p>This model could help us describe two things. One is that we can observe two high tides and two low tides every day. Another is that why the tides do not occur at the same time every day. The earth and moon rotate around one another in a lunar month that is roughly 29.5 days. As our observer at O rotates through exactly one day back to O the moon has moved about 12° further around in its orbit to the position marked “tomorrow”.The high tide that is under the moon will still be under the moon tomorrow, but it will be observed later in the observer’s day.. Since the earth spins on its axis at about 4 minutes per degree the tides will appear about 50 minutes later each day.</p>
<p>The next refinement is. If we observe both from the side, not the pole, moon is not directly over the equator. The moon can be found at various angles to the north and south of the equator up to a maximum of 35° depending on the season and the time of the lunar month. So the tide bulge is no longer on the equator. No our observer in O could observe two high tide and two low tides every day. But the high tides are unequal height, as are the low tides. This difference is called the diurnal (daily) inequality.</p>
<p>This model only consider the effect of moon,without continents Coriolis force and friction force. Such tide is called equilibrium tide and this theory is called The Equilibrium Theory of Tides or “static” theory of tides.</p>
<p>It cannot predict It cannot predict the tide at any particular location but it does explain some of the main features of the tide such as</p>
<ol type="1">
<li>diurnal variation</li>
<li>diurnal inequality in the height</li>
<li>daily delay</li>
</ol>
<p>The next improvement of equilibrium theory of tide is considering the effects of the earth-sun system on top of the effects of the earth–moon system.</p>
<p>The mass of the sun is 27 × 106 times the mass of the moon but its distance from the earth is 400 times that of the moon. Because of this great distance, the gravitational attraction on a particle of water on the earth due to the sun is about one-half that due to the moon. So we can construct diagrams like those shown in Figs. 7.03 and 7.04 for the tide due to the sun, but the height of the tide will be only half that due to the moon. The important effect of the tide due to the sun arises because its tidal bulge moves relative to the moon’s tidal bulge through- out the lunar month.</p>
<p>When the two tidal bulges coincide they add together to create the extra high tides called the spring tides. When the tidal bulges are opposed their effects tend to cancel one another, creating the neap tides. Thus, the equilibrium tide model can also qualitatively explain the fortnightly inequality in addition to the other effects.</p>
<h3 id="tides-in-the-real-ocean">Tides in the real ocean</h3>
<p>The next development of tide theory is dynamic theory of tide. It considered the continents, topography, Coriolis force and friction force, etc.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208170201.png"></p>
<p>This is the <strong>Laplace's tidal equations</strong>. But it is hard to solve. For prediction, one solution is that we can decompose the tide. We can think the real tide in our ocean is composed by a lot of tide constituents . Each tide constituents induced by each an imaginary planets. There are three main categories of constituents (Pond and Pickard 1983):</p>
<ol type="1">
<li>semi-diurnal, period about 12 hours</li>
<li>diurnal, period about 24 hours</li>
<li>long period, greater than 24 hours.</li>
</ol>
<p>The four most important constituents are:</p>
<ol type="1">
<li>The lunar semi-diurnal ,M2, Period=12.42h</li>
<li>The solar semi-diurnal, S2, Period=12.00h</li>
<li>The lunisolar diurnal, K1, Period=23.93h</li>
<li>The principal lunar diurnal, O1, period=25.82h</li>
</ol>
<p>The M2 constituent is roughly twice the amplitude of the other three.</p>
<p>In different location around the word, the relative importance of constituents is quite different. So we have different patterns of tides. The four main classifications of the form of the tides are illustrated in the next figure.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208172014.png"></p>
<p>The first one has two high tides and two low tides every day and Both the highs are about the same height and both the lows are about the same height. Such a tide is called a semi-diurnal in form because there are two per day and both are about the same height.In this case the semi-diurnal constituents dominate the diurnal ones. This fact is often quantified with the ratio F = (K1+O1)/(M2 + S2 ), where each letter stands for the amplitude of the constituent. If F is small (0.11), as in the upper record, the sum of the amplitudes of the diurnal constituents (K1+O1 ) is small relative to the sum of the semi-diurnal ones (M2+S2 ).</p>
<p>The four records in Fig. 7.05 show a marked decrease from top to bottom in the amplitude of the semi-diurnal tidal oscillation relative to the diurnal oscillation, which is confirmed by the increase in F from 0.11 to ~19. At San Francisco there are always two tides per day but they are usually of unequal amplitude. At Manila there are two tides per day during the neap tides but only one rise and fall per day during spring tides. At Do-Son there is only one rise and fall of the tide per day throughout the month, which is a purely diurnal form of tidal oscillation. This occurrence is the rarest form of tide. The changing form of the tide between locations is due partly to the shape of the ocean basin in which the tidal wave is contained and partly to the latitude (Hendershott 1981).</p>
<h3 id="moving-the-tidal-bulge-over-the-earth-kelvin-waves">Moving the tidal bulge over the earth: Kelvin waves</h3>
<p>The former one is more focus on the coast, if we focus on a more large scale, the water depth is almost the same and the friction from the topography could be ignored. More idealized, if we assume the coast line is straight, we could get One solution of former dynamic tide equation set is that the velocity of tide is</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208202646.png"></p>
<p>here g is Gravitational acceleration and k is the depth of the water. and the Kelvin wave is a reasonable approximation for tidal waves in the vicinity of a straight coastline.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208204932.png"></p>
<p>And here the Coriolis force is an important feature of the motion.</p>
<p>. The effect of the Coriolis force is to push the water to the right in the northern hemisphere</p>
<p>The Coriolis effect causes the amplitude of the wave to increase toward the shore and leads to the expression that the wave is “trapped” against the shore. Such a trapped Kelvin wave causes the water particles to move back and forth parallel to the coast as the wave goes by</p>
<p>The horizontal scale of the wave, or the approximate distance from the coast to where the sea level is undisturbed by the wave, is estimated by the Rossby radius.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200208205203.png"></p>
<p>For the Kelvin wave in Fig. 7.06 we put g = 10 m s−2 , h = 4000 m, and f= 10−4 s−1 to get Re = 2000 km. This value is commonly called the external Rossby radius, or deformation scale</p>
<h3 id="tidal-currents">Tidal currents</h3>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>book-reading-note3</title>
    <url>/posts/33f4c7b7.html</url>
    <content><![CDATA[<p>Chapter 8.3.2.-8.4.4 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<p>Good afternoon everyone, today I will talk two part. The first part is the from section three, the distribution of biological production in ocean basin. The second part is section four, biology of eddies and rings.</p>
<p>And in the first part, I'd like to add an additional story about Japanese eel.</p>
<h1 id="distribution-of-biological-production-in-ocean-basin">8.3 Distribution of biological production in ocean basin</h1>
<h2 id="eels-and-the-north-atlantic-gyre">8.3.2 Eels and the North Atlantic gyre</h2>
<p>Eel is a very important fishery species globally. Here I show And one of the very confusion problem about it ,In a long time, Fishermen never caught anything they could identify as a young eel. So where is the young eel? It is very important to find Find spawning area,Get egg for aquaculture and Establish fishing policy.</p>
<p>In 1922，Schmidt propose a Starling theory about eel, contain three part</p>
<p>•Two species in the North Atlantic: European eel and America eel</p>
<p>•Morphological change when grow up</p>
<p>•Both spawning in Sargasso Sea</p>
<p>The fisrt part is confirmed by various research such as the difference in Muscle blocks</p>
<p>,Vertebrae,Parasite,mtDNA. The second one also.</p>
<p>The most difficult part to prove last part. If they both saw in the Sargasso Sea, how can they travel such long distance as a larvae? One answer that easily to think is by basin current. But American eel only live in the side of American, European eel only live in the side of European. So the next question is why they come to different region with same current?</p>
<p>So let us open the mystery of American eel first. It is based one research about larvae distribuiton.</p>
<p>The American eel always spawns from mid Februrary to April. After spawning, they will enter the Gulf Stream in a growth rate about 0.24 millimetre per day from February to October. Some part might enter Antilles Current or Caribbean Current. But they will finnally enter gulf stream by Apr.</p>
<p>Then we can notice the distribution of most abundant larvae in the coastal. The time is not spawning season. So after spawning, the larvae will move north first, then come back south. Base one this observation, the author conclude that the larvae will Larvae actively migrate westword out of Gulf Stream. And in the north boundary, the larvae will be Carried southward passively by Larador Current and Slope water.</p>
<p>Anothe research base on the age also support the trend of southward movement of larvae. So as a result , the American eel will be Tapped in America by self movement and current, instead of going to European.</p>
<p>So obviously, the European eel larvae will not move out Gulf Stream, then it will enter North Atlantic Current and takes one or two years to reach European. In the end, they will back to Sagarsso Sea by Canary Current and North Equatorial Current.</p>
<p>In 1980s, a drastic decline in the catch of both America and European eel occurred. The solid line is the catch in Nervertheland,represent European eel. And the dotted line is the catch in Canada, represented the Catch of European eel. The Polution and habitat destruction may affect , but could not produce such big decline. A more probable reason is the ocean-scale change. One is the Slowing of Gulf Stream. As a result, the larvae will miss the best time to metaphose, and will be hunted by other species. Another one is there are more More warm core rings created by Gulf Stream, which could bring larvae out of Gulf Stream.</p>
<h2 id="salmon-and-the-alaskan-gyre">8.3.3 Salmon and the Alaskan gyre</h2>
<p>Another speices talked here is salmon fish. Unlike eel, it will spawn in fresh water and feed and grows in the sea. It's full migration pattern is known untill 1960. Here we will talke about two species, pink salmon and sockeye salmon. These are the two most productive types of salmon.</p>
<p>For the pink salmon, it usually</p>
<ul>
<li>Spawn in rive from mid-Jul. to mid-Oct</li>
<li>•Migrate out to the ocean between Jul. and Sep. in one year old</li>
<li>•Travel between 5500km and 7500km with Alaskan Gyre in one year</li>
<li>•Move north and west in summer, travel and feed along the coast</li>
<li>•Move 10° south into west-wind drift in winter</li>
<li>•Come back to parent river to spawn at two years old</li>
</ul>
<p>So it will Travel with Alaskan Gyre for one year with one circuits.</p>
<p>For the sockeye salmon, it usually</p>
<p>•Stay one or two winters in fresh water</p>
<p>•Stay two years in the sea, travle two circuits Alaskan Gyre from British Columbia</p>
<p>•Stay three years in the sea, one circle in Bering Gyre and two circuits in Alaskan Gyre from river on the shore of Bering Sea</p>
<p>So it will Travel with Alaskan Gyre for two year(additional year with Bering Gyre) with two (three) circuits.</p>
<h2 id="transport-of-invertebrate-larvae-across-ocean-basin">8.3.4 Transport of invertebrate larvae across ocean basin</h2>
<p>Besides fish, the larvae of invertebrate also could be transported. The fisrt evident is founded by Scheltema. He found the larvae of gastropod throughout Gulf Stream and North Atalantic Current. And he kept larvae alive in lab longer than necessary for transtport.</p>
<p>Both proof that Invertebrate larvae could be transported across ocean basins .</p>
<h1 id="biology-of-eddies-and-rings-associated-with-major-currents">8.4 Biology of eddies and rings associated with major currents</h1>
<p>The next session is about the biology of eddies and rings associated with major current.Include four part.</p>
<p>•Gulf Stream frontal eddies</p>
<p>•Formation of Gulf Stream rings</p>
<p>•Ecology of cold-core rings</p>
<p>•Ecology of warm-core rings</p>
<h2 id="gulf-stream-frontal-eddies">8.4.1 Gulf Stream frontal eddies</h2>
<p>The first one is about Gulf stream frontal eddies.</p>
<p>•Usually occur when the distance between Gulf Stream and coast is great.</p>
<p>•Finger like extention from Gulf Stream</p>
<p>•A new one formed every two weeks on average in the south of Cap Hatteras</p>
<p>•Introduce about 55,000 tons of nitrogen annually to the outer shelf(Lee, 1981)</p>
<p>•Breeding center for some species such as blue fish</p>
<h2 id="formation-of-gulf-stream-rings">8.4.2 Formation of Gulf Stream rings</h2>
<p>About the ring.</p>
<p>The ring will occur if the meander of Gulf Stream become too large.</p>
<p>•Every one or two month create a ring in the North of Cap Hatters</p>
<p>•Cold core ring in the south and warm core in the north</p>
<p>•Move southwesterly about 3-5km per day</p>
<h2 id="ecology-of-cold-core-rings">8.4.3 Ecology of cold-core rings</h2>
<p>Regarding the ecology of cold-core rings. Here is the verticle profile of a cold-core ring. The line is the isotherms.</p>
<p>Compared with Sargasso Sea, it contains Larger concentration of plankton, nekton and nutrient from continent shelf.</p>
<p>The Counter-clockwise rotation lead to upwelling in the center and •Bring nutrient-enriched water into the euphotic zone.</p>
<p>As a result, it is more productive than surrounding water.</p>
<p>Another feature of a cold-core ring is that Biological characteristcs change rapidlly than physical characteristics.</p>
<p>The chlorophyll-a in a cold coring is much higher in April, but will Declined eight times in August.</p>
<p>The phytoplankton species will become smaller and diversity will becom greater with time, more like the surrounding waters.</p>
<p>As for the zooplankton, the original zooplankton could not be found in a 17-month-old ring.</p>
<p>And the larvae and mesopelagic fish will also become more like surrouding water in Sargasso Sea with time.</p>
<p>I found some satellite image from NOAA. The left is the SST and chlorophyll-a in MARCH 2019, the right is in April. In the SST, we could find the cold -core ring in the red square in both image. But in the Chla. we can see some difference between cold core ring and Sargasso Sea in March. In April, we could barely see that.</p>
<p>This also indicate that Biological characteristcs change rapidlly than physical characteristics.</p>
<h2 id="ecology-of-warm-core-rings">8.4.4 Ecology of warm-core rings</h2>
<p>Warm-core ring is in clockwise circulation and will cause downwelling at the center. It lacks nutrient in the center.</p>
<p>Usually, we will think it is Biological unproductive.</p>
<p>But the fact is that it productivity is not very different from surronding water.</p>
<p>It has two enhance mechanisms</p>
<p>•Upwelling the nutrient-rich water in the thermostad (deep mix layer) to the periphery</p>
<p>•Convective mixing caused by surface water as move north</p>
<p>As for the species in the warm core rings.</p>
<p>The biomass of mesozooplankton is low and will increase by time.</p>
<p>The nonmigratory mesopelagic fish and siponiphores do not have significant change in the warm-core rings.</p>
<p>And the warm-core rings in the eastern boundaries of Gulf Stream is preferred by sperm whales.</p>
<p>The warm-core ring contacts with the continetal shelf usually. Because it is in clockwise, it will drag cold water from shelf by rotation movement to northern side and enhance poductivity.</p>
<p>These two figure is about the chla in the Georges bank, the red square is the area of georges bank. And here is a cold core ring. We can see that the chl-a is clearly enhanced by the offshore movement of shelf water, which accompanied by vigorous upwelling and vertical mixing.</p>
<p>And it will also drag cold water from shelf by rotation movement to offshore</p>
<p>This will bring larvae of sand lance, and larvae and juvenile of white hake offshore, which could •Result in the loss of population</p>
<p>As estimated, Increased warm-core activity was associated with reduced recruitment in 15 commercial species.</p>
<p>Besides, it will also bing •Warm water onto the shelf on the western and sourthern side of rings. This will make Tropical and subtropical fish larvae is founded in the high latitude .</p>
<p>In summary</p>
<ul>
<li>•Eel and salmon is transported by gyre to finish life histroy</li>
<li>•Basin-scale change may affect theire population</li>
<li>•Interterbrates also could be transport across ocean basin</li>
<li>•Frontal eddies could enhance productivity and is breeding center for some species</li>
<li>The cold core ring and warm core ring have different ecology effect as in this table</li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>cartopy</title>
    <url>/posts/c6b8edee.html</url>
    <content><![CDATA[<p>Basemap在2020年底停止维护，取而代之的是cartopy，在这里写一下一些学习笔记。</p>
<p>先说结论，截止到2020年8月1日,0.18版本仍然不能完全取代basemap，尤其是近岸数据分辨率的问题，但是已经展现出优势了，自己要在之后多多尝试使用。</p>
<a id="more"></a>
<h1 id="代码范例">代码范例</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> netCDF4 <span class="keyword">as</span> nc</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> cartopy.crs <span class="keyword">as</span> ccrs</span><br><span class="line"><span class="keyword">import</span> cartopy.feature <span class="keyword">as</span> cfeature</span><br><span class="line"><span class="keyword">from</span> cartopy.mpl.gridliner <span class="keyword">import</span> LONGITUDE_FORMATTER, LATITUDE_FORMATTER</span><br><span class="line">file=<span class="string">r&#x27;I:\Nagoya University\Project\Seto\MODIS\20100608T04.nc&#x27;</span></span><br><span class="line">nc=nc.Dataset(file,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">lon=nc.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;longitude&#x27;</span>][:]</span><br><span class="line">lat=nc.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;latitude&#x27;</span>][:]</span><br><span class="line">variables=nc.groups[<span class="string">&#x27;geophysical_data&#x27;</span>].variables</span><br><span class="line">chl=variables[<span class="string">&#x27;chlor_a&#x27;</span>]</span><br><span class="line">minlat = <span class="number">32.5</span></span><br><span class="line">minlon = <span class="number">130.5</span></span><br><span class="line">maxlat = <span class="number">35</span></span><br><span class="line">maxlon = <span class="number">136</span></span><br><span class="line">f = plt.figure(figsize=(<span class="number">20</span>, <span class="number">20</span>), dpi=<span class="number">300</span>)</span><br><span class="line">m = plt.axes(projection=ccrs.PlateCarree(central_longitude=<span class="number">0.0</span>))</span><br><span class="line">f = plt.pcolormesh(lon, lat,chl, shading=<span class="string">&#x27;flat&#x27;</span>, vmin=np.log10(<span class="number">0.01</span>), vmax=np.log10(<span class="number">50</span>), cmap=plt.cm.viridis)</span><br><span class="line">m.coastlines(resolution=<span class="string">&#x27;10m&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">extent=[<span class="number">130.5</span>,<span class="number">136</span>,<span class="number">32</span>,<span class="number">35</span>]</span><br><span class="line">m.set_extent(extent)</span><br><span class="line">m.add_feature(cfeature.RIVERS)</span><br><span class="line">m.add_feature(cfeature.COASTLINE.with_scale(<span class="string">&#x27;10m&#x27;</span>))</span><br><span class="line">m.add_feature(cfeature.LAND.with_scale(<span class="string">&#x27;10m&#x27;</span>), facecolor=<span class="string">&#x27;0.75&#x27;</span>)</span><br><span class="line"></span><br><span class="line">g1 = m.gridlines(draw_labels = <span class="literal">True</span>)</span><br><span class="line">g1.xlabels_top = <span class="literal">False</span></span><br><span class="line">g1.xlabel_style = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">g1.ylabel_style = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;gray&#x27;</span>&#125;</span><br><span class="line">g1.xformatter = LONGITUDE_FORMATTER</span><br><span class="line">g1.yformatter = LATITUDE_FORMATTER</span><br><span class="line">cbar = plt.colorbar(f, orientation=<span class="string">&quot;horizontal&quot;</span>, fraction=<span class="number">0.05</span>, pad=<span class="number">0.07</span>, ticks=[np.log10(<span class="number">0.01</span>), np.log10(<span class="number">0.1</span>),np.log10(<span class="number">0.5</span>), np.log10(<span class="number">1</span>),np.log10(<span class="number">3</span>),np.log10(<span class="number">10</span>),np.log10(<span class="number">50</span>)]) </span><br><span class="line">cbar.ax.set_xticklabels([<span class="string">&#x27;0.01&#x27;</span>,<span class="string">&#x27;0.1&#x27;</span>,<span class="string">&#x27;0.5&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;3&#x27;</span>,<span class="string">&#x27;10&#x27;</span>,<span class="string">&#x27;50&#x27;</span>], fontsize=<span class="number">20</span>) </span><br><span class="line">cbar.set_label(<span class="string">&#x27;Chlorophyll, mg m$^&#123;-3&#125;$&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;MODIS [Chl a] mg m$^&#123;-3&#125;$&#x27;</span>, fontsize=<span class="number">20</span>);</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>相比basemap这个方便很多，但是分辨率还是有一点问题。</p>
<h1 id="一些参考资料">一些参考资料</h1>
<p>https://zhajiman.github.io/post/cartopy_introduction/</p>
<p>https://scitools.org.uk/cartopy/docs/latest/index.html</p>
<p>https://www.net-analysis.com/blog/cartopylayout.html</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello Gridea</title>
    <url>/posts/6143bcfc.html</url>
    <content><![CDATA[<p>👏 欢迎使用 <strong>Gridea</strong> ！<br>
✍️ <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<a id="more"></a>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dldGdyaWRlYS9ncmlkZWE=">Github<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cHM6Ly9ncmlkZWEuZGV2Lw==">Gridea 主页<i class="fa fa-external-link-alt"></i></span><br>
<span class="exturl" data-url="aHR0cDovL2ZlaGV5LmNvbS8=">示例网站<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="特性">特性👇</h2>
<p>📝 你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️ 你可以对文章进行标签分组</p>
<p>📋 你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻 你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎 你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬 你可以进行简单的配置，接入 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dpdGFsay9naXRhbGs=">Gitalk<i class="fa fa-external-link-alt"></i></span> 或 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1N1a2thVy9EaXNxdXNKUw==">DisqusJS<i class="fa fa-external-link-alt"></i></span> 评论系统</p>
<p>🇬🇧 你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
      <tags>
        <tag>Gridea</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows环境下hexo博客搭建</title>
    <url>/posts/b1f5683b.html</url>
    <content><![CDATA[<p>自己算来算去都搭建了三次博客了，前两次是在ubuntu上，第二次在ubuntu搭建的时候花费了好多时间解决node.js和npm的问题，索性这次就在windows上了，虽然windows的命令行用着很蛋疼，但是架不住方便啊。赶紧把博客搭出来写文章才是最主要的。</p>
<a id="more"></a>
<p>每次搭建都得花好多时间搜集资料贴，这次索性把资料贴整理出来，免得自己下次再去到处找。</p>
<h2 id="博客生成">博客生成</h2>
<h3 id="入门">入门</h3>
<p>Github Pages可以被认为是用户编写的、托管在github上的静态网页。使用Github Pages可以为你提供一个免费的服务器，免去了自己搭建服务器和写数据库的麻烦。此外还可以绑定自己的域名。因此，我们需要去<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==">github官网<i class="fa fa-external-link-alt"></i></span>注册一个账号。</p>
<p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<h3 id="安装环境">安装环境</h3>
<p>1.安装<span class="exturl" data-url="aHR0cHM6Ly9naXQtc2NtLmNvbS8=">git<i class="fa fa-external-link-alt"></i></span></p>
<p>2.安装<span class="exturl" data-url="aHR0cHM6Ly9ub2RlanMub3JnL2VuLw==">node.js<i class="fa fa-external-link-alt"></i></span></p>
<p>以上两步对于windows用户来说非常友好了，按照默认来装就可以了。</p>
<p>3.安装hexo</p>
<p>右键呼出git bash。输入： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br><span class="line">npm install hexo-deployer-git --save </span><br></pre></td></tr></table></figure> 然后输入<code>hexo -v</code> 出现一系列版本号就是安装成功了，像我这样 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo -v</span><br><span class="line">hexo: 3.8.0</span><br><span class="line">hexo-cli: 1.1.0</span><br><span class="line">os: Windows_NT 10.0.17763 win32 x64</span><br><span class="line">http_parser: 2.8.0</span><br><span class="line">node: 10.15.3</span><br><span class="line">v8: 6.8.275.32-node.51</span><br><span class="line">uv: 1.23.2</span><br><span class="line">zlib: 1.2.11</span><br><span class="line">ares: 1.15.0</span><br><span class="line">modules: 64</span><br><span class="line">nghttp2: 1.34.0</span><br><span class="line">napi: 3</span><br><span class="line">openssl: 1.1.0j</span><br><span class="line">icu: 62.1</span><br><span class="line">unicode: 11.0</span><br><span class="line">cldr: 33.1</span><br><span class="line">tz: 2018e`</span><br></pre></td></tr></table></figure> 如果不成功的话可以同时按下win和R，输入cmd,分别使用如下三个命令，如果有一个没有返回版本信息则说明这个软件装失败。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git --version</span><br><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure> ### 生成博客 从现在开始，你在windows和ubuntu下的操作几乎一样了。在网上搜帖子的时候如果是ubuntu系统下的解决方案也可以尝试在windows下解决。</p>
<p>新建文件夹，例如我的文件夹为： I。博客相关文件将储存在此文件夹下。右键呼出gitbash。输入以下命令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init</span><br></pre></td></tr></table></figure> 如果最后出现 &gt;Start blogging with Hexo!</p>
<p>则说明生成成功。</p>
<p>执行以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure> 显示以下信息说明操作成功 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure> 执行完可以登录http://localhost:4000/ 查看效果。 ## 博客部署 到目前为止，我们只能通过本地连接查看博客，接下来我们需要把他部署在github pages上。来，让我们登录我们上一步申请的账号。 ### 创建项目代码库 点击 New 创建一个代码库。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/resp.png"></p>
<p>在这里需要注意仓库名必须是 用户名.github.io的形式（我这里因为已经申请了所以显示无法创建）。最后记得勾选初始化readme文件。</p>
<h3 id="配置ssh密钥">配置ssh密钥</h3>
<p>配置好SSH密钥之后，才可以通过git实现本地代码库与github代码库同步。右键唤出gitbash进入你新建的文件夹（例如我的是I:)，输入以下命令： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C <span class="string">&quot;your email@example.com&quot;</span> </span><br><span class="line"> //引号里面填写你的邮箱地址，比如我的是zhouthepassion@outlook.com</span><br></pre></td></tr></table></figure> 之后会出现： <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Generating public/private rsa key pair.  </span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/c/Users/you/.ssh/id_rsa):  </span><br><span class="line">//到这里可以直接回车将密钥按默认文件进行存储</span><br></pre></td></tr></table></figure> 然后会出现 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase):  </span><br><span class="line">//这里是要你输入密码，其实不需要输什么密码，直接回车就行 </span><br><span class="line">Enter same passphrase again: </span><br></pre></td></tr></table></figure> 接下来屏幕会显示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Your identification has been saved <span class="keyword">in</span> /c/Users/you/.ssh/id_rsa.  </span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /c/Users/you/.ssh/id_rsa.pub.  </span><br><span class="line">The key fingerprint is:  </span><br><span class="line">这里是各种字母数字组成的字符串，结尾是你的邮箱  </span><br><span class="line">The key<span class="string">&#x27;s randomart image is:  </span></span><br><span class="line"><span class="string">这里也是各种字母数字符号组成的字符串 </span></span><br></pre></td></tr></table></figure>
<p>运行以下命令,将公钥的内容复制粘贴到系统粘贴板上。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ clip &lt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure> ### 在github账户中添加你的公钥 点击你的github头像，进入settings，点击SSH and GPG Keys，选择New SSH key，然后把你刚才复制的公填在key那里就可以了，title可以随便填，最后点击下面的add ssh key。 ### 测试 输入以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure> 之后会显示 &gt;Are you sure you want to continue connecting(yes/no)? &gt;</p>
<p>输入yes后显示 &gt;Hi,XXXXX!You've successfully authenticated, but GitHub does not provide shell access. &gt;</p>
<p>表示设置正确。 ### 配置Git个人信息 这一步相当于赋予你的电脑连接到github的权限。输入以下命令 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name <span class="string">&quot;此处填你的用户名&quot;</span>  </span><br><span class="line">$ git config --global user.email  <span class="string">&quot;此处填你的邮箱&quot;</span></span><br></pre></td></tr></table></figure> 到此为止SSH Key配置成功 ## 将本地hexo文件更新到GitHub仓库中 打开创建的文件夹，打开_config.yml文件（这里推荐使用Notepad++）</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/deploy.png"></p>
<p>拉到最后，修改deploy的属性 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  </span><br><span class="line">  repo: git@github.com:username/username.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure> 其中username改为你的用户名。注意冒号之后必须空一个英文空格。 在创建的文件夹中分别执行以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo g  </span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<p>或者直接 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure> 执行完之后会让你输入你的Github账号和密码。如果显示以下错误，说明你的deployer没有安装成功。 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ERROR Deployer not found: git</span><br></pre></td></tr></table></figure> 那就执行以下命令再安装一次: <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure> 再执行<code>hexo g -d</code>，你的博客就会部署到github上了。你的网址就是https://username.github.io ## 在博客上发表文章</p>
<ol type="1">
<li><p>新建文章</p>
<p>新建一个空文章，输入以下命令，会在项目 _posts 中生成 文章标题.md 文件，文章标题根据需要命名</p></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo n <span class="string">&quot;文章标题&quot;</span></span><br><span class="line">More info: [Writing](https://hexo.io/docs/writing.html)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li><p>编辑文章</p>
<p>Markdown 是 2004 年由 John Gruberis 设计和开发的纯文本格式的语法，非常的简单实用，常用的标记符号屈指可数，几分钟即可学会， .md 文件可以使用支持 Markdown 语法的编辑器编辑，我这里使用的是typora来编辑，对于初学者十分友好。这里贴出一个Markdown格式的<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8xZTQwMjkyMmVlMzI=">语法指南<i class="fa fa-external-link-alt"></i></span></p></li>
<li><p>发布文章</p>
<p>文章写好后，可以使用如下命令发布</p></li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo g  </span><br><span class="line">$ hexo d</span><br></pre></td></tr></table></figure>
<p>或者直接 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure></p>
<p>然后就可以在刚才的网址里面看到你写的文章了</p>
<h2 id="参考资料">参考资料</h2>
<p>搭建：https://blog.csdn.net/qq_36759224/article/details/82121420</p>
<!--


乱码解决：https://blog.csdn.net/Aoman_Hao/article/details/79275570

;实用：https://blog.csdn.net/qq_36759224/article/details/85010191

;美化：https://blog.csdn.net/qq_36759224/article/details/85420403

;常见错误：http://www.aichengxu.com/other/2538446.htm

;next配置：http://theme-next.iissnan.com/theme-settings.htm

;关于页面：https://www.jianshu.com/p/7667d8e8f91c

;英文标签改中文改前面就行

;https://blog.csdn.net/qq_32337109/article/details/78755729只展示一部分;
;https://blog.csdn.net/lewky_liu/article/details/81277337



;gitalkhttps://asdfv1929.github.io/2018/01/20/gitalk/

;issue:https://liujunzhou.top/2018/8/10/gitalk-error/#%E6%9C%AA%E6%89%BE%E5%88%B0%E7%9B%B8%E5%85%B3%E7%9A%84Issues%E8%BF%9B%E8%A1%8C%E8%AF%84%E8%AE%BA%EF%BC%8C%E8%AF%B7%E8%81%94%E7%B3%BBXXX%E8%BF%9B%E8%A1%8C%E5%88%9B%E5%BB%BA

;分析https://marketingplatform.google.com/about/analytics/

;https://www.cnblogs.com/tengj/p/5357879.html

;```text
tags: [标签1,标签2,标签3]

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">;http:&#x2F;&#x2F;cnneillee.github.io&#x2F;2017&#x2F;05&#x2F;10&#x2F;hexo&#x2F;Hexo%E8%BF%9B%E9%98%B6%E2%80%94%E2%80%94%E6%B7%BB%E5%8A%A0%E7%AB%99%E7%82%B9%E5%9C%B0%E5%9B%BE&#x2F;</span><br><span class="line"></span><br><span class="line">;sitemap</span><br><span class="line"></span><br><span class="line">;提交http:&#x2F;&#x2F;fionat.github.io&#x2F;blog&#x2F;2013&#x2F;10&#x2F;23&#x2F;sitemap&#x2F;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">;https:&#x2F;&#x2F;alanlee.fun&#x2F;2017&#x2F;12&#x2F;30&#x2F;google-sitemap&#x2F;</span><br><span class="line"></span><br><span class="line">;https:&#x2F;&#x2F;www.jianshu.com&#x2F;p&#x2F;efbeddc5eb19</span><br><span class="line">;备份</span><br><span class="line">https:&#x2F;&#x2F;www.simon96.online&#x2F;2018&#x2F;10&#x2F;12&#x2F;hexo-tutorial&#x2F;</span><br></pre></td></tr></table></figure>
<p>RSS：https://segmentfault.com/a/1190000012647294</p>
<p>https://mritd.me/2016/03/08/Hexo%E6%B7%BB%E5%8A%A0Rss%E8%AE%A2%E9%98%85/</p>
<p>leancloud:https://lfwen.site/2016/05/31/add-count-for-hexo-next/</p>
<p>https://lruihao.cn/hexo/hexo-%E6%B7%BB%E5%8A%A0%E5%9B%BE%E7%89%87%EF%BC%8C%E9%9F%B3%E4%B9%90%EF%BC%8C%E9%93%BE%E6%8E%A5%EF%BC%8C%E8%A7%86%E9%A2%91.html 网易云 图片 视频</p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC8yNzU2NzI0YTVkZWU=">https://www.jianshu.com/p/2756724a5dee<i class="fa fa-external-link-alt"></i></span>图片问题终于解决了</p>
<p>百度推广https://www.jianshu.com/p/8c0707ce5da4</p>
<p>RSS<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEzMDM0NDMvYXJ0aWNsZS9kZXRhaWxzLzUyMzMzNjk1">https://blog.csdn.net/u011303443/article/details/52333695<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLnRhbmd4aWFvemh1LmNvbS8xNTI1MDkyMjMyOTczMy5odG1s">https://blog.tangxiaozhu.com/15250922329733.html<i class="fa fa-external-link-alt"></i></span>深度定制</p>
<p><span class="exturl" data-url="aHR0cDovL2xpdXFp5pel5Y6G5LqRbmd3ZW4ubWUvYmxvZy8yMDE4LzEwLzI2L3NoYXJlLWEtY3V0ZS1oZXhvLWJsb2ctcGx1Z2luLXRoZS1jbG91ZC1jYWxlbmRhci8=">http://liuqi日历云ngwen.me/blog/2018/10/26/share-a-cute-hexo-blog-plugin-the-cloud-calendar/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly90YW5rZXJ5YW5nLmdpdGh1Yi5pby9wb3N0cy9IZXhvJTIwKyUyME5leFQlMjArJTIwR2l0aHViJTIwUGFnZXMlMjArJTIwQ29kaW5nJTIwUGFnZXMlMjArJTIwR2l0ZWUlMjBQYWdlcyUyMCslMjBUcmF2aXMlMjDlhajmlLvnlaUv">https://tankeryang.github.io/posts/Hexo%20+%20NexT%20+%20Github%20Pages%20+%20Coding%20Pages%20+%20Gitee%20Pages%20+%20Travis%20%E5%85%A8%E6%94%BB%E7%95%A5/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9zZXNwcmllLmJpZC9hcnRpY2xlcy8yMS5odG1s">https://sesprie.bid/articles/21.html<i class="fa fa-external-link-alt"></i></span>进度条</p>
<p>自己要好好想想怎么实现follow效果</p>
<p>升级<span class="exturl" data-url="aHR0cHM6Ly8xMS50dC9wb3N0cy8yMDE4L2hvdy10by11cGRhdGUtaGV4by10aGVtZS1uZXh0Lw==">https://11.tt/posts/2018/how-to-update-hexo-theme-next/<i class="fa fa-external-link-alt"></i></span></p>
<p>后面这些还有</p>
<p><span class="exturl" data-url="aHR0cHM6Ly9qdWVqaW4uaW0vcG9zdC81Y2FkZGQxZmYyNjVkYTAzNWUyMTBkY2UjaGVhZGluZy00OQ==">https://juejin.im/post/5caddd1ff265da035e210dce#heading-49<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9lMjExZTkxMTk1MjI=">https://www.jianshu.com/p/e211e9119522<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly93aGprbS5naXRodWIuaW8vMjAxOC8wNy8xNy9IZXhv54mI5pys5Y2H57qn5ZKMTmV4dOS4u+mimOWNh+e6p+S5i+WdkS8=">https://whjkm.github.io/2018/07/17/Hexo%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E5%92%8CNext%E4%B8%BB%E9%A2%98%E5%8D%87%E7%BA%A7%E4%B9%8B%E5%9D%91/<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RoZW1lLW5leHQvaGV4by10aGVtZS1uZXh0L2Jsb2IvbWFzdGVyL2RvY3MvemgtQ04vVVBEQVRFLUZST00tNS4xLlgubWQ=">https://github.com/theme-next/hexo-theme-next/blob/master/docs/zh-CN/UPDATE-FROM-5.1.X.md<i class="fa fa-external-link-alt"></i></span></p>
<p>hexo-wordcounthttps://github.com/theme-next/hexo-symbols-count-time</p>
<p>代码复制</p>
<p>--&gt;</p>
-->]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title>kriging</title>
    <url>/posts/f4af350.html</url>
    <content><![CDATA[<p>Ordinary Kriging</p>
<p>Poisson Kriging-Area to Area</p>
<p>Poisson Kriging-Area to Point</p>
<p>These are the three types inside https://github.com/szymon-datalions/pyinterpolate</p>
<p>I also wan to show how to apply them to satellite image as an practice for APTRK</p>
<a id="more"></a>
<h1 id="general-introduction">General Introduction</h1>
<p>Reference: https://www.youtube.com/watch?v=J-IB4_QL7Oc</p>
<h2 id="problem-setup">Problem Setup</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022110419095.png"></p>
<p>Here we have a island and we take some measurement for some red points. Each point include two attributes. <span class="math inline">\(x_i\)</span> is the location and <span class="math inline">\(y_i\)</span> is the thing we are interested in, like elevation.</p>
<p>Now we want to get the elevation in some other point that we did not explicitly collect data. For example in this black dot.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022110833500.png"></p>
<p>So we just could use the data we have to predict the elevation of black dot. There are five closest red dots to this unknown dot. We are gonna to use these five dots to predict the unknown dots. <span class="math display">\[
y_{new}=w^Ty+\epsilon_{new}\\
=w_1y_1+w_2y_2+...+w_5y_5+\epsilon_{new}
\]</span> This is a linear combination weight of neighbor dots. This is the kirging model. So the important thing is to know the <span class="math inline">\(w\)</span> .</p>
<h2 id="variogram">Variogram</h2>
<p>A general idea is that the closer one should have higher weigh. But how do I formalize this idea in math? Here the things determines the weight is called the variogram. <span class="math display">\[
\gamma(x_i,x_j)=\frac{1}{2}(y_i-y_j)^2
\]</span> This is the equation of variogram. <span class="math inline">\((x_i,x_j)\)</span> indicate the distance between two points. The distance is the input of <span class="math inline">\(\gamma\)</span> function. And the output of <span class="math inline">\(\gamma\)</span> function is half the difference of elevation. It should be increasing function since the smaller distance, the smaller difference.</p>
<p>So lets plot the graph between H, the distance <span class="math inline">\((x_i,x_j)\)</span> and the output of <span class="math inline">\(\gamma\)</span> function.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022142200533.png"></p>
<p>This graph should reach the plateau as H increase. Because if the distance is two large, the difference should be almost the same, which indicate that the elevation belong to different group.</p>
<p>There are some terminology here. First is the nugget. The nugget is the intercept that our graph begin. It should be not equal to zero. Because the variogram is a fit line and maybe we have a lot of closed dot with different elevation. But it shoul be small.</p>
<p>Second one is the sill. Sill is the silling of a variogram. And the he range is the H value of sill.</p>
<h2 id="solving-model">Solving model</h2>
<p>So we can get the weight from the variogram by solving a matrix equation.</p>
<p><span class="math inline">\(Aw=b\)</span></p>
<p>Here A is the <span class="math inline">\(\gamma(x_i,x_j)\)</span> and b is the <span class="math inline">\(\gamma(x_{new},x_i)\)</span>, <span class="math inline">\(w\)</span> is the vector from <span class="math inline">\(w_1\)</span> to<span class="math inline">\(w_5\)</span></p>
<p>So I can just take a inverse to get the <span class="math inline">\(w\)</span>.</p>
<h2 id="several-assumpution">Several Assumpution</h2>
<ol type="1">
<li>Stationarity: In every small part of island, the change speed of elevation should be almost the same.</li>
<li>Constant variogram. In every small part of the island, the variogram shoul be almost the same.</li>
</ol>
<h2 id="pros-and-cons">Pros and Cons</h2>
<p>Pros: we can estimate the error</p>
<p>Cons: For every new point, we need to solve different equation matrix.</p>
<h1 id="ordinary-kriging">Ordinary Kriging</h1>
<p>Refference: Olea R A. Geostatistics for engineers and earth scientists[M]. Springer Science &amp; Business Media, 2012.</p>
<p>The kriging model we describe before is the ordinary kriging. Kriging covers a range of least-squares methods of spatial prediction.</p>
<ul>
<li>􏰀 Ordinary kriging of a single variable, as described in Section 8.2, is the most robust method and the one most used.</li>
<li>􏰀 Simple kriging (Section 8.9) is rather little used as it stands because we usually do not know the mean. It finds application in other forms such as indicator and disjunctive kriging in which the data are transformed to have known means.</li>
<li>􏰀 Lognormal kriging (Section 8.10) is ordinary kriging of the logarithms of the measured values. It is used for strongly positively skewed data that approximate a lognormal distribution.</li>
<li>􏰀 Kriging with drift (Chapter 9), also known as universal kriging, recognizes both non-stationary deterministic and random components in a variable, estimates the trend in the former and the variogram of the latter, and recombines the two for prediction. This introduces residual maximum likelihood into the kriging procedure (see Section 9.2).</li>
<li>􏰀 Factorial kriging or kriging analysis (Chapter 9) is of particular value where the variation is nested, i.e. more than one scale of variation is present. Factorial kriging estimates the individual components of variation sepa- rately, but in a single analysis.</li>
<li>􏰀 Ordinary cokriging (Chapter 10) is the extension of ordinary kriging of a single variable to two or more variables. There must be some coregionaliza- tion among the variables for it to be profitable. It is particularly useful if some property that can be measured cheaply at many sites is spatially correlated with one or more others that are expensive to measure and are measured at many fewer sites. It enables us to estimate the more sparsely sampled property with more precision by cokriging using the spatial information from the more intensely measured one.</li>
<li>􏰀 Indicator kriging (see Chapter 11) is a non-linear, non-parametric form of kriging in which continuous variables are converted to binary ones (indicators). It is becoming popular because it can handle distribu- tions of almost any kind, and empirical cumulative distributions of estimates can be computed and thereby provide confidence limits on them. It can also accommodate ‘soft’ qualitative information to improve prediction.</li>
<li>􏰀 Disjunctive kriging (see Chapter 11) is also a non-linear method of kriging, but it is strictly parametric. It is valuable for decision-making because the probabilities of exceeding or not exceeding a predefined threshold are determined in addition to the kriged estimates.</li>
<li>􏰀 Probability kriging (not described further in this book) was proposed by Sullivan (1984) because indicator kriging does not take into account the proximity of a value to the threshold, but only its position. It uses the rank order for each value, zðxÞ, normalized to 1 as the secondary variable to estimate the indicator by cokriging. Chile`s and Delfiner (1999) and Goo- vaerts (1997) describe the method briefly.</li>
<li>􏰀 Bayesian kriging (not described further in this book) was introduced by Omre (1987) for situations in which there is some prior knowledge about the drift. It is intermediate between simple kriging, used when there is no drift, and universal kriging where there is known to be drift. The kriging equations are those of simple kriging, but with non-stationary covariances (Chile`s and Delfiner, 1999).</li>
</ul>
<p>Here I just gonna to talk about the three kinds of kriging model. For further you can just find that textbook.</p>
<p>But before we talk more deeply about that two type. Lets write the former introduction more detailed.</p>
<h2 id="theory-of-ordinary-kriging">THEORY OF ORDINARY KRIGING</h2>
<p>The aim of kriging is to estimate the value of a random variable,<span class="math inline">\(Z\)</span>, at one or more unsampled points or over larger blocks, from more or less sparse sample data on a given support, say <span class="math inline">\(z(\boldsymbol{x}_1),z(\boldsymbol{x}_2),...,z(\boldsymbol{x}_N)\)</span>, at points <span class="math inline">\(\boldsymbol{x}_1,\boldsymbol{x}_2,...,\boldsymbol{x}_N\)</span>. The data may be distributed in one, two or three dimensions, though applications in the environmental sciences are usually two-dimensional.</p>
<p>Ordinary kriging is by far the most common type of kriging in practice,and for this reason we focus on its theory here. It is based on the assumption that we do not know the mean. If we consider punctual estimation first, then we estimate <span class="math inline">\(Z\)</span> at a point <span class="math inline">\(\boldsymbol{x}_0\)</span>by <span class="math inline">\(\hat{Z}(\boldsymbol{x}_0)\)</span>, with the same support as the data, by <span class="math display">\[
\hat{Z}(\boldsymbol{x}_0)=\sum_{i=1}^{N}\lambda_i(\boldsymbol{x}_i),
\]</span> where <span class="math inline">\(\lambda_i\)</span> are the weights. To ensure that the estimate is unbiased the weights are made to sum to 1, <span class="math display">\[
\sum_{i=1}^{N}\lambda_i=1
\]</span></p>
<blockquote>
<p>Review about the unbiased, consistent, efficient estimator https://en.wikipedia.org/wiki/Consistent_estimator#Unbiased_but_not_consistent</p>
</blockquote>
<p>and the expected error is <span class="math inline">\(E[\hat{Z}(\boldsymbol{x}_0)-Z(\boldsymbol{x}_0)]=0\)</span>.</p>
<p>The estimation variance is <span class="math display">\[
var[\hat{Z}(\boldsymbol{x}_0)]=E[\{\hat{Z}(\boldsymbol{x}_0)-Z(\boldsymbol{x}_0)\}^2]\\
=2\sum_{i=1}^{N}\lambda_i\gamma(\boldsymbol{x}_i,\boldsymbol{x}_0)-\sum_{i=1}^{N}\sum_{i=1}^{N}\lambda_i\lambda_j\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)\)</span> is the semivariance of <span class="math inline">\(Z\)</span> between the data points<span class="math inline">\(\boldsymbol{x}_i\)</span> and <span class="math inline">\(\boldsymbol{x}_j\)</span>, and <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x}_0)\)</span> is the semivariance between the ith data point and the target point <span class="math inline">\(x_0\)</span>.</p>
<blockquote>
<p>Semi variance:http://www.kgs.ku.edu/Tis/surf3/s3krig2.html</p>
</blockquote>
<p>In the more general case we may wish to estimate <span class="math inline">\(Z\)</span> in a block <span class="math inline">\(B\)</span>, which may be a line, an area or a volume depending on whether it is in one, two or three spatial dimensions. The kriged estimate in <span class="math inline">\(B\)</span> is still a simple weighted average of the data, <span class="math display">\[
\hat{Z}(\boldsymbol{B})=\sum_{i=1}^{N}\lambda_iz(\boldsymbol{x}_i),
\]</span> but with <span class="math inline">\(x_0\)</span> of equation (3) replaced by <span class="math inline">\(B\)</span>. Its variance is <span class="math display">\[
var[\hat{Z}(\boldsymbol{B})]=E[\{\hat{Z}(\boldsymbol{B})-Z(\boldsymbol{B})\}^2]\\
=2\sum_{i=1}^{N}\lambda_i\gamma(\boldsymbol{x}_i,\boldsymbol{B})-\sum_{i=1}^{N}\sum_{i=1}^{N}\lambda_i\lambda_j\gamma(\boldsymbol{x}_i,\boldsymbol{x}_j)-\bar{\gamma}(B,B).
\]</span> The quantity <span class="math inline">\(\bar\gamma(\boldsymbol{x}_i,B)\)</span> is the average semivariance between the <span class="math inline">\(i\)</span>th sampling point and the block <span class="math inline">\(B\)</span> and is the integral <span class="math display">\[
$\bar\gamma(\boldsymbol{x}_i,B)$ =\frac{1}{B}\int_B\gamma(\boldsymbol{x}_i,\boldsymbol{x})d\boldsymbol{x},
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x}_i,\boldsymbol{x})\)</span> denotes the semivariance between the sampling point xi and a point x describing the block.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021022160855202.png"></p>
<p>The third term on the right-hand side of equation (7) is the double integral <span class="math display">\[
\bar{\gamma}(B,B)=\frac{1}{|B^2|}\int_B\int_B\gamma(\boldsymbol{x},\boldsymbol{x^{\prime}})d\boldsymbol{x}d\boldsymbol{x^{\prime}}
\]</span> where <span class="math inline">\(\gamma(\boldsymbol{x},\boldsymbol{x^{\prime}})\)</span> is the semivariance between two points <span class="math inline">\(x\)</span> and <span class="math inline">\(x^{\prime}\)</span> that sweep independently over B. It is the within-block variance. In punctual kriging <span class="math inline">\(\bar{\gamma}(B,B)\)</span>becomes <span class="math inline">\(\bar{\gamma}(x_0,x_0)=0\)</span>, which is why equation (5) has two terms rather than three.</p>
<p>For each kriged estimate there is an associated kriging variance, which we can denote by <span class="math inline">\(\sigma^2(\boldsymbol{x}_0)\)</span> and <span class="math inline">\(\sigma^2(B)\)</span> for the point and block, respectively, and which are defined in equation(5) and equation(7).</p>
<p>The next step in kriging is to find the weights that minimize these variances, subject to the constraint that they sum to 1. We achieve this using the method of Lagrange multipliers.</p>
<p>Here I do not want to show how Lagrange multipliers works. Anyway this post is just a general introduction.</p>
<h2 id="weights">WEIGHTS</h2>
<p>When the kriging equations are solved to obtain the weights, <span class="math inline">\(\lambda_i\)</span>, in general the only large weights are those of the points near to the point or block to be kriged. The nearest four or five might contribute 80% of the total weight, and the next nearest ten almost all of the remainder. The weights also depend on the configuration of the sampling. We can summarize the factors affecting the weights as follows.</p>
<ol type="1">
<li>Near points carry more weight than more distant ones. Their relative proportions depend on the positions of the sampling points and on the variogram: the larger is the nugget variance, the smaller are the weights of the points that are nearest to target point or block.</li>
<li>The relative weights of points also depend on the block size: as the block size increases, the weights of the nearest points decrease and those of the more distant points increase , until the weights become nearly equal.</li>
<li>Clustered points carry less weight individually than isolated ones at the same distance</li>
<li>Data points can be screened by ones lying between them and the target</li>
</ol>
<p>These effects are all intuitively desirable, and the first shows that kriging is local. They will become evident in the examples below. They also have practical implications. The most important for present purposes is that because only the nearest few data points to the target carry significant weight, matrix A in the kriging system need never be large and its inversion will be swift.</p>
<h1 id="covariance-and-variogram">Covariance and Variogram</h1>
<p>Before we step into the next one, we need to clarify some basic definition.</p>
<p>This part also comes from the previous textbook.</p>
<h2 id="a-stochastic-approach-to-spatial-variation-the-theory-of-regionalized-variables">A STOCHASTIC APPROACH TO SPATIAL VARIATION: THE THEORY OF REGIONALIZED VARIABLES</h2>
<h3 id="random-variables">Random variables</h3>
<h1 id="poisson-kriging-area-to-area">Poisson Kriging-Area to Area</h1>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Kriging model</tag>
        <tag>Spatial staticstics</tag>
      </tags>
  </entry>
  <entry>
    <title>lambda</title>
    <url>/posts/d39dff82.html</url>
    <content><![CDATA[<h1 id="python-lambda">Python Lambda</h1>
<p>在读别人代码的时候看到的，发现自己对这个东西不是很熟悉，复习一下记个笔记。</p>
<p><strong>lambda 函数是一种小的匿名函数。</strong></p>
<p><strong>lambda 函数可接受任意数量的参数，但只能有一个表达式。</strong></p>
<a id="more"></a>
<h2 id="语法">语法</h2>
<p><code>lambda arguments : expression</code></p>
<p>执行表达式并返回结果</p>
<h2 id="实例">实例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="keyword">lambda</span> a : a + <span class="number">10</span></span><br><span class="line">print(x(<span class="number">5</span>))</span><br></pre></td></tr></table></figure>
<p>这一句话就定义了一个lambda函数，a是这个函数的参数，a+10是这个函数的表达式，x是这个函数的名字。</p>
<p>Lambda可以接受任意数量的参数，比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = <span class="keyword">lambda</span> a, b, c : a + b + c</span><br><span class="line">print(x(<span class="number">5</span>, <span class="number">6</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<p>这个函数就是三个参数</p>
<h2 id="函数内匿名函数">函数内匿名函数</h2>
<p>假设我定义了这么一个函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span>(<span class="params">n</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">lambda</span> a : a * n</span><br></pre></td></tr></table></figure>
<p>这个函数的作用是把a变成n倍。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">myfunc</span>(<span class="params">n</span>):</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">lambda</span> a : a * n</span><br><span class="line"></span><br><span class="line">mydoubler = myfunc(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>这样就可以很快速地构建出来这样的一个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mydoubler</span>(<span class="params">a</span>):</span></span><br><span class="line">  <span class="keyword">return</span> n*<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>不需要想用别的的时候再去定义，比如我还想再来一个三倍的函数，就直接：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mytripler = myfunc(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>服务器部署自动机器学习</title>
    <url>/posts/c23e0e6e.html</url>
    <content><![CDATA[<p>借着毕业实习的机会将代码放到了实验室的服务器上，在这里记录一下全过程。</p>
<a id="more"></a>
<h1 id="实验室服务器的登陆及基本操作">实验室服务器的登陆及基本操作</h1>
<p>除了直接在服务器主机上登陆之外，还可以通过一些连接软件进行远程登陆。我这里使用的是PuTTY软件。</p>
<p>PuTTY是一款开源(Open Source Software)的连接软件，主要由Simon Tatham维护，使用MIT许可证授权。包含的组件有：PuTTY, PuTTYgen,PSFTP, PuTTYtel, Plink, PSCP, Pageant,默认登录协议是SSH，默认的端口为22。Putty是用来远程连接服务器的，支持SSH、Telnet、Serial等协议的连接。其中最常用的是SSH。用它来远程管理Linux十分好用，其主要优点如下：</p>
<ul>
<li>完全免费开源;</li>
<li>全面支持windows系统;</li>
<li>全面支持SSH1和SSH2；</li>
<li>绿色软件，无需安装，下载后在桌面建个快捷方式即可使用；</li>
<li>体积很小，不到1M；</li>
<li>操作简单，所有的操作都在一个控制面板中实现。</li>
</ul>
<p>PuTTY的下载页面为<span class="exturl" data-url="aHR0cHM6Ly9wdXR0eS5vcmcv">https://putty.org/<i class="fa fa-external-link-alt"></i></span>，选择合适的版本下载安装即可。</p>
<p>下载好之后在Saved Sessions处输入服务器IP地址，点击Save，然后点Open即可打开会话，输入用户名和密码即可登陆。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190605143842.png"></p>
<p>接着使用一些基本命令来确定服务器的系统版本和python版本。</p>
<p>输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/redhat-release</span><br></pre></td></tr></table></figure>
<p>返回的系统版本为Centos 7.3.1611 Redhat。</p>
<p>输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python</span><br></pre></td></tr></table></figure>
<p>返回的系统版本为python2.7。</p>
<p>利用mkdir命令新建一个目录，后续操作皆在此目录下进行。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir amf</span><br></pre></td></tr></table></figure>
<p>CPUE自动预测系统的环境配置</p>
<p>实验室所用linux服务器版本为Centos 7.3.1611 Redhat，默认python版本为2.7，因此首先需要将python3安装到服务器上。</p>
<h1 id="python3的安装">python3的安装</h1>
<h2 id="rpm包安装">RPM包安装</h2>
<p>本次安装使用的是来源于IUS社区的RPM包进行安装。IUS是“Inline with Upstream Stable”的缩写，他主要是一个提供新版本RPM包的社区，具体情况可以查看<span class="exturl" data-url="aHR0cHM6Ly9pdXMuaW8vR2V0dGluZ1N0YXJ0ZWQvI2luc3RhbGwtdmlhLWF1dG9tYXRpb24=">官方文档<i class="fa fa-external-link-alt"></i></span>。</p>
<p>所使用的具体操作如下(部分操作需要sudo权限，在这里不一一列出)：</p>
<ol type="1">
<li>添加IUS地址：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install https://centos7.iuscommunity.org/ius-release.rpm</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建缓存元数据：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum makecache</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>安装python3.6：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install python36u</span><br><span class="line"></span><br><span class="line">yum -y install python36u-pip</span><br><span class="line"></span><br><span class="line">yum -y install python36u-devel</span><br></pre></td></tr></table></figure>
<p>（4）测试环境：输入python3.6出现如下文字即代表安装成功。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Python <span class="number">3.6</span><span class="number">.8</span> (default, May  <span class="number">2</span> <span class="number">2019</span>, <span class="number">20</span>:<span class="number">40</span>:<span class="number">44</span>)</span><br><span class="line"></span><br><span class="line">[GCC <span class="number">4.8</span><span class="number">.5</span> <span class="number">20150623</span> (Red Hat <span class="number">4.8</span><span class="number">.5</span><span class="number">-36</span>)] on linux</span><br><span class="line"></span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure>
<h2 id="虚拟环境的配置">虚拟环境的配置</h2>
<p>因为系统中存在多个python版本，为了避免环境污染，我使用virtualenv创建了独立的虚拟环境，具体过程如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python3.6 -m venv py3</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> py3/bin/activate</span><br></pre></td></tr></table></figure>
<p>执行完之后再命令行前会出现(py3)的字样，即代表进入虚拟环境中，输入python -V返回python3.6.8即代表安装成功。</p>
<h2 id="机器学习环境配置">机器学习环境配置</h2>
<p>自动预测系统是基于auto-sklearn开发的，需要scipy、sci-kit、pands、numpy等代码库的支持。在上一不中我们安装了pip这一python包管理工具，它可以提供对python包的查找、下载、安装、卸载等功能，因此这里直接采用pip命令进行安装即可</p>
<p>需要注意的是，在配置之前要先进入上一步配置的虚拟环境。</p>
<p>依次执行如下命令即可进行安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install pandas</span><br><span class="line"></span><br><span class="line">pip install scipy</span><br><span class="line"></span><br><span class="line">pip install scikit-learn</span><br><span class="line"></span><br><span class="line">pip install auto-sklearn</span><br><span class="line"></span><br><span class="line">pip install matplotlib</span><br><span class="line"></span><br><span class="line">pip install xlrd</span><br><span class="line"></span><br><span class="line">pip install openpyxl</span><br></pre></td></tr></table></figure>
<p>在安装auto-sklearn的过程中遇到如下错误：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Error: Syntax error <span class="keyword">in</span> input(3).     error: <span class="built_in">command</span> <span class="string">&#x27;swig&#x27;</span> failed with <span class="built_in">exit</span> status 1</span><br></pre></td></tr></table></figure>
<p>根据提示可知是由于swig而出现的错误，SWIG本质上是个代码生成器，为C/C++程序生成到其他语言的包装代码(wrapper code)，这些包装代码里会利用各语言提供的C API，将C/C++程序中的内容暴露给相应语言。为了生成这些包装代码，SWIG需要一个接口描述文件，描述将什么样的接口暴露给其他语言。</p>
<p>查看swig所用的版本为2.0.10，为python2.7所对应的版本，因此需要在系统中将swig升级到3版本。</p>
<p>首先将swig2卸载，执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y remove swig</span><br></pre></td></tr></table></figure>
<p>然后安装swig 3，执行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install swig3</span><br></pre></td></tr></table></figure>
<p>安装以后执行命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">swig -version</span><br></pre></td></tr></table></figure>
<p>可以看到swig的版本变成了3.0.12。</p>
<p>重新执行pip install auto-sklearn即可完成安装。</p>
<p>安装完成后在虚拟环境中输入python，进入python语言，执行如下命令，如果没有报错，即说明环境配置完成。按Ctrl+D即可退出虚拟环境和puTTY。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> autosklearn.regression</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<h1 id="服务器与windows之间的文件传输">服务器与windows之间的文件传输</h1>
<p>在运行程序之前，需要将要用到的数据传输到服务器上，这里采用的是puTTY提供的PSFTP工具。在之前安装puTTY时已经一并安装了。</p>
<p>打开PSFTP，输入open 服务器地址，完成登陆，然后采用put命令将本地文件传输到服务器上，get命令将服务器上的文件取回。</p>
<h1 id="程序调试">程序调试</h1>
<p>利用PSFTP将源代码传输到服务器上，进入虚拟环境，在命令行中输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python code.py</span><br></pre></td></tr></table></figure>
<p>即可看到程序开始运行。</p>
<p>如果程序报错，需要利用系统自带的vim编辑器进行编辑与调试。vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是：</p>
<p>（1）命令模式：</p>
<p>用户刚刚启动 vim，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。</p>
<p>以下是常用的几个命令：</p>
<ul>
<li>l i 切换到输入模式，以输入字符。</li>
<li>l x 删除当前光标所在处的字符。</li>
<li>l : 切换到底线命令模式，以在最底一行输入命令。</li>
</ul>
<p>若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。</p>
<p>命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。</p>
<p>（2）输入模式：</p>
<p>在命令模式下按下i就进入了输入模式。在输入模式中，可以使用以下按键：</p>
<ul>
<li>l 字符按键以及Shift组合，输入字符</li>
<li>l ENTER，回车键，换行</li>
<li>l BACK SPACE，退格键，删除光标前一个字符</li>
<li>l DEL，删除键，删除光标后一个字符</li>
<li>l 方向键，在文本中移动光标</li>
<li>l HOME/END，移动光标到行首/行尾</li>
<li>l Page Up/Page Down，上/下翻页</li>
<li>l Insert，切换光标为输入/替换模式，光标将变成竖线/下划线</li>
<li>l ESC，退出输入模式，切换到命令模式</li>
</ul>
<p>（3）底线命令模式：</p>
<p>在命令模式下按下:（英文冒号）就进入了底线命令模式。底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。在底线命令模式中，基本的命令有（已经省略了冒号）：</p>
<ul>
<li>l q 退出程序</li>
<li>l w 保存文件</li>
<li>l 按ESC键可随时退出底线命令模式。</li>
</ul>
<p>如果你想用vim来编辑或者建立一个名为test.txt的文件时，只需要在虚拟环境中输入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim test.txt</span><br></pre></td></tr></table></figure>
<p>即可。此时进入的是一般模式，在一般模式下按i即可进入输入模式，此时左下角状态栏会出现–INSERT- 的字样，即代表可以输入任意字符。这时除了ESC之外，其余按键都可以作为一般的输入按钮。编辑完成之后按ESC即可挥动一般模式。在一般模式下按：，输入wq即可保存离开。</p>
<p>除此之外还有很多进阶命令，在这里就不再细数了。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Linux</tag>
        <tag>服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>Material for ocean color</title>
    <url>/posts/3aa0ed1a.html</url>
    <content><![CDATA[<p>I have been in master course for half years. It’s time to organize the materials I have used.</p>
<p>This article will update as soon as I get new resource.</p>
<a id="more"></a>
<h1 id="basic-knowledge">Basic Knowledge</h1>
<h2 id="textbook">Textbook</h2>
<p>Kirk, J. (1994). <em>Light and Photosynthesis in Aquatic Ecosystems</em>. Cambridge: Cambridge University Press. doi:10.1017/CBO9780511623370 https://www.cambridge.org/core/books/light-and-photosynthesis-in-aquatic-ecosystems/C19B28AE07B1CDEBDA5593194DE4E304</p>
<p>Martin, S. (2014). <em>An Introduction to Ocean Remote Sensing</em>. Cambridge: Cambridge University Press. doi:10.1017/CBO9781139094368 https://www.cambridge.org/core/books/an-introduction-to-ocean-remote-sensing/B05BDCA4B71B9F41E1F1E97FBDCDC9BB</p>
<p>Ocean Optics Web book http://www.oceanopticsbook.info/</p>
<p>IOCCG report https://ioccg.org/what-we-do/ioccg-publications/ioccg-reports/</p>
<p>NASA's Ocean Biology Processing Group (OBPG) Technical Documents:https://oceancolor.gsfc.nasa.gov/docs/technical/</p>
<h2 id="video-and-training-course">Video and Training course</h2>
<p>IOCCG training course https://ioccg.org/what-we-do/training-and-education/</p>
<p>Cornell Summer Satellite Remote Sensing Training Program http://oceanography.eas.cornell.edu/satellite/</p>
<p>Lecture Material from IOCCG Training Courses https://ioccg.org/what-we-do/training-and-education/lectures/</p>
<h1 id="programming-resource">Programming Resource</h1>
<h2 id="python-package">Python package</h2>
<p>I strongly recommend you install them by Anaconda</p>
<p>numpy,pandas,scipy,scikit-learn,matplotlib,Basemap,GDAL,geopandas,geos,h5py, hdf4,hdf5,netcdf4,pyresample,rasterio,shapely,earthpy,</p>
<h2 id="material-for-programming">Material for programming</h2>
<p>PyHOGs: Python Hour for Oceanographers and Geoscientists http://pyhogs.github.io/</p>
<p>RGB 3S blog:https://www.ixxin.cn/</p>
<p>OceanPython.org: https://oceanpython.org/table-of-contents/</p>
<p>python4geosciences:materials for the Texas A&amp;M Python for Geoscientists class, OCNG 489/689.</p>
<p>https://github.com/hetland/python4geosciences_OLD</p>
<p>Python for Geosciences: https://github.com/koldunovn/python_for_geosciences</p>
<p>R and Python for Oceanographers 1st Edition:https://www.elsevier.com/books/r-and-python-for-oceanographers/alyuruk/978-0-12-813491-7</p>
<p>Earth Lab:https://www.earthdatascience.org/</p>
<p>Processing Remote Sensing Data with Python:https://skemman.is/bitstream/1946/16233/1/final_processingwithpython_dillon.pdf</p>
<p>Geo-python: https://geo-python.github.io/site/</p>
<p>Ocean Optics UMaine MISC Lab:https://github.com/OceanOptics</p>
<p>Optical Oceanography Lab :http://oceanoptics.umb.edu/resources/</p>
<h2 id="software">Software</h2>
<p>Seadas:https://seadas.gsfc.nasa.gov/</p>
<p>Windows Image Manager:http://www.wimsoft.com/index.html</p>
<p>GOCI Data Processing System(GDPS):http://kosc.kiost.ac.kr/eng/p30/kosc_p31.html</p>
<p>Ocean Data View:https://odv.awi.de/</p>
<p>GISS:https://www.giss.nasa.gov/tools/</p>
<h1 id="data-resource">Data Resource</h1>
<h2 id="ocean-color-data">Ocean Color Data</h2>
<p>NASA ocean color data :https://oceancolor.gsfc.nasa.gov/</p>
<p>Earthdata website:https://earthdata.nasa.gov/</p>
<p>GOCI data:http://kosc.kiost.ac.kr/eng/</p>
<p>Maine production(standard VGPM):http://kosc.kiost.ac.kr/eng/</p>
<p>Japan GCOM-C/SGLI:https://gportal.jaxa.jp/gpr/</p>
<p>China GF satellite :http://www.hbeos.org.cn/</p>
<p>Earthexplore： https://earthexplorer.usgs.gov/</p>
<p>EUMETSAT:https://www.eumetsat.int/website/home/index.html</p>
<h2 id="other-data">Other data:</h2>
<p>GHRSST:https://www.ghrsst.org/</p>
<p>China Argo:www.argo.org.cn/</p>
<p>Other Argo:http://www.argodatamgt.org/</p>
<p>Asia-Pacific Data Research Center,:http://apdrc.soest.hawaii.edu/index.php</p>
<p>AVISO:https://www.aviso.altimetry.fr/en/data/products.html</p>
<p>Japan Meteorological Agency:www.jma.go.jp/jma/menu/menureport.html</p>
<p>REMSS:http://www.remss.com/</p>
<p>Jet Propulsion Lab：https://podaac.jpl.nasa.gov/</p>
<p>KNMI Climate Explorer,：https://climexp.knmi.nl/start.cgi?id=someone@somewhere</p>
<p>ECMWF:https://apps.ecmwf.int/datasets/data/interim-full-daily/levtype%3Dsfc/</p>
<p>OUC ocean &amp; atmosphere data center:http://coadc.ouc.edu.cn/index.php/Index</p>
<p>China Center For Resources Satellite Data and Application:http://218.247.138.119:7777/DSSPlatform/index.html</p>
<p>Geospatial Data Cloud:https://www.gscloud.cn/</p>
<p>FAO Fishery data:http://www.fao.org/fishery/statistics/en</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第六周笔记 Machine Learning Foundation Week 6 Note in Cousera</title>
    <url>/posts/da4d42a2.html</url>
    <content><![CDATA[<p>Theory of Generalization</p>
<p>test error can approximate training error if there is enough data and growth function does not grow too fast</p>
<a id="more"></a>
<h1 id="restriction-of-breaking-point">Restriction of Breaking Point</h1>
<h2 id="the-four-breaking-points">The Four Breaking Points</h2>
<p>growth function <span class="math inline">\(m_\H(N)\)</span>:max number of dichotomies</p>
<ul>
<li>positive rays: <span class="math inline">\(m_\H(N)=N+1\)</span></li>
<li>positive intervals: <span class="math inline">\(m_\H(N)=\frac{1}{2}N^2+\frac{1}{2}N+1\)</span></li>
<li>convex sets: <span class="math inline">\(m_\H(N)=2^N\)</span></li>
<li>2D perceptrons :<span class="math inline">\(m_\H(N)&lt;2^N\)</span> in some cases</li>
</ul>
<h2 id="restriction-of-breaking-point-1">Restriction of Breaking Point</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190512171932.png"></p>
<h1 id="bounding-functionbasic-cases">Bounding Function:Basic Cases</h1>
<h2 id="bounding-function">Bounding Function</h2>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>note for ocean optic web book：Liaght and Radiometry</title>
    <url>/posts/80897339.html</url>
    <content><![CDATA[<p>Souce: http://www.oceanopticsbook.info/</p>
<a id="more"></a>
<h1 id="unit">UNIT</h1>
<p>All other quantities are derivable from these units.</p>
<table>
<thead>
<tr class="header">
<th>Physical quantity</th>
<th>Base Unit</th>
<th>Symbol</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>length</td>
<td>meter</td>
<td>m</td>
</tr>
<tr class="even">
<td>mass</td>
<td>kilogram</td>
<td>kg</td>
</tr>
<tr class="odd">
<td>time</td>
<td>second</td>
<td>s</td>
</tr>
<tr class="even">
<td>electric current</td>
<td>ampere</td>
<td>A</td>
</tr>
<tr class="odd">
<td>temperature</td>
<td>kelvin</td>
<td>K</td>
</tr>
<tr class="even">
<td>amount of substance</td>
<td>mole</td>
<td>mol</td>
</tr>
<tr class="odd">
<td>luminous intensity</td>
<td>candela</td>
<td>cd</td>
</tr>
<tr class="even">
<td></td>
<td>Supplementary Units</td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research Basis</tag>
        <tag>Ocean Optics</tag>
        <tag>bookreading</tag>
      </tags>
  </entry>
  <entry>
    <title>np.ma.mask</title>
    <url>/posts/39e89397.html</url>
    <content><![CDATA[<p>自己前几天一直在跟mask斗争，中文网站上也没什么好的资料，就索性自己整理一下。</p>
<a id="more"></a>
<h1 id="创建">创建</h1>
<p>官方提供了三种方法来创建mask，第一种是直接指定mask的位置</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> numpy.ma <span class="keyword">as</span> ma</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = ma.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], mask = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">y</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[1, --, 3],
             mask=[False,  True, False],
       fill_value=999999)</code></pre>
<p>第二种是用ma.MaskedArray类，这个不是很常用</p>
<p>x = MaskedArray(data, mask=nomask, dtype=None, copy=False, subok=True, ndmin=0, fill_value=None, keep_mask=True, hard_mask=None, shrink=True, order=None)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">np.ma.MaskedArray(data, mask=[[<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">False</span>],</span><br><span class="line">                              [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>]])</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(
  data=[[0, --, 2],
        [3, 4, --]],
  mask=[[False,  True, False],
        [False, False,  True]],
  fill_value=999999)</code></pre>
<p>这种方法可以直接给整个数组上mask</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.ma.MaskedArray(data, mask=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(
  data=[[0, 1, 2],
        [3, 4, 5]],
  mask=[[False, False, False],
        [False, False, False]],
  fill_value=999999)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.ma.MaskedArray(data, mask=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(
  data=[[--, --, --],
        [--, --, --]],
  mask=[[ True,  True,  True],
        [ True,  True,  True]],
  fill_value=999999,
  dtype=int64)</code></pre>
<p>官方给出的第三种原文和事例如下，但是我始终没有特别理解</p>
<p>A third option is to take the view of an existing array. In that case, the mask of the view is set to nomask if the array has no named fields, or an array of boolean with the same structure as the array otherwise.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.view(ma.MaskedArray)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[1, 2, 3],
             mask=False,
       fill_value=999999)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.array([(<span class="number">1</span>, <span class="number">1.</span>), (<span class="number">2</span>, <span class="number">2.</span>)], dtype=[(<span class="string">&#x27;a&#x27;</span>,int), (<span class="string">&#x27;b&#x27;</span>, float)])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x.view(ma.MaskedArray)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[(1, 1.0), (2, 2.0)],
             mask=[(False, False), (False, False)],
       fill_value=(999999, 1.e+20),
            dtype=[(&#39;a&#39;, &#39;&lt;i8&#39;), (&#39;b&#39;, &#39;&lt;f8&#39;)])</code></pre>
<p>对于我来说我的需求基本就是构造一个和已有mask array相同的数组，对我来说可以用以下方法得到</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ma.array(np.zeros_like(y),mask=y.mask)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[0, --, 0],
             mask=[False,  True, False],
       fill_value=999999)</code></pre>
<p>除此之外，还有一些函数可以完成效果，比较常用的是这几个</p>
<p>masked_equal(x, value[, copy])</p>
<p>masked_greater(x, value[, copy])</p>
<p>masked_greater_equal(x, value[, copy])</p>
<p>masked_invalid(a[, copy])</p>
<p>masked_less(x, value[, copy])</p>
<p>masked_less_equal(x, value[, copy])</p>
<p>masked_not_equal(x, value[, copy])</p>
<p>masked_where(condition, a[, copy])</p>
<p>这里masked_where()和masked_invalid()最好用</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = np.arange(<span class="number">4</span>)</span><br><span class="line">ma.masked_where(a &lt;= <span class="number">2</span>, a)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[--, --, --, 3],
             mask=[ True,  True,  True, False],
       fill_value=999999)</code></pre>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a=np.asarray([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,np.inf,np.nan])</span><br><span class="line">ma.masked_invalid(a)</span><br></pre></td></tr></table></figure>
<pre><code>masked_array(data=[1.0, 2.0, 3.0, --, --],
             mask=[False, False, False,  True,  True],
       fill_value=1e+20)</code></pre>
<p>在创建里面还有一个事情是比较重要的，那就是fill_value</p>
<h1 id="参考">参考</h1>
<p>https://numpy.org/doc/stable/reference/maskedarray.generic.html</p>
<p>https://www.numpy.org.cn/reference/arrays/maskedarray.html</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas cheat sheet</title>
    <url>/posts/da4a7e8b.html</url>
    <content><![CDATA[<p>和matplotlib一样pandas也有cheatsheet</p>
<a id="more"></a>
<p>地址https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00020924161352046.png"></p>
<p>另外顺手立个flag，每周在博客更新 Annotated Bibliography</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>plot</title>
    <url>/posts/bebb8f89.html</url>
    <content><![CDATA[<p>一些在读别人代码的时候发现自己还没有掌握的东西。</p>
<a id="more"></a>
<h1 id="matplotlib.ticker">matplotlib.ticker</h1>
<h2 id="定位">定位</h2>
<h3 id="tick-locating">Tick locating</h3>
<p>The Locator class is the base class for all tick locators. The locators handle autoscaling of the view limits based on the data limits, and the choosing of tick locations. A useful semi-automatic tick locator is <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a>. It is initialized with a base, e.g., 10, and it picks axis limits and ticks that are multiples of that base.</p>
<p>The Locator subclasses defined here are</p>
<ul>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.AutoLocator"><code>AutoLocator</code></a></p>
<p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MaxNLocator"><code>MaxNLocator</code></a> with simple defaults. This is the default tick locator for most plotting.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MaxNLocator"><code>MaxNLocator</code></a></p>
<p>Finds up to a max number of intervals with ticks at nice locations.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LinearLocator"><code>LinearLocator</code></a></p>
<p>Space ticks evenly from min to max.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogLocator"><code>LogLocator</code></a></p>
<p>Space ticks logarithmically from min to max.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a></p>
<p>Ticks and range are a multiple of base; either integer or float.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FixedLocator"><code>FixedLocator</code></a></p>
<p>Tick locations are fixed.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.IndexLocator"><code>IndexLocator</code></a></p>
<p>Locator for index plots (e.g., where <code>x = range(len(y))</code>).</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullLocator"><code>NullLocator</code></a></p>
<p>No ticks.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.SymmetricalLogLocator"><code>SymmetricalLogLocator</code></a></p>
<p>Locator for use with with the symlog norm; works like <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogLocator"><code>LogLocator</code></a> for the part outside of the threshold and adds 0 if inside the limits.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogitLocator"><code>LogitLocator</code></a></p>
<p>Locator for logit scaling.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.OldAutoLocator"><code>OldAutoLocator</code></a></p>
<p>Choose a <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.MultipleLocator"><code>MultipleLocator</code></a> and dynamically reassign it for intelligent ticking during navigation.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.AutoMinorLocator"><code>AutoMinorLocator</code></a></p>
<p>Locator for minor ticks when the axis is linear and the major ticks are uniformly spaced. Subdivides the major tick interval into a specified number of minor intervals, defaulting to 4 or 5 depending on the major interval.</p></li>
</ul>
<p>There are a number of locators specialized for date locations - see the <code>dates</code> module.</p>
<p>You can define your own locator by deriving from Locator. You must override the <code>__call__</code> method, which returns a sequence of locations, and you will probably want to override the autoscale method to set the view limits from the data limits.</p>
<p>If you want to override the default locator, use one of the above or a custom locator and pass it to the x or y axis instance. The relevant methods are:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.xaxis.set_major_locator(xmajor_locator)</span><br><span class="line">ax.xaxis.set_minor_locator(xminor_locator)</span><br><span class="line">ax.yaxis.set_major_locator(ymajor_locator)</span><br><span class="line">ax.yaxis.set_minor_locator(yminor_locator)</span><br></pre></td></tr></table></figure>
<p>The default minor locator is <a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullLocator"><code>NullLocator</code></a>, i.e., no minor ticks on by default.</p>
<h2 id="格式">格式</h2>
<h3 id="tick-formatting">Tick formatting</h3>
<p>Tick formatting is controlled by classes derived from Formatter. The formatter operates on a single tick value and returns a string to the axis.</p>
<ul>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.NullFormatter"><code>NullFormatter</code></a></p>
<p>No labels on the ticks.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.IndexFormatter"><code>IndexFormatter</code></a></p>
<p>Set the strings from a list of labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FixedFormatter"><code>FixedFormatter</code></a></p>
<p>Set the strings manually for the labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FuncFormatter"><code>FuncFormatter</code></a></p>
<p>User defined function sets the labels.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.StrMethodFormatter"><code>StrMethodFormatter</code></a></p>
<p>Use string <a href="https://docs.python.org/3/library/functions.html#format"><code>format</code></a> method.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.FormatStrFormatter"><code>FormatStrFormatter</code></a></p>
<p>Use an old-style sprintf format string.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.ScalarFormatter"><code>ScalarFormatter</code></a></p>
<p>Default formatter for scalars: autopick the format string.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatter"><code>LogFormatter</code></a></p>
<p>Formatter for log axes.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterExponent"><code>LogFormatterExponent</code></a></p>
<p>Format values for log axis using <code>exponent = log_base(value)</code>.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterMathtext"><code>LogFormatterMathtext</code></a></p>
<p>Format values for log axis using <code>exponent = log_base(value)</code> using Math text.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogFormatterSciNotation"><code>LogFormatterSciNotation</code></a></p>
<p>Format values for log axis using scientific notation.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.LogitFormatter"><code>LogitFormatter</code></a></p>
<p>Probability formatter.</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.EngFormatter"><code>EngFormatter</code></a></p>
<p>Format labels in engineering notation</p></li>
<li><p><a href="https://matplotlib.org/3.1.1/api/ticker_api.html#matplotlib.ticker.PercentFormatter"><code>PercentFormatter</code></a></p>
<p>Format labels as a percentage</p></li>
</ul>
<p>You can derive your own formatter from the Formatter base class by simply overriding the <code>__call__</code> method. The formatter class has access to the axis view and data limits.</p>
<p>To control the major and minor tick label formats, use one of the following methods:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax.xaxis.set_major_formatter(xmajor_formatter)</span><br><span class="line">ax.xaxis.set_minor_formatter(xminor_formatter)</span><br><span class="line">ax.yaxis.set_major_formatter(ymajor_formatter)</span><br><span class="line">ax.yaxis.set_minor_formatter(yminor_formatter)</span><br></pre></td></tr></table></figure>
<p>See <span class="exturl" data-url="aHR0cHM6Ly9tYXRwbG90bGliLm9yZy8zLjEuMS9nYWxsZXJ5L3RpY2tzX2FuZF9zcGluZXMvbWFqb3JfbWlub3JfZGVtby5odG1s">Major and minor ticks<i class="fa fa-external-link-alt"></i></span> for an example of setting major and minor ticks. See the <a href="https://matplotlib.org/3.1.1/api/dates_api.html#module-matplotlib.dates"><code>matplotlib.dates</code></a> module for more information and examples of using date locators and formatters.</p>
<p>参考</p>
<p>https://matplotlib.org/3.1.1/api/ticker_api.html</p>
<p>https://matplotlib.org/3.1.1/api/ticker_api.html</p>
<h1 id="enumerate">enumerate</h1>
<h2 id="描述">描述</h2>
<p>enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。</p>
<p>Python 2.3. 以上版本可用，2.6 添加 start 参数。</p>
<h3 id="语法">语法</h3>
<p>以下是 enumerate() 方法的语法:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">enumerate(sequence, [start=<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h3 id="参数">参数</h3>
<ul>
<li>sequence -- 一个序列、迭代器或其他支持迭代对象。</li>
<li>start -- 下标起始位置。</li>
</ul>
<h3 id="返回值">返回值</h3>
<p>返回 enumerate(枚举) 对象。</p>
<hr>
<h2 id="实例">实例</h2>
<p>以下展示了使用 enumerate() 方法的实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;seasons = [<span class="string">&#x27;Spring&#x27;</span>, <span class="string">&#x27;Summer&#x27;</span>, <span class="string">&#x27;Fall&#x27;</span>, <span class="string">&#x27;Winter&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons))</span><br><span class="line">[(<span class="number">0</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">1</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>list(enumerate(seasons, start=<span class="number">1</span>))       <span class="comment"># 下标从 1 开始</span></span><br><span class="line">[(<span class="number">1</span>, <span class="string">&#x27;Spring&#x27;</span>), (<span class="number">2</span>, <span class="string">&#x27;Summer&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;Fall&#x27;</span>), (<span class="number">4</span>, <span class="string">&#x27;Winter&#x27;</span>)]</span><br></pre></td></tr></table></figure>
<h3 id="普通的-for-循环">普通的 for 循环</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;i = <span class="number">0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> element <span class="keyword">in</span> seq:</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> i, seq[i]</span><br><span class="line"><span class="meta">... </span>    i +=<span class="number">1</span></span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">0</span> one</span><br><span class="line"><span class="number">1</span> two</span><br><span class="line"><span class="number">2</span> three</span><br></pre></td></tr></table></figure>
<h3 id="for-循环使用-enumerate">for 循环使用 enumerate</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;seq = [<span class="string">&#x27;one&#x27;</span>, <span class="string">&#x27;two&#x27;</span>, <span class="string">&#x27;three&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> i, element <span class="keyword">in</span> enumerate(seq):</span><br><span class="line"><span class="meta">... </span>    <span class="keyword">print</span> i, element</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="number">0</span> one参考</span><br><span class="line"><span class="number">1</span> two</span><br><span class="line"><span class="number">2</span> three</span><br></pre></td></tr></table></figure>
<p>参考</p>
<p>https://www.runoob.com/python/python-func-enumerate.html</p>
<h1 id="subplot2grid">subplot2grid</h1>
<p>这个可以自定义子图的位置，并且可以跨越原来大小。</p>
<p>原文https://wizardforcel.gitbooks.io/matplotlib-user-guide/content/3.3.html</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">GridSpec</span><br></pre></td></tr></table></figure>
<p>指定子图将放置的网格的几何位置。 需要设置网格的行数和列数。 子图布局参数（例如，左，右等）可以选择性调整。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">SubplotSpec</span><br></pre></td></tr></table></figure>
<p>指定在给定<code>GridSpec</code>中的子图位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">subplot2grid</span><br></pre></td></tr></table></figure>
<p>一个辅助函数，类似于<code>pyplot.subplot</code>，但是使用基于 0 的索引，并可使子图跨越多个格子。</p>
<h2 id="subplot2grid基本示例">subplot2grid基本示例</h2>
<p>要使用subplot2grid，你需要提供网格的几何形状和网格中子图的位置。 对于简单的单网格子图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot2grid((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">       nRow=<span class="number">2</span>, nCol=<span class="number">2</span></span><br><span class="line">(<span class="number">0</span>,<span class="number">0</span>) +-------+-------+</span><br><span class="line">      |   <span class="number">1</span>   |       |</span><br><span class="line">      +-------+-------+</span><br><span class="line">      |       |       |</span><br><span class="line">      +-------+-------+</span><br></pre></td></tr></table></figure>
<p>要注意不像<code>subplot</code>，<code>gridspec</code>中的下标从 0 开始。</p>
<p>为了创建跨越多个格子的子图，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax2 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">0</span>), colspan=<span class="number">2</span>)</span><br><span class="line">ax3 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">2</span>), rowspan=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>例如，下列命令：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax1 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">0</span>,<span class="number">0</span>), colspan=<span class="number">3</span>)</span><br><span class="line">ax2 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>,<span class="number">0</span>), colspan=<span class="number">2</span>)</span><br><span class="line">ax3 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">1</span>, <span class="number">2</span>), rowspan=<span class="number">2</span>)</span><br><span class="line">ax4 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">ax5 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>), (<span class="number">2</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>会创建：</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec01.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="gridspec和subplotspec">GridSpec和SubplotSpec</h2>
<p>你可以显式创建<code>GridSpec</code>并用它们创建子图。</p>
<p>例如，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ax = plt.subplot2grid((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">0</span>, <span class="number">0</span>))</span><br></pre></td></tr></table></figure>
<p>等价于：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">ax = plt.subplot(gs[<span class="number">0</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p><code>gridspec</code>示例提供类似数组（一维或二维）的索引，并返回<code>SubplotSpec</code>实例。例如，使用切片来返回跨越多个格子的<code>SubplotSpec</code>实例。</p>
<p>上面的例子会变成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">ax1 = plt.subplot(gs[<span class="number">0</span>, :])</span><br><span class="line">ax2 = plt.subplot(gs[<span class="number">1</span>,:<span class="number">-1</span>])</span><br><span class="line">ax3 = plt.subplot(gs[<span class="number">1</span>:, <span class="number">-1</span>])</span><br><span class="line">ax4 = plt.subplot(gs[<span class="number">-1</span>,<span class="number">0</span>])</span><br><span class="line">ax5 = plt.subplot(gs[<span class="number">-1</span>,<span class="number">-2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec02.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="调整-gridspec布局">调整 GridSpec布局</h2>
<p>在显式使用<code>GridSpec</code>的时候，你可以调整子图的布局参数，子图由<code>gridspec</code>创建。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs1 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs1.update(left=<span class="number">0.05</span>, right=<span class="number">0.48</span>, wspace=<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<p>这类似于<code>subplots_adjust</code>，但是他只影响从给定<code>GridSpec</code>创建的子图。</p>
<p>下面的代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs1 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs1.update(left=<span class="number">0.05</span>, right=<span class="number">0.48</span>, wspace=<span class="number">0.05</span>)</span><br><span class="line">ax1 = plt.subplot(gs1[:<span class="number">-1</span>, :])</span><br><span class="line">ax2 = plt.subplot(gs1[<span class="number">-1</span>, :<span class="number">-1</span>])</span><br><span class="line">ax3 = plt.subplot(gs1[<span class="number">-1</span>, <span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">gs2 = gridspec.GridSpec(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">gs2.update(left=<span class="number">0.55</span>, right=<span class="number">0.98</span>, hspace=<span class="number">0.05</span>)</span><br><span class="line">ax4 = plt.subplot(gs2[:, :<span class="number">-1</span>])</span><br><span class="line">ax5 = plt.subplot(gs2[:<span class="number">-1</span>, <span class="number">-1</span>])</span><br><span class="line">ax6 = plt.subplot(gs2[<span class="number">-1</span>, <span class="number">-1</span>])</span><br></pre></td></tr></table></figure>
<p>会产生</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec03.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="使用-subplotspec创建-gridspec">使用 SubplotSpec创建 GridSpec</h2>
<p>你可以从<code>SubplotSpec</code>创建<code>GridSpec</code>，其中它的布局参数设置为给定<code>SubplotSpec</code>的位置的布局参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs0 = gridspec.GridSpec(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">gs00 = gridspec.GridSpecFromSubplotSpec(<span class="number">3</span>, <span class="number">3</span>, subplot_spec=gs0[<span class="number">0</span>])</span><br><span class="line">gs01 = gridspec.GridSpecFromSubplotSpec(<span class="number">3</span>, <span class="number">3</span>, subplot_spec=gs0[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec04.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="使用subplotspec创建复杂嵌套的gridspec">使用SubplotSpec创建复杂嵌套的GridSpec</h2>
<p>这里有一个更复杂的嵌套<code>gridspec</code>的示例，我们通过在每个 3x3 内部网格中隐藏适当的脊线，在 4x4 外部网格的每个单元格周围放置一个框。</p>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec06.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="网格尺寸可变的gridspec">网格尺寸可变的GridSpec</h2>
<p>通常，<code>GridSpec</code>创建大小相等的网格。你可以调整行和列的相对高度和宽度，要注意绝对高度值是无意义的，有意义的只是它们的相对比值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gs = gridspec.GridSpec(<span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">                       width_ratios=[<span class="number">1</span>,<span class="number">2</span>],</span><br><span class="line">                       height_ratios=[<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line">                       )</span><br><span class="line"></span><br><span class="line">ax1 = plt.subplot(gs[<span class="number">0</span>])</span><br><span class="line">ax2 = plt.subplot(gs[<span class="number">1</span>])</span><br><span class="line">ax3 = plt.subplot(gs[<span class="number">2</span>])</span><br><span class="line">ax4 = plt.subplot(gs[<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="http://matplotlib.org/_images/demo_gridspec05.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h1 id="seaborn">seaborn</h1>
<p>seaborn是对matplotlib进一步的封装，简单点来说就是更简单了。</p>
<p>官网https://seaborn.pydata.org/</p>
<p>我这里放几个我感觉用得上的代码。</p>
<h2 id="lineplot">lineplot</h2>
<p>seaborn.lineplot(x=None, y=None, hue=None, size=None, style=None, data=None, palette=None, hue_order=None, hue_norm=None, sizes=None, size_order=None, size_norm=None, dashes=True, markers=None, style_order=None, units=None, estimator='mean', ci=95, n_boot=1000, seed=None, sort=True, err_style='band', err_kws=None, legend='brief', ax=None, **kwargs)</p>
<p>https://seaborn.pydata.org/generated/seaborn.lineplot.html</p>
<h2 id="heatmap">heatmap</h2>
<p>seaborn.heatmap(data, vmin=None, vmax=None, cmap=None, center=None, robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels='auto', yticklabels='auto', mask=None, ax=None, **kwargs)</p>
<p>https://zhuanlan.zhihu.com/p/35494575</p>
<h2 id="implot">implot</h2>
<p>eaborn.lmplot(<em>x</em>, <em>y</em>, <em>data</em>, <em>hue=None</em>, <em>col=None</em>, <em>row=None</em>, <em>palette=None</em>, <em>col_wrap=None</em>, <em>size=5</em>, <em>aspect=1</em>, <em>markers='o'</em>, <em>sharex=True</em>, <em>sharey=True</em>, <em>hue_order=None</em>, <em>col_order=None</em>, <em>row_order=None</em>, <em>legend=True</em>, <em>legend_out=True</em>, <em>x_estimator=None</em>, <em>x_bins=None</em>, <em>x_ci='ci'</em>, <em>scatter=True</em>, <em>fit_reg=True</em>, <em>ci=95</em>, <em>n_boot=1000</em>, <em>units=None</em>, <em>order=1</em>, <em>logistic=False</em>, <em>lowess=False</em>, <em>robust=False</em>, <em>logx=False</em>, <em>x_partial=None</em>, <em>y_partial=None</em>, <em>truncate=False</em>, <em>x_jitter=None</em>, <em>y_jitter=None</em>, <em>scatter_kws=None</em>, <em>line_kws=None</em>)</p>
<p>https://zhuanlan.zhihu.com/p/25909753</p>
<p>常见统计图片基本都可以在这里面看到</p>
<p>https://seaborn.pydata.org/examples/index.html</p>
<h2 id="subplot_adjust">subplot_adjust</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">matplotlib.pyplot.subplots_adjust(*args, **kwargs)</span><br><span class="line">subplots_adjust(left=<span class="literal">None</span>, bottom=<span class="literal">None</span>, right=<span class="literal">None</span>, top=<span class="literal">None</span>,wspace=<span class="literal">None</span>, hspace=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">left  = <span class="number">0.125</span>  <span class="comment"># 子图(subplot)距画板(figure)左边的距离</span></span><br><span class="line">right = <span class="number">0.9</span>    <span class="comment"># 右边</span></span><br><span class="line">bottom = <span class="number">0.1</span>   <span class="comment"># 底部</span></span><br><span class="line">top = <span class="number">0.9</span>      <span class="comment"># 顶部</span></span><br><span class="line">wspace = <span class="number">0.2</span>   <span class="comment"># 子图水平间距</span></span><br><span class="line">hspace = <span class="number">0.2</span>   <span class="comment"># 子图垂直间距</span></span><br></pre></td></tr></table></figure>
<h1 id="pltaxfig">plt/ax/fig</h1>
<figure>
<img src="https://pic2.zhimg.com/80/v2-6e4429872eeb8a155433c0ee7c75b6ea_720w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>尽量避免直接使用plt</p>
<p>https://zhuanlan.zhihu.com/p/93423829</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>博客第三方插件和图片问题解决</title>
    <url>/posts/361a6d0d.html</url>
    <content><![CDATA[<p>啊四月份本咸鱼赏(da)樱(you)花(xi)和搞毕业论文去了，五月份滚回来更新。争取在没有你的五月（误）把机器学习基石的上更新完，然后把毕业论文的代码发到github。</p>
<p>这一篇包括第三方功能（评论、站点地图、阅读量、统计分析、分享）和图片问题的彻底解决。</p>
<a id="more"></a>
<h1 id="评论">评论</h1>
<p>我采用的评论系统是gitalk，因为这个系统不用注册什么乱七八糟的网站，支持github登录，搞起来很方便。</p>
<p>gitalk详情参见<span class="exturl" data-url="aHR0cHM6Ly9naXRhbGsuZ2l0aHViLmlvLw==">https://gitalk.github.io/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="注册应用">注册应用</h2>
<p>在GitHub上注册新应用，点击<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3NldHRpbmdzL2FwcGxpY2F0aW9ucy9uZXc=">这里<i class="fa fa-external-link-alt"></i></span>。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509163920.png"></p>
<p>网址就填你网站的母页面(像我的是lifeodyssey.github.io)，callback URL也是这个，剩余的随意即可。</p>
<p>点击注册之后页面跳转，其中Client ID和Client Secret在后面用到的时候复制粘贴即可。</p>
<h2 id="gitalk.swig">gitalk.swig</h2>
<p>新建<code>/layout/_third-party/comments/gitalk.swig</code>文件，并添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% <span class="keyword">if</span> page.comments &amp;&amp; theme.gitalk.enable %&#125;</span><br><span class="line">  &lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;https://unpkg.com/gitalk/dist/gitalk.css&quot;</span>&gt;</span><br><span class="line">  &lt;script src=<span class="string">&quot;https://unpkg.com/gitalk/dist/gitalk.min.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">   &lt;script <span class="built_in">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><br><span class="line">        var gitalk = new Gitalk(&#123;</span><br><span class="line">          clientID: <span class="string">&#x27;&#123;&#123; theme.gitalk.ClientID &#125;&#125;&#x27;</span>,</span><br><span class="line">          clientSecret: <span class="string">&#x27;&#123;&#123; theme.gitalk.ClientSecret &#125;&#125;&#x27;</span>,</span><br><span class="line">          repo: <span class="string">&#x27;&#123;&#123; theme.gitalk.repo &#125;&#125;&#x27;</span>,</span><br><span class="line">          owner: <span class="string">&#x27;&#123;&#123; theme.gitalk.githubID &#125;&#125;&#x27;</span>,</span><br><span class="line">          admin: [<span class="string">&#x27;&#123;&#123; theme.gitalk.adminUser &#125;&#125;&#x27;</span>],</span><br><span class="line">          id: location.pathname,</span><br><span class="line">          distractionFreeMode: <span class="string">&#x27;&#123;&#123; theme.gitalk.distractionFreeMode &#125;&#125;&#x27;</span></span><br><span class="line">        &#125;)</span><br><span class="line">        gitalk.render(<span class="string">&#x27;gitalk-container&#x27;</span>)           </span><br><span class="line">       &lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="comments.swig">comments.swig</h2>
<p>修改<code>/layout/_partials/comments.swig</code>，添加内容如下，与前面的<code>elseif</code>同一级别上：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% elseif theme.gitalk.enable %&#125;</span><br><span class="line"> &lt;div id=<span class="string">&quot;gitalk-container&quot;</span>&gt;&lt;/div&gt;</span><br></pre></td></tr></table></figure>
<h2 id="index.swig">index.swig</h2>
<p>修改<code>layout/_third-party/comments/index.swig</code>，在最后一行添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;% include <span class="string">&#x27;gitalk.swig&#x27;</span> %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="gitalkt.styl">gitalkt.styl</h2>
<p>新建<code>/source/css/_common/components/third-party/gitalk.styl</code>文件，添加内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">.gt-header a, .gt-comments a, .gt-popup a</span><br><span class="line">  border-bottom: none;</span><br><span class="line">.gt-container .gt-popup .gt-action.is--active:before</span><br><span class="line">  top: 0.7em;</span><br></pre></td></tr></table></figure>
<h2 id="third-party-styl">third-party-styl</h2>
<p>修改<code>/source/css/_common/components/third-party/third-party.styl</code>，在最后一行上添加内容，引入样式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">@import <span class="string">&quot;gitalk&quot;</span>;</span><br></pre></td></tr></table></figure>
<h2 id="config.yml">_config.yml</h2>
<p>在主题配置文件<code>next/_config.yml</code>中添加如下内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line">  githubID: github帐号  <span class="comment"># 例：asdfv1929   </span></span><br><span class="line">  repo: 仓库名称   <span class="comment"># 例：asdfv1929.github.io</span></span><br><span class="line">  ClientID: Client ID</span><br><span class="line">  ClientSecret: Client Secret</span><br><span class="line">  adminUser: github帐号 <span class="comment">#指定可初始化评论账户</span></span><br><span class="line">  distractionFreeMode: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>参考<span class="exturl" data-url="aHR0cHM6Ly9hc2RmdjE5MjkuZ2l0aHViLmlvLzIwMTgvMDEvMjAvZ2l0YWxrLw==">https://asdfv1929.github.io/2018/01/20/gitalk/<i class="fa fa-external-link-alt"></i></span>的教程。</p>
<h1 id="站点地图">站点地图</h1>
<p>俗话说得好，酒香害怕巷子深，自己做的宝贝当然是想让别人也看到的。站点地图提交到搜索引擎之后就可以被搜索引擎搜索到了。不过我这里只写了怎么提交谷歌搜索，百度站长所需要的个人信息资料太多太私密，让我不寒而栗，因此我自己不做提交，也不做讲解。</p>
<p>谷歌提交之后还可以通过analytics平台分析访客数据。</p>
<h2 id="开启seo优化">开启SEO优化</h2>
<p>打开主题配置文件，找到seo选项改为true</p>
<h2 id="生成sitmap地图">生成sitmap地图</h2>
<p>先，安装插件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br></pre></td></tr></table></figure>
<p>在博客配置文件中改url为你自己的地址</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># URL</span></span><br><span class="line"><span class="comment">## If your site is put in a subdirectory, set url as &#x27;http://yoursite.com/child&#x27; and root as &#x27;/child/&#x27;</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://lifeodyssey.github.io/</span></span><br><span class="line"><span class="attr">root:</span> <span class="string">/</span></span><br><span class="line"><span class="comment"># permalink: :year/:month/:day/:title/</span></span><br><span class="line"><span class="attr">permalink:</span> <span class="string">post/:abbrlink.html</span></span><br><span class="line"><span class="attr">permalink_defaults:</span></span><br></pre></td></tr></table></figure>
<p>并添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">sitemap:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">sitemap.xml</span></span><br></pre></td></tr></table></figure>
<p>之后hexo d -g，这时在public目录下会生成sitemap.xml。这个之后需要提交给谷歌</p>
<h2 id="提交给谷歌">提交给谷歌</h2>
<p><span class="exturl" data-url="aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS93ZWJtYXN0ZXJzLw==">点这里<i class="fa fa-external-link-alt"></i></span></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509182929.png"></p>
<p>点击添加资源</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509183019.png"></p>
<p>选择网址前缀验证，里面选标签验证，在主题配置文件中修改</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Google Webmaster tools verification setting</span><br><span class="line"># See: https:&#x2F;&#x2F;www.google.com&#x2F;webmasters&#x2F;</span><br><span class="line">google_site_verification: xxxxxxxxxxxxx # 此处改为google提供给你的HTML标签content后的内容</span><br></pre></td></tr></table></figure>
<p>这里也可以使用analytics验证，我自己用的是analytics，但是因为时间太久了我忘了怎么做了......没有特别麻烦总之。</p>
<p>回到search consle，点击左侧sitemap<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509183405.png"></p>
<p>输入站点地图的网址并提交，例如https://xxx.github.io/sitemap.xml，接下来就可以谷歌搜一下你自己的博客看看有没有被收录了。</p>
<p>参考：<span class="exturl" data-url="aHR0cHM6Ly9sdWFuemh1eGlhbi5naXRodWIuaW8vcG9zdC84MmQ5MmFkNC5odG1s">https://luanzhuxian.github.io/post/82d92ad4.html<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="robots协议">Robots协议</h2>
<p>为了防止自己的网站被恶意爬取，这一步是必须的。</p>
<p>在站点<code>source</code>文件夹下新建<code>robots.txt</code>文件，文件内容如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">User-agent: *</span><br><span class="line">Allow: &#x2F;</span><br><span class="line">Allow: &#x2F;archives&#x2F;</span><br><span class="line">Allow: &#x2F;tags&#x2F;</span><br><span class="line">Allow: &#x2F;categories&#x2F;</span><br><span class="line"></span><br><span class="line">Disallow: &#x2F;vendors&#x2F;</span><br><span class="line">Disallow: &#x2F;js&#x2F;</span><br><span class="line">Disallow: &#x2F;css&#x2F;</span><br><span class="line">Disallow: &#x2F;fonts&#x2F;</span><br><span class="line">Disallow: &#x2F;vendors&#x2F;</span><br><span class="line">Disallow: &#x2F;fancybox&#x2F;</span><br><span class="line"></span><br><span class="line">Sitemap: http:&#x2F;&#x2F;yoursite.com&#x2F;sitemap.xml</span><br></pre></td></tr></table></figure>
<p><code>Allow</code>字段的值即为允许搜索引擎爬区的内容，<code>/</code>表示网站首页，<code>/categories/</code>为分类页面，如果菜单栏还有其他选项都可以按照格式自行添加。</p>
<h1 id="阅读量与字数统计">阅读量与字数统计</h1>
<p>阅读量统计我用的是leancloud。<span class="exturl" data-url="aHR0cHM6Ly9sZndlbi5zaXRlLzIwMTYvMDUvMzEvYWRkLWNvdW50LWZvci1oZXhvLW5leHQv">https://lfwen.site/2016/05/31/add-count-for-hexo-next/<i class="fa fa-external-link-alt"></i></span>这篇文章讲的贼详细我就不再赘述了。</p>
<p>字数统计我用的https://github.com/theme-next/hexo-symbols-count-time，也是特别详细，没啥好讲的，需要注意的是这个可能需要一段时间才能显示出来效果。</p>
<h1 id="分享">分享</h1>
<p>同样是出于对隐私的担心和对国产厂商的不信任，没有采用ShareSDK和百度分享，用的AddThis，不知道啥时候会被屏蔽掉。可以直接关联到google。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20190509184840.png"></p>
<p>进去之后点share button，选一个你喜欢的样式，右上角可以切换PC和Phone显示，点continue可以选择平台，都选完了点Activate Tool,然后获取代码ID</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/1557399873308.png"></p>
<p>即public后面的，接着编辑主题配置文件，知道关键字add_this_id,添加即可</p>
<p>参考：<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC80ZWYzNTUyMWZlZTk=">https://www.jianshu.com/p/4ef35521fee9<i class="fa fa-external-link-alt"></i></span></p>
<p>以下更新于2019.5.11。</p>
<p>最后发现其实这个并没有那么好用，自己测试了一下如果是分享到微信的话，只会生成一个链接或者二维码。看了一下主题配置文件中有官方支持的三方插件，发现百度share的隐私要求没有那么严格，但是不支持https协议因此放弃。最后采用likely的方案，具体参见https://ilyabirman.net/projects/likely/。缺点就是不支持微信。不过也就这样吧，做这个博客并不是为了想要多少人看到，想要赚什么钱，只是想记录下自己成长的点点滴滴。</p>
<h1 id="图片问题的彻底解决">图片问题的彻底解决</h1>
<p>我上一篇一直没能把图片问题解决，本地插件一直不成功，然后想注册图床又因为隐私泄露的问题望而却步，突然想到github既然能作为评论系统的载体，能不能作为我图片系统的载体呢？网上一搜果然有人做过了。点击<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL01vbHVuZXJmaW5uL1BpY0dv">这里<i class="fa fa-external-link-alt"></i></span>即可开启PicGo的丝滑体验。</p>
<p>下一篇：定制优化，包括版权页、右下角的猫、升级与备份、背景图片、代码复制、文章连接唯一化、语法优化，pdf。其他花里胡哨但是我没有放到博客里的内容会统一整理出链接放在下一篇里。</p>
]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>博客更换主题、页面设置及问题解决</title>
    <url>/posts/aaf90768.html</url>
    <content><![CDATA[<p>上一篇解决了博客的生成、部署和更新的问题，实现了基本的功能。这一篇主要来解决更换主题、子页面设置和乱码三个问题。<a id="more"></a></p>
<h3 id="hexo博客主题更换">hexo博客主题更换</h3>
<p>hexo官网就提供了大量的可用<span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL3RoZW1lcy8=">主题<i class="fa fa-external-link-alt"></i></span>，我们要做的就是把主题克隆过来。我这里用的是<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tLw==">next主题<i class="fa fa-external-link-alt"></i></span>。</p>
<p>其实next主题的文档已经写的很清楚了，我这里主要写一下我对next主题所做的修改。</p>
<p>在这里先区分两个概念，站点配置文件是指根目录下的＿config.yml 文件，主题配置文件是指themes目录下的_config.yml文件。</p>
<h3 id="next主题安装">next主题安装</h3>
<p>唤出gitbash，进入站点目录，输入以下命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> your-hexo-site</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>即可下载next主题。然后打开站点配置文件,ctrl+f找到theme字段，将它的值改为next</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">theme:　next</span><br></pre></td></tr></table></figure>
<p>接下来输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean</span><br><span class="line">$ hexo g -d</span><br></pre></td></tr></table></figure>
<p>即可在网页中看到站点的外观。</p>
<h3 id="next主题设定">next主题设定</h3>
<p>这里<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tL2dldHRpbmctc3RhcnRlZC5odG1s">next主题文档<i class="fa fa-external-link-alt"></i></span>写的十分详细，我选用的是mist主题，并且进行了<strong>选择Scheme</strong>、<strong>设置语言</strong>、<strong>设置菜单</strong>、<strong>设置侧栏</strong>、<strong>设置作者昵称</strong>，在这里写一下除了官方文档之外我做的修改。</p>
<h4 id="文章摘要设置">文章摘要设置</h4>
<p>打开主题配置文件，找到如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Automatically Excerpt. Not recommend.</span></span><br><span class="line"><span class="comment"># Please use &lt;!-- more --&gt; in the post to control excerpt accurately.</span></span><br><span class="line">auto_excerpt:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">false</span></span><br><span class="line">  length: 150</span><br></pre></td></tr></table></figure>
<p>把这里的False改为true就可以启动文章显示预览了length是显示预览的长度。</p>
<p>这里我们可以通过在文章使用<!-- more -->标志来精确控制文章的摘要预览，比如这篇文章就是在这个段落的末尾添加了该标志，所以本文在首页的预览就会显示到这个段落为止。 强烈推荐使用该<!-- more -->标志来控制文章的摘要预览，因为这种方式可以让摘要也按照css文件中的样式来渲染。如果使用了自动摘要的功能，你会发现文章摘要是一大团没有样式的文本，很是难看。</p>
<h3 id="hexo页面设置">hexo页面设置</h3>
<p>这里包括添加标签、分类、404页面、关于、代码高亮、社交、数学公式、建立时间、搜索工具，站点地图等到后面添加第三方服务的时候再讲，日程这个我还没弄明白（雾）。</p>
<p>在讲之前先说一下，标签、分类、关于、404需要在主题配置文件中的menu进行开启</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  首页: / || home</span><br><span class="line">  关于: /about/ || user</span><br><span class="line">  标签: /tags/ || tags</span><br><span class="line">  分类: /categories/ || th</span><br><span class="line">  归档: /archives/ || archive</span><br><span class="line">  日程: /schedule/ || calendar</span><br><span class="line">  站点地图: /sitemap.xml || sitemap</span><br><span class="line">  公益站点: /404/ || heartbeat</span><br></pre></td></tr></table></figure>
<h4 id="标签分类关于页面">标签、分类、关于页面</h4>
<p>这三个都是一样的，标签和分类页面<span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lmlpc3NuYW4uY29tL3RoZW1lLXNldHRpbmdzLmh0bWw=">next主题文档<i class="fa fa-external-link-alt"></i></span>写的很清楚，我写一下关于页面和多标签的方法。</p>
<p>唤出gitbash，在站点根目录下输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new page <span class="string">&quot;about&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后在source目录下会有一个新的about文件夹，打开可以看到index.md，进行修改。</p>
<p>由于主题配置文件已经修改了，直接进行<code>hexo g -d</code>即可看到效果。</p>
<p>如果想给一篇文章天假多个标签的话，可以有以下两种方式</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">tags:</span><br><span class="line"><span class="bullet">-</span> PS3</span><br><span class="line"><span class="bullet">-</span> Games</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">tags: [标签1,标签2,标签3]</span><br></pre></td></tr></table></figure>
<h4 id="社交建立时间代码高亮数学公式">404、社交、建立时间、代码高亮、数学公式</h4>
<p>前四个next主题文档也都讲的很清楚，这里写一下数学公式。</p>
<p>打开主题配置文件，找到math并作如下修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Math Equations Render Support</span></span><br><span class="line">math:</span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Default(true) will load mathjax/katex script on demand</span></span><br><span class="line">  <span class="comment"># That is it only render those page who has &#x27;mathjax: true&#x27; in Front Matter.</span></span><br><span class="line">  <span class="comment"># If you set it to false, it will load mathjax/katex srcipt EVERY PAGE.</span></span><br><span class="line">  per_page: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  engine: mathjax</span><br><span class="line">  <span class="comment">#engine: katex</span></span><br></pre></td></tr></table></figure>
<p>另外，在写文章的时候也需要打开mathjax开关，以加快渲染速度</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: index.html</span><br><span class="line">date: 2019-03-07 12:01:30</span><br><span class="line">tags:</span><br><span class="line">mathjax: true</span><br><span class="line">--</span><br></pre></td></tr></table></figure>
<h4 id="搜索工具">搜索工具</h4>
<p>安装npm install hexo-generator-search:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure>
<p>在配置文件中加入：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">search:</span><br><span class="line">        path: search.xml</span><br><span class="line">        field: post</span><br></pre></td></tr></table></figure>
<p>即可启用。</p>
<h3 id="常见问题解决">常见问题解决</h3>
<p>常见问题都可以在<span class="exturl" data-url="aHR0cDovL3d3dy5haWNoZW5neHUuY29tL290aGVyLzI1Mzg0NDYuaHRt">这个博客<i class="fa fa-external-link-alt"></i></span>中找到解决方案。我这里主要说一下中文乱码的解决方案。</p>
<p>中文乱码的原因一般是没有采用utf-8编码，我自己测试了一下发现是站点配置文件没有采用utf-8。用notepad++打开，在编码选项中选择转为utf-8即可。</p>
<h3 id="结尾">结尾</h3>
<p>下一期将说明第三方服务的使用，包括评论、站点地图、阅读量、统计分析、分享等功能。</p>
<p>这一期主要参考了官方文档，因此这里不再另外写明参考文献。</p>
]]></content>
      <categories>
        <category>资料贴整理</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
        <tag>进阶</tag>
      </tags>
  </entry>
  <entry>
    <title>日本留学申请经验贴（一）之留学机构</title>
    <url>/posts/27dde70e.html</url>
    <content><![CDATA[<p>其实很早之前就想写这个帖子了。自己从去年这个时候到现在花了整整一年时间经历了留学的大大小小的事情，但是不知道从哪里讲起来。就想到哪里讲哪里吧。带有一定的主观性，仅供参考。</p>
<a id="more"></a>
<h2 id="我要不要找留学机构">我要不要找留学机构</h2>
<p>留学这件事，无论是去哪儿，很多人想到的第一件事就是要不要花钱找留学机构，其实这个答案很多，因人而异，而且现在各种机构除了传统的文书服务之外还打出了各种背景提升服务，什么跟哈佛斯坦福的线上研究、世界五百强的内推之类的，具体适不适合就更难说了。这里需要先厘清几个概念。</p>
<h2 id="中介与咨询机构">中介与咨询机构</h2>
<p>我发现很多人都很难分清中介这个概念。拿房屋中介举例子，卖房子的人给中介钱让中介帮忙卖，买房子的人给中介钱来获取信息。放到留学上，留学中介在这里一方面收外国学校的钱来给他们招生，另一方面收学生和家长的钱来帮助他们申请。显而易见，这种概念下的中介对绝大多数人来说都毫无意义，因为国外的好学校不需要中介来帮他们招生。我们平时所找的一些“中介”，更多的是指留学咨询机构。</p>
<h2 id="留学需要的材料">留学需要的材料</h2>
<p>在说要不要找留学机构之前，我想先说明留学需要什么，然后再来说明留学机构能不能帮我们完成这些东西。</p>
<p>对于绝大多数学校的申请来说，需要的硬核材料无非以下几项： - 语言成绩 - 简历 - 成绩单、在读证明、毕业证明 - 推荐信 - Paper - 陶瓷信 - Personal Statement或Statement of Purpose - Writing Sample或Research Proposal</p>
<p>申请的整个过程中还需要做的事有</p>
<ul>
<li><p>查找学校和老师信息</p></li>
<li><p>合理选校定位</p></li>
<li><p>小蜜沟通</p></li>
<li><p>填写网申</p></li>
<li><p>材料寄送</p></li>
<li><p>offer选择</p></li>
<li><p>签证、租房</p></li>
</ul>
<p>前面那一栏是申请的硬实力，也是最能决定你申请结果的因素；而后面这一栏则是申请中的细节问题，但是同样至关重要，因为选校定位不合理、材料寄送不及时而导致全聚德的人每年都有。我接下来将分开说明这两项。</p>
<p>硬核材料</p>
<p>这些材料里，在读证明和毕业证明属于学校开具的材料，只要你递交的时候注意以下几点 （1）英文翻译 （2）学校公章 （3）密封 就不会因为这两个卡你。 ### 语言成绩、简历、成绩单、推荐信、Paper 这五个材料很大程度上其实取决于你自己。无论你是想保研、考研、找工作还是出国，几乎都要用到这五个材料（或者其中一部分）。因此如果大一的学弟学妹们感到很迷茫没有目标，我建议你们就把目标定为出国，因为在我看来这是最难的。到了大三下学期的暑假，如果你成绩好有paper，但是突然不想出国了，那么去保研也是没有任何问题的；对于商科来说，有一份好的实习，不想出国去找工作也很容易。 说远了，这五个材料里，语言成绩和你的成绩单需要你自己去考，留学机构能帮到的无非是指导一下选课（对于想转专业的同学还是很有必要的，因为有些学校写明了如果想申请某个项目必须修读什么课程，但是这个去搜索名校培养方案、录取要求或者询问学长学姐也可以得到）或者提供语言培训（大多数需要收费），最后三维高不高还是看你自己的努力。 简历、推荐信、Paper这三者取决于你之前的科研、实习、竞赛以及其他一些活动（推荐信如果找任课老师写的话需要看你课堂表现），当然了简历的撰写还是有门道的，这个可以重开一个帖子，这里就不多说了。这些活动你自己不努力不积极就拿不到一个足够有分量的推荐信，发表不了Paper，也没有一个丰富的简历。留学机构在这里能做的就是所谓的背景提升项目，给你提供实习内推和科研的资源，或者帮你申请暑研，具体能帮到多少其实情况非常复杂。如果你本身非常优秀但是缺少相关的信息和资源的话，或许对你来说有很深刻的意义；除此之外，就算你通过机构的帮助去了世界五百实习强或者顶尖名校做科研，最后的结果不好，没有什么好的成果，依然不能给你的留学提供太大的帮助；更何况机构提供的这些机会并不是你报名就能够通过，同样存在着竞争，同样需要你本身足够优秀。 ### Personal Statement或Statement of Purpose＼Writing Sample或Research Proposal 这两个的话，前者其实取决于你的语言水平，后者取决于你的科研实力，关于如何撰写这两个材料可以说很长很长时间，这里先聚焦于机构。前者对于大多数学校都是很重要的材料，留学机构能够帮你最多的也是这一个材料，因此我强烈建议就算是DIY的同学也可以找一些机构进行Personal Statement或Statement of Purpose修改润色，我这里推荐一下<span class="exturl" data-url="aHR0cDovL3d3dy5wYWxtZHJpdmUuY24v">棕榈大道<i class="fa fa-external-link-alt"></i></span>，绝对物超所值。而后一个材料，文科有一些专业要求写Writing Sample，我不是很了解，因此在这里不做评论；对于大多数日本申请而言，Research Proposal绝对是最重要的材料没有之一，但是这个材料太过专业和学术化，大多数留学机构只能帮你修改语法、单词错误和一些句式，内容上只有和你申请的老师是同一个方向的在读研究生或博士生才能给出意见（当然了，很多时候你要申请的老板也会给你的Research Proposal一些修改意见），因此Research Proposal去找你的师兄师姐或者关系好的老师修改可能更好一点。有一些机构会说他们可以提供Research Proposal的修改或者代写，如果你因为这个而想和他们签约的话，请一定确认好合同条款和申请辅导老师的水平。</p>
<h3 id="申请细节">申请细节</h3>
<p>相较于硬核材料，在申请细节这一方面留学辅导机构由于有过去学生的申请数据和申请辅导经验，反而能发挥很大作用。但是另一方面，这些也可以通过学长学姐和自己去论坛、官网查询而得到。如果你所在的学校出国氛围比较浓厚的话，留学机构能够在这一项上提供的帮助反而不是很多。</p>
<h2 id="diy的判断标准">DIY的判断标准</h2>
<p>前面说了这么多，接下来我来说一个我认为的DIY理想状态。</p>
<p>如果在大四上学期刚开学的时候，你不打算跨专业申请，语言已经满足要求或者距离很小，已经确定了要申请的项目/学校/导师，手握两到三段拿得出手的科研实习经历，那么你完全不需要找辅导机构，DIY就可以，除非你想申请一些录取难度极高的项目。</p>
<p>现在就可以评判一下自己的实力，看看自己大四上学期的时候能不能达到这个标准。</p>
<h2 id="怎么选择机构">怎么选择机构</h2>
<p>如果你想选择机构的话，还会面临一个怎么选择机构的问题。相信很多人都听说过被某些留学机构坑钱的事情，我认为选择机构主要要有以下几个标准：</p>
<ol type="1">
<li>网申账号、邮箱必须掌握在你自己的手里</li>
<li>合同里有明确的退款政策</li>
<li>学生有权利主动更换导师，并且给出更换所需时间</li>
<li>该机构过往无重大黑历史（这一条在知乎、微信、微博搜一下就能知道）</li>
</ol>
<p>下一期将聚焦于日本研究生申请制度的介绍。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>日本留学申请（四）：经管类申请</title>
    <url>/posts/40e83800.html</url>
    <content><![CDATA[<p>［本文由人美心善的小姑娘蓝田双慕所著］ 本文主要介绍经管类的日本留学申请。笔者自身在申请学校的时候主要是奔着经济系去的，对日本商学院的了解不够深入，因此，笔者只能尽己所能提供自身了解的相关信息，并不能保证信息的完全囊括和绝对准确，希望此文能给有志于申请日本经管类研究生的同学带来一些帮助。</p>
<p>笔者申请的是sgu英文硕士项目，对日语入学的流程和要求不太了解，因此本文主要介绍日本经管类硕士英文项目的申请。</p>
<a id="more"></a>
<p>根据笔者主观判断，将经管类申请分为二类，一是MBA类申请，二是经营或经济类申请。</p>
<h1 id="mba-类申请">MBA 类申请</h1>
<h2 id="ｍｂａ类介绍">ＭＢＡ类介绍</h2>
<p>MBA类申请的典型特点是所需材料较简单，流程比较便捷，基本不需要撰写研究计划书，结业时应该也不需要撰写毕业论文，大致可以类比为国内的专业硕士。</p>
<p>例如，早稻田大学的商学院，除了需要提交雅思，GMAT，成绩单，推荐信外，基本只需要在系统上填写给出的五六个开放性问题。早稻田商学院大致分为金融硕士和MBA硕士，分五轮进行申请。和英美商学院相比，早稻田商学院对雅思，GMAT的硬性要求不是很高，申请难度适中。当然，商学院对费用的要求很高。早稻田商学院学制两年，预计费用600万日元，差不多35万到40万人民币。</p>
<p>除早稻田商学院外，早稻田的亚洲大平洋项目申请过程也不复杂，也不需要撰写研究计划书，同时项目费用也较高。如果希望得到早稻田大学的学历，这个项目也可以考虑考虑。</p>
<p>同为私立高校的庆应义塾大学也开设MBA项目，但其开学日期是每年的四月份,而且可能会要求申请者具有两年或两年以上的工作经验。此外，七所帝国大学也可能会有相应的MBA项目，笔者未能深入查找，读者可以登录大学的官方网站，查看学校的招生项目。</p>
<p>还有需要注意的是，东京大学的MPP项目也值得关注。MPP又称公共政策硕士，也是一种非研究型的硕士项目。MPP的申请好像也不需要撰写研究计划书。对于有志于从日本回国的同学，东京大学的声望还是具有优势的，同时东京大学作为国立高校，学费的负担较小。同时，一桥大学的MPP项目也是很好的。一桥大学在日本声望很高，但由于其规模小，因此声名局限在日本国内。此外，神户，明治，横滨等大学应该也有开设MPP项目，读者在浏览官网时可以稍稍关注一下。</p>
<h2 id="申请所需要的准备">申请所需要的准备：</h2>
<p>对于商学院申请，成绩，语言，实践经历这三项自然是越优秀越好。同时，出身校也会占一部分权重。但如果你背景不强，语言成绩不好，或是实践经历单薄，也不要气馁。在达到学校对语言等的最低标准后，你可以认真地申请一下，想办法展示你好的地方，认真地填写开放性问题，也是很有可能成功的。</p>
<h1 id="经营或经济类研究生申请">经营或经济类研究生申请</h1>
<h2 id="经管或经济类介绍">经管或经济类介绍</h2>
<p>不同于我国的管理学院和经济学院，日本将经管类分为经营部和经济部。经营部大致包括会计，审计，财务管理，市场营销，金融等。经济部大致包括微观经济，宏观经济，产业经济，城市经济，博弈论，计量经济等。有的大学将经营部和经济部合在了一个部门，有的大学将经营部和经济部分开为两个部门。</p>
<p>与理工科申请不同，理工科申请一定要套瓷，即你看到哪个教授不错，就去给他发邮件，简单介绍一下自己，说一下自己对教授的研究方向很感兴趣，希望教授收我为学生。对经管类来说，如果项目的guideline有说需要提前联系导师，即 prospective tutor， 那就提前联系；如果没有提及的话，那就可以不联系。当然，无论有无要求，提前发邮件给喜欢的导师都是有帮助的。</p>
<p>这类研究生申请一般都需要撰写研究计划书。研究计划书类似于大学毕业论文的开题报告，找一个你感兴趣的问题，写出你研究这个问题的计划。研究计划书在这类申请上发挥的作用很大，它名义上表示你未来两年研究的规划。一个可行的，有意义的研究计划书表示你未来两年不会虚度，学校给你的这个名额不会被浪费。所以一定要重视研究计划书，在撰写研究计划书的时候，请务必多找学长，学姐或老师进行参谋。</p>
<p>从我个人观点，写研究计划书前，应该先浏览学校官方网站的老师介绍，看看喜欢老师的研究方向。因为撰写研究计划书消耗精力还是比较大的，所以在选择研究课题时，可以选一些适用性较强，范围较广的研究方向。因为你喜欢的老师可能因为种种原因今年不收学生，所以保险起见，最好让自己的研究计划可以适用于多个导师。</p>
<p>以我个人的经验，申请经管类的时间跨度是很大的，同时申请难度也有点高。另外，因为各个大学开设英语项目的不一致，有时候需要从夹缝里找合适的项目。</p>
<p>首先，东京大学的经济英文项目(UTIPE项目)好像申请比较早。如果2019年十月入学（为方便，下列皆以2019年入学为准）的话，2018年8,9月好像就可以申请。但东京大学对硬件要求很高，一般都需要很好的语言和GRE成绩，申请者的素质也都很优秀，同时招生人数很少，申请难度较高。东京大学还有一个农业经济的项目，分为两轮申请，最后一轮是2019年的2,3月份。京都大学的东亚经济项目同样招生人数较少，竞争激烈。京都大学是需要你填写一个意向导师的，这里强烈推荐填写项目内的教授，不要填写属于经济部但不属于这个项目的导师。</p>
<p>除了东大，京大以外，其他帝国大学开设的英文项目种类不同。大阪大学和北海道好像是没有开设经管类的英文项目。但是我听一位学长介绍，北海道大学可以从食品工程这一类项目中找到经济学方向的导师，有心者应该可以通过此项目来学习经济。名古屋大学开设的英文项目范围较广，涵盖经济，经营项目，同时申请系统设计得比较成熟，可以进行申请。东北大学和九州大学均有经济，经营类项目，需要注意的是东北大学的会计大学院项目好像已经停办，但GPEM经济项目仍然正常运行。九州大学和东北大学的申请时间较晚，如九州大学，好像是2019年4月开始申请。私立大学中，早稻田大学的经济项目从2019年1,2月开始，但据说录取offer一直到5月才能发放。庆应义塾大学的经济项目好像从2019年5,6月开始，但可能需要到日本面试。庆应大学SFC的申请时间较早，SFC中的两个学部（综合政策学部和环境情报学部）看似与经管无关，但其中有经管的细分方向，有经济方面的优秀导师。</p>
<p>如果申请者为了多增加选择，可以申请一些综合性强的项目。比如说农业大类下有农业经济，亚太研究，东亚研究下有区域经济，公共政策下应该有宏观经济。也可以转专业申请，比如说本科商科申请个公司法方向，申请个经济学方向，都是可以的。</p>
<h2 id="申请前需要的准备">申请前需要的准备</h2>
<p>研究型硕士主要看重科研成果，对实习的看重没有那么高。但是本科没有科研成果的也不要灰心，好好写研究计划书，成功的几率还是不错的。</p>
<p>总体来说，评判标准可以分为研究计划书，绩点，语言，出身校。研究计划书是很重要的。同时，经管类研究型硕士一般都是有面试的，通过Skype等，面试的内容基本上围绕研究计划书和personal statement，需要好好准备。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>本科总结</title>
    <url>/posts/726664aa.html</url>
    <content><![CDATA[<p>写在最前面：虽然我明年才毕业，虽然还有毕业认定等等一堆事情要做，但是我所有的理论课程都结束了，大四一年就是申请、科研、语言、毕业事宜，怎么看怎么不像一个本科生的生活，所以就提前总结了吧，而且也免得明年这个时候再忘记了。</p>
<a id="more"></a>
<h2 id="我自己">我自己</h2>
<p>先来写一下我自己。</p>
<p>其实我自己是一个非常容易犹豫不决选择困难的人，同时自己非常懦弱，一直害怕和别人不一样而不被认可，害怕别人的目光。大一入学之前我就想转专业，暑假里联系好了要换宿舍，却在选课前夕放弃；经过了大一一年的摧残，背普动背的要死了，终于又想转专业，和班主任说明了心思，却又在选课的时候踟蹰犹豫，最后决定先选两门课上上看看——上完之后，我真的后悔真的想转了，而且变成了想转数学；但是却不想延期毕业——虽然其实我可以不延期毕业的；现在我大三结束了，在选秋季学期课程的时候，我认认真真的算了一下学分，发现我是可以延期两年辅修CS，可是我已经没有勇气了啊，两年，说出去大学本科六年才能毕业，怕不是要成为别人口中的笑料——我跟我爸妈解释专业到底是干什么，都花了很长时间，在爸妈眼里，辅修和没有辅修看起来是一样的，反而后者代表着我儿子没有能力正常毕业。当然也是因为一直不喜欢海大和青岛，我想我毕业的时候一点都不会不舍，反而非常解脱，我终于能走了，我终于能离开这个让我讨厌了这么久的地方了。</p>
<p>这还表现在我对于出国的决定上，我很早很早就开始想出国了，但是只有在分手之后才真正的下定决心，飞速签了棕榈定了雅思，阻断了自己所有的退路，申请季拿不到offer，就等着灰头土脸的回家吧。</p>
<p>我还是一个自制力、意志力都很差的人。最突出的表现就是，我大学三年没有一个我全身心投入进去的事情。自学CS就学了一点皮毛，甚至皮毛都算不上，专业课不好好听全靠背背背，看paper就拿谷歌翻译一下一目十行，做项目就想着抄代码，借来的书从来没有好好读过，走马观花地看了很多领域的东西，没有坚持完成过任何一个计划。这么说似乎不是特别好理解，拿数字说话，Ubhind(一个手机使用的监控软件)告诉我，我平均五分钟解锁一次手机。我一直想努力改掉这个毛病，但是似乎毫无成效。</p>
<p>我大学里唯一坚持下来的两件事情，就是国赛和美赛。从一开始坚持到最后，美赛论文截止提交两小时前坐在那里静下心来认认真真的改latex代码的我，简直不像是我。感谢陪我做这两次比赛的队友，你们让我感受到了同伴的力量，让我坚持下来。希望未来的路上，我能找到像你们一样好的同伴。</p>
<p>这是我这个人性格里，最能影响我的两点了。</p>
<p>大学里只是简简单单的有一点点成绩，接下来就写一下经验吧。</p>
<h2 id="关于方向">关于方向</h2>
<p>很多老师和同学都说我适合去搞研究，从高中开始，多到我觉得，是不是我除了学习/科研之外，没有任何长处，所以他们想夸我的话，就只能说这个了2333.我在定方向的时候，反而没有受到这个的太多影响，因为我并没有找到一个能让我热爱的的问题或者方向，让我如饥似渴的去学习相关知识迫不及待的去解决它。</p>
<p>每个人来到大学都会有一个问题：我毕业之后究竟要干什么？可能很多人到了毕业也没想清楚，说实话我也不清楚，但我知道了我喜欢的事情究竟是什么样子，和我不喜欢什么事情。</p>
<p>大学毕业的方向，可以大概的分为四类：考研保研、出国留学、考公务员、自主创业、直接就业这几条，大一一年少去参加各种无意义的活动。前两者都需要你去实验室，创业就业需要你的实习经历，不要把宝贵的时间浪费在毫无意义的各种活动上。如果你的目标只是正常毕业，那么修读完所有学分+不违反校规校纪就可以了，剩下的所有被强制要求的活动你都可以不去。</p>
<h2 id="关于课程与培养方案">关于课程与培养方案</h2>
<p>我这个人记忆力不是特别好，我个人喜欢推理、运算与逻辑。数学吸引我的一个方面就是他的完整性，最为人知的比如欧式几何，从五个基本公理就可以推出剩下所有的东西。如果说一门课程能够用一条清晰的线索从头穿到尾，一条做不到三四条也行，那么我非常喜欢学习这种课程并且记忆效果会非常好；但是我所学的大多数专业课，都不能做到这一点，例如普通动物门这门课，我丝毫看不出上一个门的动物特点和下一个门的动物特点有任何逻辑上的联系。我知道这门课只能这样讲，我不觉得孙老师和艾老师讲课讲的不好水平不行，只是我真的很难记下这种结构的东西。就像我的手里只能拿一条线，不管这条线多长多粗，我都能很好的掌握它，但是现在这门课需要我同时拿着十条线，我强行去做的后果要么是只能拿一根背不完，要么只能从每根线上截一部分接到另一个地方——例如背混了桡足类里面哲水蚤、猛水蚤、剑水蚤的区别，考试现场创造出来一只第一触角长度和体长差不多的猛水蚤，手动狗头。</p>
<p>说完了我自己，再来说说培养方案和它的课程。现行培养方案里面的课程安排我相信已经是老师能够做到的最好的情况了，自己不在其位不谋其政，可能下面的意见有点何不食肉糜。</p>
<p>1.专业课导论。</p>
<p>已经上完所有理论课的我已经能够用一条线将所有的课程穿起来，虽然不知道对不对，但是在专业课导论上我没有听见过类似的描述。下列描述单指现在的（2018.7.8）中国海洋大学水产学院海洋资源与环境专业：</p>
<p>海洋资源与环境是海洋学下属的一门应用型学科，学科的基本问题是渔业资源问题。具体到中国渔业资源衰退的背景，就是渔业资源衰退的问题，渔业资源衰退到什么程度，渔业资源为什么会衰退，怎么样恢复渔业资源，怎么样维持渔业资源长期稳定的开发利用，是这个问题的四个方面。</p>
<p>如果老师能在专业课导论上先说明这个，然后再按照这四个方面去引出各个实验室来介绍自己的东西，我们就会对本专业有一个很好的了解。</p>
<p>2.通识教育</p>
<p>中国海洋大学一直坚持“通识为体，专业为用”，那我也分开说好了。先说通识教育部分。</p>
<p>我和行远书院的想法不谋而合，通识教育不是说 你一个学理工科的学点文科的东西，学文学点理工科的就叫通识教育，而是说我在本科毕业以后的生活中，当我需要去学习之前没有教过的东西的时候，我有这一份学习的能力。接下来具体说一下什么样的通识教育才是我眼里的通识教育。</p>
<p>（1）认识事物需要一定的认知方式和精神，例如批判能力、实证能力、推理能力等等</p>
<p>（2）人们已经很少用到能用单一的能力或知识来解决一个特定的问题</p>
<p>（3）黑箱式的工具会越来越多，但是了解背后的原理就用这些工具会产生错误</p>
<p>所以，通识教育应该有三个方面的特点。第一点是对于思维方式的培养，第二点是对于知识和技能的培养。其中知识和技能的培养，不要求精深，但是要求广博和基础。广博至理工农医文商艺体，基础可以视专业而定，但是体系一定要搭建好。例如正确的分辨朋友圈谣言，理解国家政策对于房价的影响，看得懂渔业资源评估论文里面的数学公式。</p>
<p>3.专业课</p>
<p>专业既然为用，就是说我们学到的东西里，肯定有应用型的技能或者技术（插播一句,我觉得科学、技术和工程的区别，应该给每个高考完填报志愿的人好好讲一下）。这个技能或者技术可以是针对于实际问题，例如软件的开发，也可以是针对科学研究中遇到的问题，例如生物统计学。我的意见是，既然是针对问题的课程，那就针对问题去考核。在课程开始之初就确定问题，例如布置一个小组任务或者个人任务，期末的时候通过看同学们问题解决的怎么样来看学习的情况。例如我们很多课程里有针对分类的知识，如果实验条件允许的话，把这些东西让同学们实际去分类鉴定，能够分出来多少就给多少分，学习的效果会比单纯的期末考和好得多。</p>
<p>4.我眼里一个好的培养方案</p>
<p>（1）公共基础比重增加且不设具体课程要求，只设置课程门类和总学分要求，例如总共要学40个学分的课，19个学分的数学，10个学分的化学物理，10个学分的英语，剩余10个学分任意选择。</p>
<p>（2）对于有联系的专业课，安排在相邻学期，例如植物学与藻类学，水生生物学与海洋浮游生物学，渔业资源与渔场学和生物资源评估。</p>
<p>（3）增加项目考核的方式。</p>
<p>5.学习这么多课程的意义</p>
<p>常常有人说学这个有什么用，我也在想到底有什么用。有用是绝对有用的，但是很难体会到。比如我在餐桌上已经可以讲一下吃的是什么东西，看文献的时候专业名次可以不依靠翻译，给身边的人科普海洋生态文明建设；那一大堆公共基础课呢能让我遇见不懂得东西的时候，知道我该去翻偏微分方程的数值解法、数量经济学还是拉汉世界鱼类系统名典。这或许就是学习这些东西的意义吧。</p>
<h2 id="关于本科生科研与竞赛">关于本科生科研与竞赛</h2>
<p>这一部分我一直不知道该怎么去讲，就索性想到啥写啥。</p>
<p>1.比起经历，更重要的是结果。</p>
<p>2.发论文不是目的，体验完整的科研流程才是目的。</p>
<p>3.当你不知道要选择哪个实验室的时候，可以先排除不喜欢的方向，或者去和每个实验室的PI聊天了解情况。</p>
<p>4.大胆的勾搭老师，即便你什么都不会。谁不是从零基础过来的呢。</p>
<p>5.一定要以解决问题为目标。看到一篇论文的方法可以应用在你的问题上面时就去用，不要把时间浪费在学习各种论文的方法上。</p>
<p>6.不要把竞赛当成项目，不要把时间浪费在参加竞赛上，竞赛只是锦上添花的东西。</p>
<p>7.通过本研和竞赛掌握一定的技能和方法。</p>
<p>8.通过这些活动，你会遇见和你一样的人，大神见大神。常有人问我各种队友怎么找啊，我只能说，你想成为什么样的人，你就会遇见什么样的人。</p>
<p>9.申请旁听所在实验室的组会让你对于科研有更明确的认识。</p>
<p>10.没有见到过凌晨四点五点学校的本科生活，才是不完整的本科生活。</p>
<h2 id="结语">结语</h2>
<p>时间过得好快，希望我的最后一年，能够不再像前三年一样，充满遗憾。</p>
<p>如果有错误或者冒犯之处还请海涵，如果有能帮到你的地方，不胜荣幸。</p>
]]></content>
      <categories>
        <category>学习经验</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>Cousera机器学习基石第二周笔记 Machine Learning Foundation Week 2 Note in Cousera</title>
    <url>/posts/2c9001a2.html</url>
    <content><![CDATA[<p>Learning to Answer Yes/No <a id="more"></a></p>
<h1 id="perceptron-hypothesis-set">Perceptron Hypothesis Set</h1>
<p>Example:Credit Approval Problem Revisited</p>
<h2 id="a-simple-hypothesis-setthe-perceptron">A Simple Hypothesis Set:the 'Perceptron'</h2>
<ul>
<li><p>For <strong>x</strong>=<span class="math inline">\((x_1,x_2,...,x_d)\)</span> 'feature of customer',compute a weighted'score' and</p>
<p>&lt;center&gt; <span class="math inline">\(approve \quad credit\quad if \sum_{i=1}^{d} w_i x_i&gt;threshold\)</span>&lt;center&gt;</p>
<p>&lt;center&gt; <span class="math inline">\(deny \quad credit\quad if \sum_{i=1}^{d} w_i x_i&lt;threshold\)</span>&lt;center&gt;</p></li>
<li><p><span class="math inline">\(y:\{+1(good),-1(bad)\}\)</span>,0 ignored-linear formula<span class="math inline">\(h\in H\)</span>are</p>
<p>&lt;center&gt;<span class="math inline">\(h(x)=sign((\sum_{i=i}^{d}w_i x_i)-threshold)\)</span>&lt;center&gt;</p></li>
</ul>
<p>this is called'<strong>perceptron</strong>'hypothesis histroically</p>
<h2 id="vector-form-of-perceptron-hypothesis">Vector Form of Perceptron Hypothesis</h2>
$$
<span class="math display">\[\begin{split}
h(x)&amp;=sign((\sum_{i=1}^{d}w_i x_i)-threshold)\\
   
    &amp;=sign((\sum_{i=1}^{d}w_i x_i)+\underbrace{(threshold)}_{w_0}\cdot\underbrace{(+1)}_{x_0})\\
   
    &amp;=sign(sum_{i=0}^{d}w_i x_i)\\
    &amp;=sign(W^T x)
\end{split}\]</span>
<p>$$</p>
<ul>
<li>each'tall'<strong>w</strong> represents a hypothesis <em>h</em> &amp;is multiplied with 'tall' <strong>x</strong>——will use tall versions to simplify notation</li>
</ul>
<p>Q:What does <em>h</em> look like</p>
<h2 id="perceptrons-in-r2">Perceptrons in <span class="math inline">\(R^2\)</span></h2>
<p><strong>perceptrons<span class="math inline">\(\Leftrightarrow\)</span>linear(binary) classifiers</strong></p>
<h1 id="perceptron-learning-algorithm-pla">Perceptron Learning Algorithm (PLA)</h1>
<h2 id="select-g-from-h">Select <em>g</em> from H</h2>
<ul>
<li>want: g<span class="math inline">\(\approx\)</span>f(hard when f unkown)</li>
<li>almost necessary:g<span class="math inline">\(\approx\)</span>f on D,ideally <span class="math inline">\(g(x_n)=f(x_n)=y_n\)</span></li>
<li>difficult:H is of infinite size</li>
<li>idea: start from some <span class="math inline">\(g_0\)</span>,and 'correct' its mistakes on D</li>
</ul>
<h2 id="perceptron-learning-algorithm">Perceptron Learning Algorithm</h2>
<p>For t=0,1,...</p>
<p>1. find a mistake of <span class="math inline">\(w_t\)</span> called<span class="math inline">\((x_{n(t)},y_{n(t)})\)</span></p>
<p>sign<span class="math inline">\((W^{T}_t X_{n(t)})\not=y_{n(t)}\)</span></p>
<p>2. (try to) correct the mistake by</p>
<p><span class="math inline">\(w_{t+1}\leftarrow w_t+y_{n(t)}x_{n(t)}\)</span></p>
<p>...until no more mistakes</p>
<p>return last <strong>w</strong> (called <span class="math inline">\(w_{PLA}\)</span> )as <em>g</em></p>
<p>My question:why determinant is like vector</p>
<h2 id="pratical-implementation-of-pla">Pratical implementation of PLA</h2>
<h3 id="cyclic-pla">Cyclic PLA</h3>
<h2 id="some-remaning-issues-of-pla">Some Remaning issues of PLA</h2>
<p>###　Algorithmic:halt(no mistake)? - naive cyclic:?? - random cyclic:?? - other variant:??</p>
<h3 id="learninggapprox-f">Learning:<span class="math inline">\(g\approx f\)</span> ?</h3>
<ul>
<li>on D, if halt,yes(no mistake)</li>
<li>outside D:??</li>
<li>if not halting:??</li>
</ul>
<h1 id="guarantee-of-pla">Guarantee of PLA</h1>
<h2 id="linear-separability">Linear Separability</h2>
<ul>
<li>if PLA halts(i.e. no more mistakes), (necessary condition)D allows some <strong>w</strong> to make no mistakes</li>
<li>call such D linear separable</li>
</ul>
<h2 id="pla-fact-w_tgets-more-aligned-with-w_f">PLA Fact: <span class="math inline">\(w_t\)</span>Gets More Aligned with <span class="math inline">\(w_f\)</span></h2>
<ul>
<li><p><span class="math inline">\(w_f\)</span> perfect hence every <span class="math inline">\(x_n\)</span> correctly away from line: <span class="math inline">\(y_{n(t)}w_f^T x_{n(t)}\ge \underset{n}{min} y_{n(t)}w_f^T x_{n(t)}&gt;0\)</span></p></li>
<li><p><span class="math inline">\(w_f^T w_t\uparrow\)</span>by updating with any<span class="math inline">\((x_{n(t)},y_{n(t)})\)</span> <span class="math display">\[
\begin{split}
w_f^Tw_{t+1}&amp;=w_f^T(w_t+y_{n(t)}x_{n(t)})\\
&amp;\ge w_f^Tw_{t}+\underset{n}{min}  y_{n(t)}w_f^T x_{n(t)}\\
&amp;&gt; w_f^Tw_{t}+0
\end{split}
\]</span></p></li>
</ul>
<p><span class="math inline">\(w_t\)</span> appears more algned with <span class="math inline">\(w_f\)</span></p>
<p>Q:the length of vector</p>
<h2 id="pla-fact-w_t-does-not-grow-too-fast">PLA fact: <span class="math inline">\(w_t\)</span> Does Not Grow Too Fast</h2>
<p><span class="math inline">\(w_t\)</span> changed only when mistake</p>
<p><span class="math inline">\(\Leftrightarrow sign(w_t^Tx_{n(t)})\not=y_{n(t)}\Leftrightarrow y_{n(t)}w_t^Tx_{n(t)}\le 0\)</span></p>
<ul>
<li>mistake ‘limits’<span class="math inline">\(||w_t||^2\)</span> growth,even when updating with’longest’ <span class="math inline">\(x_n\)</span> <span class="math display">\[
\begin{split}
||w_{t+1}||^2&amp;=||w_t+y_{n(t)}x_{n(t)}||^2\\
&amp;=||w_t||^2+2y_{n(t)}w_t^Tx_{n(t)}+||y_{n(t)}x_{n(t)}||^2\\
&amp;\le ||w_t||^2+0+||y_{n(t)}x_{n(t)}||^2\\
&amp;\le||w_t||^2+\underset{n}{max}||y_nx_n||^2
\end{split}
\]</span></li>
</ul>
<p>start from <span class="math inline">\(w_0=0\)</span>,after<em>T</em> mistake corrections, <span class="math display">\[
\frac{w_f^T\quad w_T}{||w_f||\quad||w_T||}\ge \sqrt{T}\cdot constant
\]</span></p>
<h2 id="novikoff-theorem">Novikoff theorem</h2>
<p>ref:Lihang<statistic learning approach>page 31</statistic></p>
<p>设训练数据集<em>T</em>=<span class="math inline">\({(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)</span>是线性可分的，其中<span class="math inline">\(x_i\in\mathcal{X}=R^n,y_i\in\mathcal{Y}={-1,+1},i=1,2,...,N\)</span>,则</p>
<p>（1）存在满足条件<span class="math inline">\(||\hat{w}_{opt}||=1\)</span>的超平面<span class="math inline">\(\hat{w}_{opt}\cdot\hat{x}+b_{opt}=0\)</span>将训练数据集完全正确分开，且存在<span class="math inline">\(\gamma&gt;0\)</span>，对所有<span class="math inline">\(i=1,2,...,N\)</span> <span class="math display">\[
y_i(\hat{w}_{opt}\cdot\hat{x}_i)=y_i(\hat{w}_{opt}\cdot\hat{x}_i+b_{opt}\ge\gamma
\]</span></p>
<p>(2)令<span class="math inline">\(R=\underset{1\le i\le N}{max}||\hat{x}_i||\)</span>,则感知机算法在训练数据集上的误分类次数<em>k</em>满足不等式 <span class="math display">\[
k\le (\frac{R}{\gamma})^2
\]</span></p>
<h1 id="non-separable-data">Non-Separable Data</h1>
<h2 id="more-about-pla">More about PLA</h2>
<p>CONS:maybe not’linnear separable’,and not fully sure how long halting takes</p>
<h2 id="learning-with-noisy-data">Learning with Noisy Data</h2>
<h2 id="line-with-noise-tolerance">Line with Noise Tolerance</h2>
<p>NP-hard</p>
<h2 id="pocket-algorithm">Pocket Algorithm</h2>
<p>Find the least mistakes until iterations</p>
<h1 id="summary">Summary</h1>
<ul>
<li><p>Perceptron Hypothesis Set</p>
<p>hyperplanes/linear classifiers in <span class="math inline">\(\mathcal{R}^d\)</span></p></li>
<li><p>Perceptron Learning Algorithm(PLA)</p>
<p>correct mistakes and improve iteratively</p></li>
<li><p>Guarantee of PLA</p>
<p>no mistake eventually if linear separable</p></li>
<li><p>Non-Separable Data</p>
<p>hold somewhat’best’weights in pocket</p></li>
</ul>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Cousera</tag>
        <tag>林轩田</tag>
      </tags>
  </entry>
  <entry>
    <title>清华大学《研究生学位论文的选题方法》讲座实录</title>
    <url>/posts/307feb93.html</url>
    <content><![CDATA[<p>讲座地址：https://www.bilibili.com/video/av94346515</p>
<a id="more"></a>
<h1 id="学位论文">学位论文</h1>
<p>博士学位论文要求</p>
<ol type="1">
<li>掌握坚实宽广的基础理论和系统深入的专门知识</li>
<li>具有独立从事科学研究工作的能力</li>
<li>在科学或专门技术上做出创造性的成果</li>
</ol>
<p>硕士学位论文要求</p>
<ol type="1">
<li>掌握坚实的基础理论和系统的专门只是</li>
<li>具有独立从事科学研究工作或独立担负专门技术工作的能力</li>
</ol>
<p>研究生培养时间表：</p>
<table>
<thead>
<tr class="header">
<th>时间</th>
<th>博士生</th>
<th>硕士生</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>课程学习，了解本学科基础知识</td>
<td>同左</td>
</tr>
<tr class="even">
<td>2</td>
<td>选定学位论文研究题目，开展研究工作</td>
<td>同左</td>
</tr>
<tr class="odd">
<td>3</td>
<td>开展研究工作</td>
<td>学位论文答辩</td>
</tr>
<tr class="even">
<td>4</td>
<td>开展研究工作</td>
<td></td>
</tr>
<tr class="odd">
<td>5</td>
<td>学位论文答辩</td>
<td></td>
</tr>
</tbody>
</table>
<h1 id="选题的重要性">选题的重要性</h1>
<p>##　科研三观</p>
<ol type="1">
<li>学术界的发展规律是什么？：推陈出新，创新至上</li>
<li>研究生阶段要实现的目标是什么？：追求卓越，锻炼能力</li>
<li>什么样的科学研究是有价值的：创造知识，服务国家</li>
</ol>
<p>##　科研问题</p>
<p>科学研究围绕着提出问题和回答问题而展开</p>
<p>评价研究问题的标准</p>
<ul>
<li>重要性：是否是学科中的重要问题</li>
<li>创新性：是否为学科创造新的知识</li>
<li>前沿性：是否有可能引领未来潮流</li>
<li>探索性：是否尚未得到充分的探索</li>
<li>基础性：是否对相关方向产生影响</li>
<li>复杂性：是否具备三年探索的体谅</li>
<li>系统性：是否可分解为多个子问题</li>
<li>可行性：是否具备短期实现可能性</li>
<li>承接性：是否具有良好的前期积累</li>
<li>适合性：是否能够发挥自己的能力</li>
</ul>
<p>###　重要性</p>
<p>评估一下该问题在学科发展主脉络上的问题</p>
<p>If you do not work on an important problem, it is unlikely you will do important work--Richard Hamming</p>
<ol type="1">
<li>悬而未决的重要挑战</li>
<li>制约发展的关键瓶颈</li>
</ol>
<h3 id="创新性">创新性</h3>
<p>研究该问题应该突破人类知识的边界，创造新知识</p>
<h3 id="前沿性">前沿性</h3>
<p>判断该问题当前在本学科发展大潮中的位置</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309121010.png"></p>
<p>###　探索性</p>
<p>评估目前问题的解决程度和未来可能的创新空间</p>
<h3 id="基础性">基础性</h3>
<p>该问题对于本学科和相关学科产生广泛深远的影响</p>
<h3 id="复杂性">复杂性</h3>
<p>该问题有足够的体量，可拆分为若干个创新点</p>
<p>###　系统性</p>
<p>各个子问题之间密切关联、有机衔接、浑然一体</p>
<h3 id="可行性">可行性</h3>
<p>该问题应该具备在短期内被解决的可能性</p>
<h3 id="承接性">承接性</h3>
<p>课题组有良好的工作积累，能够提供最大的助力</p>
<p>###　适合性</p>
<p>自己对该问题感兴趣，能够充分发挥出自己的优势</p>
<h1 id="如何进行选题">如何进行选题</h1>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309135345.png"></p>
<h2 id="文献调研">文献调研</h2>
<p>勤读文献，及时更新知识结构，站在领域前沿</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309171527.png"></p>
<h3 id="经典著作">经典著作</h3>
<p>每个都要读，一个读三遍才读懂(ORZ)</p>
<h3 id="期刊杂志">期刊杂志</h3>
<p>同时阅读领域内外的期刊杂志，注意学科交叉</p>
<h3 id="会议论文集">会议论文集</h3>
<p>时效性高、质量上乘，是最佳平衡点</p>
<h3 id="学者主页">学者主页</h3>
<p>了解本学科顶级学者目前正在研究的问题</p>
<h3 id="社交媒体">社交媒体</h3>
<p>Twitter, blog, FB, BBS</p>
<h3 id="预印网站">预印网站</h3>
<p>实效性最高，质量最参差不齐</p>
<h3 id="粗度与精读">粗度与精读</h3>
<p>80%的文章看标题</p>
<p>14%的文章阅读标题和摘要</p>
<p>5%正文</p>
<p>1%所有细节</p>
<h3 id="深入思考">深入思考</h3>
<p>去粗取精，构建知识体系，找到关键文献节点，形成个人思考</p>
<p>##　独立性</p>
<p>坚持独立自主，不要老是问老师师兄师姐做啥，别把希望寄托在别人身上</p>
<h2 id="勇气">勇气</h2>
<p>不畏风险，做具有挑战性的问题</p>
<p>高风险=高回报</p>
<p>高门槛=低竞争</p>
<p>One of the characteristics of successful scientists is having courage. Once you get your courage up and believe that you can do important problems, then you can. If you think you can’t,almost surely you are not going to.</p>
<p>如果你觉得你做不出来，就基本做不出来了</p>
<p>曲高和寡，领先于时代的人往往不被理解</p>
<h2 id="理性选择">理性选择</h2>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/20200309173654.png"></p>
<p>承接性跟合适性不重要，因为你把它做出来你就有能力和基础了（也许这就是大佬吧）</p>
<p>问题更重要</p>
<h1 id="总结与qa">总结与Q&amp;A</h1>
<h2 id="总结">总结</h2>
<ul>
<li>选择学位论文题目是研究生阶段的重大战略性决策，必须高度重视。越早越好，定了就不要换，后面基本上就不要变了</li>
<li>弄懂什么才是好的研究题目，通过充分的调研和思索，尽可能多找出候选题目，</li>
<li>独立思考，理性决策，有勇气选择有挑战性的题目</li>
</ul>
<h2 id="qa">Q&amp;A</h2>
<ol type="1">
<li>怎么找1%值得精读的文献？</li>
</ol>
<p>一开始100%都要读标题，然后再选14%读摘要，慢慢往下漏；另一种策略是找师兄和老师推荐文献，把他们作为入口。读经典的文章，读大佬的文章，读新的文章</p>
<ol start="2" type="1">
<li>如果实验室没有基础怎么办？</li>
</ol>
<p>看研究性质，计算机方向很多数据都是公开的，开辟新方向问题不大；生物、机械等领域需要大型仪器设备的研究，实验室基础就很重要。</p>
<ol start="3" type="1">
<li>社会科学的选题方式和理工科一样吗？</li>
</ol>
<p>没有太大区别</p>
<ol start="4" type="1">
<li>如果课题难度过大，进展缓慢，需要换课题吗？</li>
</ol>
<p>和时间点相关，如果刚开始，用十条原则打分，觉得确实不行，那就换吧；第四年第五年就要慎重，换课题可能延期。</p>
<ol start="5" type="1">
<li>如何平衡文献调研、理论学习和实际搞科研的时间？</li>
</ol>
<p>也取决于时间点，一二年级文献调研和理论学习比较重要，70%+，三四年50%</p>
<ol start="6" type="1">
<li>三五年研究生生涯怎么规划？</li>
</ol>
<p>看个人的基础。最好按照标准模式来，第二年一定要把题目定下来，第一二年学完所有基础知识，二三四五进行创造知识。</p>
<ol start="7" type="1">
<li>先看论文再提问题还是先提问题再看论文？</li>
</ol>
<p>两种都是，可以看文章来想idea；也可以先想idea，想自己该怎么解决，避免自己的思维被束缚，再去读文章验证自己的idea，看看自己想的别人有哪些没做过，如果都没做过，那就去做吧233。</p>
<h1 id="附录如何阅读文献">附录：如何阅读文献</h1>
<p>(这个好像是知乎还是微博某位老师写的)</p>
<p>最近很多人问我该如何阅读文献，才能提高速度和效率，然后做文献综述。其实读文献是一件很枯燥的事情，而且往往走进迷宫，比如会经常在一个相关的领域里越看越多，走向枝节，往往花费掉一两周的时间，把握不好和自己选题的关系，觉得进度很慢。其实这是每个人都会遇到的困境，有的时候很难取舍。</p>
<p>我个人的体会是：本科生、硕士生和博士生采取不同的阅读方式和文献梳理方式。阅读英语文献第一点是英文要足够好，靠大量阅读，英语的水平也可得到实质性的提高。</p>
<p>本科生阅读相对简单，如果你给本科生上过课，或者经常看一些教授的本科生讲义，你会发现，一般推荐的必读文献都是一些写的很经典的教材（通俗易懂，英语写得很朴实，不是拽文采那种），或者引用率非常高的一些学术论文。我建议本科生的涉猎广一些，学科内部每个领域都尝试读一下，不求多么高深的领悟，但要明白每个故事的完整性。有时候“浅尝辄止”也不是一无是处的，在有限的时间，多读一些topic，这样以后读研究生才会发现自己的兴趣点。</p>
<p>硕士生是初级研究阶段，一般硕士生周期很短，毕业之后也未必做学术。但是作为初级研究者我建议在老师的指导下，选定一个合适的题目，然后开始选文献。这个阶段选文献就像捡树叶，要懂得取舍。这个过程可以发挥导师的作用让老师推荐（实际老师在上课的时候也会提供一些参考文献目录），也可以从本专业最基本的几本期刊入手，比如先选择3－5本期刊把最近10年的相关研究先找出来，然后根据和自己研究的亲疏程度进行精读和囫囵吞枣式阅读的分类。这个时候就像捡树叶不能只看脚底下，要看清这片叶子是从哪棵树掉下来的。这棵树就是你的研究领域，这里面有你的研究主题。换句话说，硕士生可以“只见树木，不见森林”。</p>
<p>博士生是独立研究阶段的开始，这时候和导师是合作关系。这个阶段，了解一个概念，一般会从实证文章入手，但初始很难判断文章好坏，大概读10-20篇，对概念理论脉络可形成初步认识（从树叶到树枝）。100篇是质变阶段可以把概念讲清楚（看清树干轮廓），这时候文献的好坏你会很快区分。读到500篇却会变茫然，因发现树根了，一个概念所依赖土壤都在这里，这就是地理哲学部分。 我建议优秀的博士生一定要从本源上看清楚问题，忽视本体论的做法，认识论容易出现偏差，因为理论有不同的内生性背景因素。并且博士生不能只爱一棵树，博士生读文献有个tool是专业的Handbook，这是比较general的了解一个专业的方法，我认为博士的阅读要广度和深度兼顾。树与树之间成长的环境差异可以是很大的，这时候很考验对交叉学科的了解和哲学流派的掌控。我认为一周期的PhD，大概是2年在阅读（我默认此人对这个领域在硕士阶段已经有初步了解）。厚积薄发的好处不像处理数据可直接看出效果，但是我想这种受益是一生的。</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>狼总访谈</title>
    <url>/posts/6ff151e3.html</url>
    <content><![CDATA[<p>最近看到杨振宁在国科大的访谈上说“一个年轻的研究生最重要的一件事情是什么？其实不是你学到哪些技术，而是要使你自己走进未来五年、十年有大发展机会的领域，这才是你做研究生时所要达到的目标”，想起来自己大一找狼总访谈时，狼总说自己做出退博的一个重要原因就是能看到教培行业存在的问题，并且知道自己能够解决这个问题。</p>
<p>因此重新把这篇当时的访谈作业发出来，希望自己未来再站在十字路口时能够做出一个不令自己后悔的决定，也希望能帮到看这篇文章的你。</p>
<p>写的比较粗浅，切莫见笑。</p>
<a id="more"></a>
<p>朱宇,现担任北京<em>新东方</em>学校优能一对一部总监、<em>新东方</em>迅程K12项目部总监和<em>新东方</em>东方优播公司CEO</p>
<h1 id="p1学习及工作经历">P1学习及工作经历</h1>
<h2 id="学校经历">学校经历</h2>
<p>2004年竞赛保送到清华大学材料科学与工程系，大一主要忙于学业，绩点排名全系第二。第二年竞选为学生会副主席，大三周转于学校各类社团活动并参与了团委的志愿者活动，大四直博到系主任张政军（教育部长江学者特聘教授，现任清华大学材料科学与工程学院院长）的科研团队，同时由于由宿舍朋友推荐08年3月开始在新东方兼职</p>
<p>08年9月到10年9月一边在张政军的团队中从事材料科学基础研究，一边在新东方任职，10年9月从清华博士退学，在新东方全职工作</p>
<h2 id="新东方工作经历">新东方工作经历</h2>
<p>开始时初中数学物理老师</p>
<p>08年9月成为初中物理组组长</p>
<p>09年4月成为高中物理组组长</p>
<p>09年9月开始负责北京新东方优能中学初中部所有数理化生四科老师的招聘和培训</p>
<p>10年4月成为北京新东方优能中学高中数学组的组长 同时负责招聘培训的统一协调工作</p>
<p>11年3月成为优能中学初中数理化部分项目的主管，独立负责初中数理化的运营</p>
<p>12年4月成为优能中学高中所有科目项目的经理</p>
<p>14年4成为整个北京所有校区优能中学的主管，负责招生运营主管工作</p>
<p>15年4月调任北京优能一对一部，成为整个北京新东方优能一对一部的总监至今</p>
<p>成名作《教育培训行业现状分析十五篇》，系统分析了新东方、学而思、学大的不同，各自的发展营销模式以及互联网+的局势下传统教培行业的发展方向。并借由此建立了一套行之有效的制度，使得新东方优能中学从星星之火成燎原之势，完美反杀学而思</p>
<h1 id="p2qa">P2Q&amp;A</h1>
<p>##放弃清华博士去新东方的原因</p>
<ol type="1">
<li><p>能够看出来新东方这个教配行业背后的大量隐患以及机会</p></li>
<li><p>当时新东方中学部处于蓬勃发展状态，优秀的数学物理老师急缺，会在新东方获得更多发展机会</p></li>
<li><p>由于在新东方的两年兼职，对新东方产生了情感‘</p></li>
<li><p>在科研阶段个人想法兴趣的改变，不适应国内的科研环境。相比之下觉得在教培行业能让自身获得更大发展</p></li>
</ol>
<h2 id="教培行业的待遇">教培行业的待遇</h2>
<p>优能中学部老师平均年薪25万，大量30万，而且每年会有二十人左右八十万，两人超过百万，老师之外的基层人员每年五万到六万</p>
<p>一对一部的基层人员十万到十五万</p>
<p>顶层总监年薪一百万以上</p>
<h2 id="最希望招聘员工所具有的特点">最希望招聘员工所具有的特点</h2>
<p>1） 执行力强。没有拖延症说干就干干净利落</p>
<p>2） 责任心强。具有对团队和自己负责任的想法。</p>
<p>3） 进取心强。能够自我学习自我发展，有强烈的进步意愿</p>
<h2 id="八十万以上名师的特点">八十万以上名师的特点：</h2>
<p>进入新东方时间较早，具有强大的人格魅力，能够带动学生情绪，课堂具有感染力，知识储备丰富，博闻强识，博古通今，课程结构严谨讲述设计巧妙。</p>
<h2 id="学生会和社团工作对于现在工作的影响">学生会和社团工作对于现在工作的影响</h2>
<p>在学生会和社团的工作中学会了如何和别人打交道，如何管理一群人为共同目标努力、如何计划、组织，如何培训、指导，如何监督、反馈、总结，这些都是管理能力的很重要的一部分，这些能力只有在时间和经验的积累才能提升——初中物理组组长的敲门砖</p>
<h2 id="工作对自己的改变">工作对自己的改变</h2>
<p>自己在工作中变得更成熟 能够清晰地判断一件事情的收获与损害，遇事不在慌张手足无措而是能够沉着冷静，将意外的损失降到最小，学会了如何更好地解决问题，提升了跟别人打交道的熟练程度，提高了研究事物规律、公开演讲、管理培训的能力，学会了如何在自己的领域产生影响力</p>
<h2 id="工作之余的提升途径">工作之余的提升途径</h2>
<p>阅读，偏重于数理方面的书籍教材，例如经济学、运营学、管理学相关的西方教材，以及博弈论、运筹学，策略决策方面的书籍帮助自己去理解行业、公司的发展规律</p>
<p>文科方面主要是是专业性历史书，比如欧洲史，美国经济史、西方国家科学技术发展史及政治经济制度发展史、哲学发展史，帮助自己理解公司的制度、理解人的行为</p>
<h2 id="文科与理科思维的差异">文科与理科思维的差异</h2>
<p>文科思维-感性，直接</p>
<p>理科思维-长线，间接寻找事物规律</p>
<p>例如新东方和学而思，新东方就是典型的文科思维，他看到了中考高考补习这个刚需，于是就专心去研究中考与高考。而学而思则是典型的理科思维，看到了背后的规律，不是从中考高考开始做起而是从初一高一开始，这样学员上完初一高一的课程之后升入初二高二，学而思就会顺势推出下一阶段的补习班，利用之前建立起的口碑来招收学员。</p>
<h1 id="对我们想说的话">对我们想说的话</h1>
<p>针对刚刚踏入大学生活的大一学生我有非常多的心里话想跟你们分享。</p>
<p>大学四年时间是非常宝贵，但是对于目前中国绝大多数大学生而言这四年都是荒废过去的，这非常的可惜。因为这四年，说实在的，是从中学阶段那种强压式的学习，转换到了一种自我学习、自我提升、自我成长，从中学阶段那种考试成绩作为唯一目标和唯一方向的学习，变成大学里的多样化目标和多样化标准，是一种非常突兀的转变，大学新生对此会非常的不适应。哪怕是在清华也有将这四年荒废过去的同学，他到了打死的时候人生一片茫然，对于未来怎么发展心里没底。</p>
<p>而能在如果大一大二时给自己选定一个发展方向，提前进行规划和准备，对于未来能够走好这条路是非常有好处的。现在的发展方向基本上就是从五条路中挑出来一个两个来。</p>
<p>如果你想保研考研，那么就要抓好分数、了解导师及研究方向、尽早进入实验室。</p>
<p>如果你打算考公务员，那么就要掌握公务员考试的应试知识以及公务员所需的人际交往能力、政治敏感性和管理能力，而且需要更多参与团委工作，因为现团委会跟中国的政治体系靠的更加紧密</p>
<p>如果你打算出国留学，那么现在就要开始准GRE托福雅思考试了，同时了解国外大学的院系、方向、导师，提前准备推荐材料，掌握学术英语以及论文写作的能力</p>
<p>如果你打算就业，那么就尽可能多参加学生会社团活动，有机会的话去实习、参观中小型公司或创业公司，了解公司内部的礼仪制度，以及成为公司员工所需的执行力和管理能力，最好能够参加企业设立在学校内的企业俱乐部，我的一位同学在大学时期成为了保洁俱乐部的主席，毕业之后年薪三十万，超过了绝大部分清华毕业同学的工资。</p>
<p>如果你打算创业，那么需要准备的东西就更多了，需要提前找好创业方向，了解怎么去融资，了解投资人的心态，积累人脉，寻找合伙人例如技术人员、市场人员、设计人员、推销人员、推广人员、运营人员。而且要找到自己的特点，在创业团队中是作为主要角色还是帮扶角色，同时去参加创业创新大赛，获取有经验的创业者和从业者的指导和建议，为未来的项目打下基础，也通过创业的竞赛把自己名声推广出去。当你有了好的项目、有了创业的基础和人脉，那么创业成功的可能性就会高很多。</p>
<p>总而言之，大学的四年时间不像中学六年小学六年，是别人帮你规划好了的，用条条框框限制住了你的所有时间和精力。大学时期的所有精力与时间，都是把握在每一个大学生自己手上的，如果你抓不好，你到了大四的时候你完全不知道自己应该走哪条路，要是随便的选择考研保研工作，那么这条路一定会比别人走的更加曲折。</p>
]]></content>
      <categories>
        <category>学习经验</category>
      </categories>
      <tags>
        <tag>作业</tag>
        <tag>警醒</tag>
      </tags>
  </entry>
  <entry>
    <title>硕士一年</title>
    <url>/posts/577f7527.html</url>
    <content><![CDATA[<p>终于把博客恢复过来了，一边听着2020年lpl夏季赛常规赛的最后一个饭堂，一边写点感想。</p>
<a id="more"></a>
<h1 id="关于博客">关于博客</h1>
<p>其实自己本来是想把这个博客替代成微信公众号，所以早期的一些文章都是一些个人想法和乱七八糟的文章，后来在《数字图像处理》的时候查到了这个大佬的<span class="exturl" data-url="aHR0cHM6Ly9iYWlkdXQuZ2l0aHViLmlvL2Fib3V0Lw==">博客<i class="fa fa-external-link-alt"></i></span>，才有了把自己的博客改编成自己的简历的想法。</p>
<p>前几天在想有没有about页面的的模版，搜了搜发现了这个hugo<span class="exturl" data-url="aHR0cHM6Ly90aGVtZXMuZ29odWdvLmlvL2FjYWRlbWljLw==">主题<i class="fa fa-external-link-alt"></i></span>，花了两三天的时间迁移了过去，然后发现这个主题并不合适我这种经常写自己的想法笔记的人，更适合那种专门的学术主页，所以就又迁移回来了。</p>
<h1 id="关于硕士">关于硕士</h1>
<p>自己的硕士一年级就这么过去了，回想起来我过去这一年的好多事情，都让我尴尬到脚趾抠出来一个阿房宫，自己在这里第一年搞了好多笑话。</p>
<p>因为自己性格的原因，自己的日语并没有得到很好的进步，在这里呆一年，并没有像刚进大学的自己一样，像一只饥饿的狼。</p>
<p>自己在这里一年，做出来的东西，感觉真的就只有半年的量，一年前拿到的很多关于学术写作演讲发表和海洋光学海洋遥感水色遥感的资料，到现在也就学习了20%。</p>
<p>其实很多东西真的一点都不难，就是自己很难静下心来去思考。</p>
<p>自己真的太心急了，急于求成追求短平快，就比如现在写个总结，还想着赶紧写完。</p>
<h1 id="关于精力">关于精力</h1>
<p>自己这一年最大的一个感受就是好多时候精力和体力明显跟不上，比如最近这几天吃完饭就忍不住的犯困一睡俩小时，比如看一会论文写一会代码就觉得累，比如早上起不来，比如很难集中精力。看看老板六十多还健步如飞似少年自己是真的羡慕。身体素质真的肉眼可见的退化。</p>
<p>一些不好的习惯是真的需要改了。</p>
<h1 id="关于未来">关于未来</h1>
<p>其实到现在我还对未来要做什么很不确定，尤其是最近这个国际环境动荡的情况下。</p>
<p>但是最近慢慢地越来越感觉自己就是太不能吃苦了，自己每天养尊处优，不经风吹日晒，还喊着累。</p>
<h1 id="第二年">第二年</h1>
<p>希望明年这个时候，不管我做了什么选择，都能问心无愧的说，自己这个第二年，做到了自己能做的所有事情。</p>
<p>静下心来，认认真真去学习，不要怕前路未卜。</p>
<p>分携如昨。人生到处萍飘泊。偶然相聚还离索。多病多愁，须信从来错。尊前一笑休辞却。天涯同是伤沦落。故山犹负平生约。西望峨嵋，长羡归飞鹤。</p>
]]></content>
      <categories>
        <category>学习经验</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>随便写写</tag>
      </tags>
  </entry>
  <entry>
    <title>经验贴（三）申请流程及准备</title>
    <url>/posts/751458a5.html</url>
    <content><![CDATA[<p>拖更了这么久主要是不知道下一步该说什么，索性以我去年的整个申请节点来写。这里以2020年申请的为例，方便对照。另外我这里给出的只是一个理想情况，实际可以根据自身情况调整。</p>
<a id="more"></a>
<h1 id="材料准备">材料准备</h1>
<p>关于怎么写材料，知乎和寄托很多帖子写的很好，请自行搜集和学习。</p>
<h2 id="招生指南">招生指南</h2>
<p>这一点对于申请G30/SGU的学生来说尤为重要，因为G30只能在一小部分教授里面申请，这个名单会随着招生指南一起发布。提前搜集了招生指南的话，陶瓷的时候不至于是无头苍蝇。</p>
<p>如果要申请2020年10月入学的话，2019年11月份就可以去院校官网搜集指南了，同时自2020年3月起，可以去寄托论坛关注offer情况，看看有没有申请你想去的项目的学长学姐。 ## 语言成绩 ### 日语</p>
<p>申请G30/SGU是不需要日语的，虽然你可以交这个材料。至于这个材料究竟占多大分量，笔者到现在也不是很明确。如果能考出来就考，考不出来也不必太过担心。</p>
<p>申请研究生可以不用日语，只用英语，但是用日语可以扩大你申请老师的范围。理工科的话，一般N2就足够了，文科可能会有一些实地调查的项目所以要N1。至于自己想申请的老师对日语究竟有没有要求，可以从老师实验室组成人员上来看。如果老师实验室里留学生比较多，一般不需要日语也可以申请；如果老师实验室里留学生较少甚至没有留学生，那一般就一定要日语了。至于这项考试的时间节点，如果你申请的老师对日语有要求的话，我推荐在19年7月考过Ｎ2。在后面和老师套瓷用日语交流的时候，老师也可以判断出你的日语水平。</p>
<h3 id="英语">英语</h3>
<p>在我申请时查阅的学校（七帝大+东工大），都是可以用雅思的，但是我个人比较推荐考托福。托福的分数在日本知名度比较高，不仅留学，日后如果进入对英语有要求的企业时也可以使用。最迟要在2019年10月份考出来。至于成绩，如果你想申请东大、京大的G30/SGU，托福100+甚至105+才算一个比较有竞争力的分数；申请其他学校的G30/SGU一般95+就够用了；申请研究生的话，90+就可以，不过我也推荐考到95+。值得一提的是，托福成绩可以在修士入学考试中折换成英语考试的成绩，我见到的一个说法是托福100对应修士入学考试的英语满分，在这之下的对应换算过去，不知道是不是真的。另外，我没有见过学校对小分有要求。</p>
<p>另外，如果你考的是雅思，请注意不能选择电子寄送成绩单。 ### GRE/GMAT</p>
<p>这个只有在申请G30/SGU的时候才用到，如果申请东大、京大，即使有的项目是非必需材料，我也推荐考出来。至于分数要求、科目和节点，请参照往年的申请指南。</p>
<h2 id="ps">PS</h2>
<p>这个我只在京都大学AAO的时候用到过。所以更具体的我想放到AAO的时候在讲。大阪大学也有类似的预审核制度，但是我没有申请大阪大学，因此对大阪大学的龙门制度并不是很了解，就不再介绍了。</p>
<h2 id="研究计划书">研究计划书</h2>
<p>一般来说，你第一封套辞信发过去之后，导师如果对你感兴趣就会接着回复问你的研究计划书是什么，因此最好在套辞前准备好。申请研究生的话，研究计划书不用特别详细，一张A4纸就好；G30/SGU最好发一个比较完善的版本。</p>
<p>我觉得日本老师是不见兔子不撒鹰，如果你非常想申请的老师不回复你邮件的话，很有可能是因为他没看到你的研究计划书。我就遭遇到了这样的情况，在我把研究计划书发过去之后老师才回复我并且说“直到现在我才看到你申请的决心”。</p>
<h2 id="成绩单推荐信简历summary-of-thesis">成绩单、推荐信、简历、Summary of Thesis</h2>
<p>和研究计划书一样，老师对你感兴趣的话在回复你第一封陶瓷信的时候就会问你要这些，因此最好在套辞前准备好。第一封套辞信可不放简历。</p>
<h2 id="在读证明毕业证明护照">在读证明、毕业证明、护照</h2>
<p>如果是申请Ｇ30/SGU的话，这些在申请指南上都有写，按照指南来准备就好；研究生可以等2020年开学在办。</p>
<h1 id="时间流程">时间流程</h1>
<p>这里所介绍的时间流程全是研究生的，G30/SGU由于不同学校差别过大（例如九大有的19年10月入学的项目19年3月才开始申请），请按照招生指南上所说的自行安排。</p>
<h2 id="套辞">套辞</h2>
<h3 id="时间安排">时间安排</h3>
<p>在2019年八九月份就可以开始套辞了，之前可以选择导师。 最迟也一定要在2019年12月份套辞，2020年1月份开始，大部分导师的研究生名额都已经被申请完了。</p>
<h3 id="导师搜索及选择">导师搜索及选择</h3>
<p>我这里以东大为例来讲一下导师搜索和选择的整个流程。</p>
<h4 id="导师搜索">导师搜索</h4>
<p>打开东京大学主页，这里有一个“教员检索”</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/jingyantie3fi.png"></p>
<p>点进去，在检索这一栏里输入你读研时想做的<strong>研究的关键词</strong>,例如“phytoplankton”,“machine learning”,“image process”，不要写太宽泛的单词；如果没有的话就减少关键词的数量。</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image/e3f2.png"></p>
<p>出来结果之后就可以查看导师具体信息了，一般情况下只有Professor和Associate Professor有招生资格。</p>
<p>其他学校大同小异。</p>
<h4 id="导师选择">导师选择</h4>
<h5 id="对中国人的友好程度">对中国人的友好程度</h5>
<p>确定好导师之后，找到他的实验室主页，看一下学生组成和往届学生，一般可以分为以下几种情况：</p>
<p>1. 学生全是日本人。这种导师可能是名气比较小或者只是没有开始收中国人而已，可以试试申请。</p>
<p>2. 有外国人，但是没有一个中国人。这种老师可能就对中国人有偏见，不建议申请。毕竟中国人那么多，如果能申请进去的话不早就进去了。</p>
<p>3. 有中国人。这种导师一般对中国人比较友好，可以尝试联系一下组里中国人查看情况。</p>
<h5 id="学术水平">学术水平</h5>
<p>最直观的可以通过Google scholar的H-index看出来，但是出于某些原因，不是特别方便。这里推荐另外两个网站，<span class="exturl" data-url="aHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC8=">research gate<i class="fa fa-external-link-alt"></i></span>和<span class="exturl" data-url="aHR0cHM6Ly93d3cuc2NvcHVzLmNvbS9mcmVlbG9va3VwL2Zvcm0vYXV0aG9yLnVyaT96b25lPSZhbXA7b3JpZ2luPU5PJTIwT1JJR0lOJTIwREVGSU5FRA==">scopus<i class="fa fa-external-link-alt"></i></span>。后者比前者要更全。这两个网站上都有计算的一些学术评价指数，根据这个来判断就好。但是要注意，不同学科之间的指数差距比较大，如果你申请的老师中有不在同一个大方向的，这个指数并不能反映出老师的相对水平。</p>
<h5 id="毕业生去向">毕业生去向</h5>
<p>这个一般在导师实验室网站上都会放出来，如果没放出来，抱歉，我也不知道了。</p>
<h5 id="地理位置">地理位置</h5>
<p>有很多学校都是有分校区的，例如东大。东大海洋与大气研究中心的老师实验室我印象中都设立在千叶柏市，而不在东京。同时可以用谷歌地图查一下坐电车花费的时间，这个在你想出去玩或者求职的时候还是挺重要的。</p>
<p>除此之外，可以通过Dark sky map这个APP 的夜光指数来看你的实验室在不在市中心。但是说实话，除了东京和大阪，日本的其他地方都可以看成村。</p>
<h2 id="入学手续">入学手续</h2>
<p>套辞成功叫拿到内诺，内诺之后就要申请入学了，拿到小蜜给你发过来的研究生的入学通知才叫offer。这个申请只是走过场，一般在2020年四月开始，三月就可以去学校官网查看申请的指南了。由于我还没到这一步，略去不表。</p>
<h1 id="关于aao的小尾巴">关于AAO的小尾巴</h1>
<p>在这里就不介绍AAO是什么了，我个人推荐9月份最迟十月份提交AAO，AAO可能会需要一个月的时间。同时因为AAO只有一次机会,如果失败了只能通过直接考试的方法进入京大，因此在进行AAO之前最好能先得到你想申请的导师的回复。</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>经验贴（二）日本留学制度介绍</title>
    <url>/posts/c7945378.html</url>
    <content><![CDATA[<p>不同于欧洲、北美、香港等国家，日本拥有极其独特的留学制度。如果一个国内的本科生想去日本攻读研究生的话，大致可以分为语言学院、研究生（research student）、直接考试和申请英语项目（G30/SGU）这几种，相较其他国家复杂了很多。需要注意的使，即使是同一个学校，不同的学院之间的入学制度也会有很大不同，包括申请时间、申请材料、考试方式等等，一定要认真核实。</p>
<a id="more"></a>
<h1 id="我为什么不推荐你来日本留学">我为什么不推荐你来日本留学</h1>
<p>在正式开始之前我先来劝退一波。</p>
<p>不同于欧美国家有授课型硕士（taught-lesson）的存在，日本几乎没有授课型硕士，几乎所有的硕士都是研究型硕士，硕士期间就要跟着老师做实验做课题了。因此在申请的时候老师会更看重你做研究的能力，这个能力很大程度上由你的研究计划书（research proposal）来体现。显而易见，你没有办法像申请美国英国一样，不同学校的personal statement或者statement of purpo只改一个why school就可以重复套用，你的research proposal和其他文书必须针对你要申请的导师的研究方向来针对的写，而我在申请寻找导师的时候几乎没有看到两位导师的研究方向有很大相似度的情况。俗话说得好，同一个实验室的两个博士都不一定能真正理解彼此做的课题，更别提不同实验室的导师了。所以你的research proposal和其他文书几乎没有多少可以在不同学校间重复套用的东西，看过上一篇博文的同学可以知道，research proposal是一个很难由咨询机构写好的东西，除非给你写的人是和你申请的老师一个方向的硕士或者博士。因此在准备申请材料时，相比申请其他地区，就算你找了咨询机构，也会花费你很多很多的精力。</p>
<p>说完了申请材料，再来说申请的目的。</p>
<p>如果你出国留学是为了在日本工作的话，其实还算一个比较好的选择。在日本影响你工作好坏的因素，据我了解，主要有以下几点：</p>
<p>1. 学校所在位置。日本绝大多数工作机会都在东京与大阪这两座城市里。如果不是在这两座城市里上学，找工作的时候还要舟车劳顿去参加招聘会。</p>
<p>2. 日语水平。这一条其实取决于个人，如果走研究生考修士或者语言学校来读研的话，日语水平一般还可以，但是G30/SGU的学生相对就会差一点。</p>
<p>3. 同一个实验室的前辈所去的公司。在日本内推对求职成功的影响是很大的。</p>
<p>因为我还没有到找工作的时候，以上三条仅为个人看法。从这方面来看，你的个人能力反而没有那么重要。日本社会擅长把每个人打造成螺丝钉，不需要你有很大的创新很强的能力，只要你按照上级的交代像个螺丝钉一样被锤子锤在合适的地方就可以了。同时职位的晋升也很大程度上依赖于你进入公司有多久，而不是你的业绩。</p>
<p>如果你想回国找工作，那么对不起，我强烈不推荐你去。虽然有很多公司都有海外招聘，但是他们都有目标院校——即所谓的target school。抛去这些不谈，如果你拿着毕业证书打算回国工作的话，很多公司单位很有可能都不知道你的学校是个什么水平。大多数中国人只知道东大和早大这两所学校，其他的学校在国内都不是很出名，你花了两年（半）以及更多的精力去日本读研，最后回国工作可能还比不过香港的一年制硕士。</p>
<p>如果你想搞研究的话，认真的说，读博还是去美国好，甚至一些国内的院校例如清华的计算机，北大的物理化学，都能赶超很多世界名校。读博最重要的是你跟的导师和你自己是不是努力，在导师这一方面美国有着天然的优势，汇集着最顶尖的科研人才。可能还有一部分同学的想法是日本读研当跳板再去美国读博，这个面临的问题一个是你会比直接申请美国花费更多的时间毕业，另一个是在日本期间无论如何你的英语都会受到影响，其实不是很利于你申请。 除此之外，如果你直接申请美国的博士，自带的奖学金基本可以cover你全部的学费和生活费，但是日本的奖学金需要你入学之后再去申请，存在着很大的不确定性。</p>
<p>综上所述，我并不是很推荐你来日本留学。</p>
<h1 id="研究生制度起源">研究生制度起源</h1>
<p>日本传统的的一个学年开始并不是在秋季，而是在春季。多说一句，日本的樱花之所以会被视为离别的象征（就比如AKB48就很多人的毕业曲就和樱花有关），就是因为3-4月份是日本传统的学生毕业的时间。美国的GRE一样研究生入学考试一年可以考好几次，然后由每个学生拿着考试成绩去申请，但是日本的研究生入学考试是由每个学校甚至每个院系单独举行的，只有考试通过才能去读他们的研究生。这样的话，其他很多国家的学生毕业的时间大多数在夏季，没有办法去参加入学考试（当然现在也有秋季入学的考试，这个到后面的制度介绍的时候具体去讲），这中间就隔了大半年的时间，因此日本很多学校就设立了研究生（research student）制度来让外国学生先以旁听生的身份入学，等到来年三四月开春了再去考试成为正式学生。</p>
<h1 id="研究生research-student和直接考试">研究生（research student）和直接考试</h1>
<p>在接着往下讲之前先明确研究生（research student）和修士（master）的概念。</p>
<p>研究生在日本其实是一种非正式学生，真的就是字面上的意思——做研究的学生，读研究生没有办法获得硕士学位，需要经过入学考试才能称为正式的学生——修士，修士毕业才能获得硕士学位。简单来说，可以把研究生看作是硕士预科生，修士看成硕士生，从这里开始提到的研究生和修士都是这个概念。</p>
<p>前文已经提到了，研究生是修士之前的一个过渡阶段，需要通过入学考试才能称为正式学生。但是这个入学考试并不像国内考研和美国GRE一样，对分数有着很高的要求，你最终能不能通过考试成为修士，更多的是看你申请的老师想不想要你。换句话说，决定你能否成为修士的并不是你修士考试考了多少分，而是你在研究生阶段给你申请的老师留下的印象如何。如果老师特别想要你来读的话，还会给你划重点什么的。同样的，由于研究生阶段并不是一个正式的学生，你考修士的时候选择考另一个老师的修士也是可以的。</p>
<p>总的来说，申请到了研究生并不一定能保证你一定能成为修士。所以有一些导师就大量收研究生，但是只通过一部分，来给他打工。相信我这样的导师是很少的。研究生期间很难申请到奖学金补助，而且也无法选课获得学分，但是可以打工来弥补一下费用。</p>
<p>需要说明的是，研究生并不是成为修士必须要经过的阶段。只要你通过修士入学考试，那你就可以成为修士。所以有一些院校是不收研究生的，这样的话你只能通过直接考试的方式来成为他们的修士。我前面也说了，能够决定你能否通过考试的是你申请的老师对你的印象</p>
<p>最后说一下修士入学考试的时间问题。现在一些学校存在着秋季入学的修士考试，但是由于日本大部分学生都是在春季毕业，所以如果你秋季入学的话，和很多招聘活动都是错开的，非常不利于你求职，因此一般情况下我不推荐参加秋季入学的研究生入学考试。</p>
<h1 id="g30sgu">G30/SGU</h1>
<p>很多大学排行榜上都有国际化率这一项指标，日本学校特殊的制度使得日本大学里的外国人并没有特别的多，因此在这一项指标上比较吃亏。为了改变这一现象，很多学校开设了G30/SGU项目。这个项目和欧美的申请就比较一致了，只是有的学校还会有考试这一项，像我知道的考试方式的话有的有开着Skype监考，有的有去国内某个地方参加考试，有的会在面试的时候举个小黑板让你做题。因为我自己研究生和G30/SGU都有申请，更具体的我想放到后面再说。在这里我想强调以下几点：</p>
<ul>
<li>G30/SGU项目依然很大程度上取决于你要申请的导师对你的印象</li>
<li>几乎全部是研究型硕士</li>
<li>申请难度比研究生高的多</li>
</ul>
<h1 id="语言学校">语言学校</h1>
<p><strong>语言学校，真的就是学语言的学校，而不是修士入学考试的辅导班。</strong></p>
<p><strong>语言学校自己申请就好，不需要找中介。</strong></p>
<p><strong>上来就让你读语言学校的机构就是在坑你钱。</strong></p>
<p>说到语言学校这里忽然间不知道该从哪儿下手了。因为我觉得对于硕士的申请来说这是一个很坑的东西。如果你真的要读语言学校，请记住以上三条。</p>
<h1 id="日本留学机构中介会怎么坑你">日本留学机构（中介）会怎么坑你</h1>
<p>写完上一条忍不住来总结一下我遇见或者听说过日本留学中介或者机构的坑钱方法。</p>
<p>1. 申请账号、邮箱不公开</p>
<p>2. 只帮你申请学校列表里最差的学校</p>
<p>3. 给你申请你不喜欢但是招人多的老师</p>
<p>4. 花式诱导你读语言学校</p>
<p>5. 申请材料不向你公开</p>
<p>6. 申请到奖学金额外收钱，申请到好大学额外收钱</p>
<p>7. 霸王条款，无明确退款政策</p>
]]></content>
      <categories>
        <category>留学生活</category>
      </categories>
      <tags>
        <tag>留学</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 10.5-10.11</title>
    <url>/posts/3d8d27aa.html</url>
    <content><![CDATA[<p>Annotated Bibliography 2020 10.5-10.11</p>
<p>Next Monday I will do a book reading presentaion. So this post will mainly include the book reading and some other oceanography quick look.</p>
<p>And from this semester, I think I'd better make some notes for seminar to keep myself concentrated.</p>
<a id="more"></a>
<h1 id="book-reading">Book reading</h1>
<p>Ch. 1.1-1.2.2 of book &lt;Emery, William, and Adriano Camps. <em>Introduction to satellite remote sensing: atmosphere, ocean, land and cryosphere applications</em>. Elsevier, 2017.&gt;</p>
<h2 id="the-definition-of-remote-sensing">The definition of Remote Sensing</h2>
<p>Remote sensing: a measurement made by some indirect or “remote” means rather than by a contact sensor.</p>
<p>In its application to satellite and aircraft instrumentation, remote sensing relied primarily upon either reflected or emitted electromagnetic radiation (optical and mi- crowave) from the Earth to infer changes on the Earth’s surface or in the overlying atmosphere.</p>
<p>The fact that these inferences must be made from a by-product (either the reflected or the emitted radiation) of the surface or atmospheric process qualifies satellite data collection as “remote sensing.”</p>
<p>Other applications such as the use of acoustic signals to map the internal character of the ocean and the solid Earth are often also considered as a remote sensing. In the past few decades, however, satellite and aircraft data analyses have become even more closely associated with the term remote sensing.</p>
<h2 id="the-history-of-satellite-remote-sensing">The History of Satellite Remote Sensing</h2>
<h3 id="the-nature-of-light-and-the-development-of-aerial-photography">The Nature of Light and the Development of Aerial Photography</h3>
<p>Early work by Sir Isaac Newton: white light is not a single entity</p>
<p>In optics, chromatic aberration (CA), also called chromatic distortion and spherochromatism, is a failure of a lens to focus all colors to the same point. It is caused by dispersion: the refractive index of the lens elements varies with the wavelength of light.</p>
<figure>
<img src="https://ipt.imgix.net/203320/x/0/chromatic-aberration-ndash-what-it-is-and-how-to-avoid-it-2.jpg?auto=compress%2Cformat&amp;ch=Width%2CDPR&amp;dpr=1&amp;ixlib=php-3.3.0&amp;w=883" alt="Chromatic Aberration – What it is and How to Avoid It"><figcaption aria-hidden="true">Chromatic Aberration – What it is and How to Avoid It</figcaption>
</figure>
<p>When he passed a thin beam of sunlight through a glass prism, Newton noted the spectrum of colors that was formed. Newton argued that white light is really a mixture of many different types of rays, which are refracted at slightly different angles, and that each different type of ray produces a different spectral color. Newton was led by this reasoning to the erroneous conclusion that telescopes using refracting lenses would always suffer chromatic aberration. He therefore proposed and constructed a reflecting telescope (i.e., using mirrors).</p>
<p>Maxwell:</p>
<p>Phenomenon of light is therefore an electromagnetic phenomenon</p>
<p>Daguerre:</p>
<p>first photographic plate, which consisted of a thin film of polished silver on a copper base</p>
<p>Nie ́pce: reduced the exposure time from 8 h down to half an hour.</p>
<p>topographic mapping was first suggested in 1849</p>
<p>Balloonist F. Tournachon undertook initial attempts in 1858 from a captive balloon a few hundred meters over Petit Bicetre in France using large silver plates as the camera</p>
<p>Balloon photographs of Confederate positions during the American Civil War represent the first practical use of aerial photography.</p>
<p>Maddox, in 1871, film</p>
<p>Triboulet used dry plates in 1879 to photograph Paris from a free balloon. The size of the camera was also reduced which opened more opportunities for photography.</p>
<p>English meteorologist E. Archibald: first kite photographs in 1882</p>
<p>In 1889, R. Thiele, from Russia, mounted cameras on seven unmanned kites to produce a “panaramograph.”</p>
<p>In 1885, W. A. Eddy, an American meteorologist in New Jersey, reported the first kite photograph taken in the western hemisphere</p>
<p>kite-camera system, which proved a useful supplement to balloon photography during the Spanish-American war. G. R. Lawrence, referred to as the “King of Kite Photography,” used kite systems with cameras weighing up to 454 kg and negatives as large as 1.35 m  2.4 m. He is particularly noted for his photograph of San Francisco just after the earthquake of 1906</p>
<p>the attachment of cameras to carrier pigeons at the 1909 world’s fair in Dresden,which would then be developed and printed for sale to the attendees at the fair that can see themselves and the overall fairgrounds.</p>
<p>In 1908 a passenger appropriately collected the first aircraft still photographs with Wilbur Wright flying on a test flight in France (Fig. 1.6), while another passenger took the first aerial movies with Wilbur in the following year.</p>
<p>Samuel Goddard collected the first rocket photos in 1926 during his experiments with rocketry.</p>
<h3 id="the-birth-of-earth-orbiting-satellites">The Birth of Earth-Orbiting Satellites</h3>
<p>In 1903, Konstantin Tsiolkovsky (1857e1935) published Exploring Space Using Jet Propulsion Devices: first academic treatise on the use of rocketry to launch spacecraft.</p>
<p>He calculated the orbital speed required for a minimal orbit around the Earth at 8 km/s, and that a multistage rocket fueled by liquid propellants could be used to achieve this. He proposed the use of liquid hydrogen and liquid oxygen, though other combinations can be used.</p>
<p>In 1928, Slovenian Herman Potocnik (1892e1929) published his sole book, The Problem of Space TraveldThe Rocket Motor (German: Das Problem der Befahrung des Weltraumsdder Raketen- Motor): a plan for a breakthrough into space and a permanent human presence there.</p>
<p>He conceived a space station in detail and calculated its geostationary orbit. He described the use of orbiting spacecraft for detailed peaceful and military observation of the ground and described how the special conditions of space could be useful for scientific experiments. The book described geostationary satellites (first put forward by Tsiolkovsky) and discussed communication between them and the ground using radio, but fell short of the idea of using satellites for mass broadcasting and as tele- communications relays.</p>
<p>In a 1945 Wireless World article, the English science fiction writer Arthur C. Clarke (1917e2008) described in detail the possible use of communications satellites for mass communications</p>
<p>examined the logistics of satellite launch, possible orbits, and other aspects of the creation of a network of world-circling satellites, pointing to the benefits of high-speed global communications. He also suggested that three geostationary satellites would provide coverage over the entire planet.</p>
<p>October 4, 1957 with the successful launch and operation of the Russian Sputnik satellite, which was the first human created instrument to orbit the Earth.</p>
<p>the start of the space age and the USeUSSR space race.</p>
<p>carried no Earth-oriented sensors and only really sent out radio signals that were used to communicate with the satellite. It did demonstrate, however, that satellites could be launched from the Earth and operated on a continuous basis.</p>
<p>on November 3, Sputnik II was launched, carrying a much heavier payload, including a dog named Laika. Table 1.1 lists all of the first satellites launched by 12 different countries starting with the Soviet Union launch of Sputnik-1 in 1957.</p>
<p>There were also a number of attempted first launches by many of these same countries before they were successful at launching a satellite and inserting it in to Earth orbit. Several other countries, including Brazil, Argentina, Pakistan, Romania, Taiwan, Indonesia, Australia, New Zealand, Malaysia, Turkey, Spain, Japan, India, Israel, France, Germany, and Switzerland (and others) are at various stages of development of their own small-scale launcher capabilities. This list grows a lot longer when you include nations and satellites that were launched by the capabilities of other nations.</p>
<p>Today with the advent of small satellites such as “CubeSats” almost anyone can get a satellite payload into space. It is something the commercial remote sensing companies are taking a very close look at.</p>
<p>US: how Earth-orbiting satellites could benefit the meteorological forecasting community in monitoring conditions on the Earth</p>
<p>the first TIROS (Television and Infrared Observation Satellite) was launched and made operational in April of 1960. This satellite was spin stabilized which led to the fact that the Earth-oriented sensor (aligned with the spin access) could view only a limited portion of the Earth’s latitude</p>
<p>The primary sensor was the wide-angle TV camera, which collected images of the Earth at approximately 750 km orbital altitude. A small infrared (IR) system was also used to collect some limited measurements through the narrow angle TV camera that also collected radiation in visible wavelengths. The receiving and transmitting antennas are shown, and all data collected were transmitted as analog signals down to the ground. A tape recorder on board was used to store these analog data so that they could be downlinked to the ground when the satellite was in view of a tracking ground station.</p>
<p>Thus, the TIROS satellites were incapable of observing the entire globe. This was a limitation of the spin stabilization at least as it was deployed in this fashion.</p>
<p>These early satellite designs were driven primarily by meteorological considerations and the need for improved forecasting.</p>
<p>Since all of the TIROS imagery were analog the correction of these geometric distortions was not possible using digital methods and mapping was done by overlaying “warped grids” that best matched the orientation of the global features. This type of mapping approach determined the lines on</p>
<p>Land surface features were also apparent in the early TIROS imagery when cloud cover was sufficiently low to make it possible to view the surface.</p>
<p>Here the lake covers a number of satellite passes each of which has a slightly different exposures. This produces artificial striping in the image. Earth surface distortion continues to be a problem as shown by the elongated part of the lake in the southwest portion of the image. The presence of clouds in this same portion of the image also obscures the surface of the lake. Discontinuities in the cloud cover are introduced by the fact that the image is made up of sequential passes, which are not truly synoptic in coverage.</p>
<p>The initial TIROS satellites were relatively short-lived with satellites lasting only a few months each. By the end of the series, however, the satellites were lasting approximately a year and continuing to report data over this entire period.</p>
<p>To overcome the viewing limitations of the original TIROS series of satellites the next generation of spinning satellites was changed to have the camera pointing radially outward and the spin axis of the satellite turned 90 degrees relative to the original TIROS satellites. This new configuration was called the “wheel” satellite and a consequence of this change was the ability to collect a series of circular images that over the period of a day covered the entire surface of the Earth.</p>
<p>The next development in the evolution of operational weather satellites was the incorporation of spacecraft stability control.Developed as part of the ballistic missile program during the “cold war,” three-axes stability systems were now available to control the pointing of the spacecraft without the need to spin the spacecraft. With this three-axes stabilization, it was possible to keep the Earth sensors always pointing at the Earth regardless of its position in the orbit. This made it possible to collect imagery over the entire Earth’s surface from the same sensors at the same resolution.</p>
<p>Called the Improved TIROS Observing Satellite, or ITOS, this family of satellites brought in a new era of remote sensing. In addition to the three-axes stabilization, these satellites carried a new suite of optical radiometers which were scanning systems that collected reflected and emitted radiation from the Earth’s surface line by line as the satellite moved along in its polar orbit. These first radiometers (Fig. 1.17) ushered in the new era of improved capabilities that became a standard approach to viewing the Earth.</p>
<p>The ITOS scanning radiometers were those that became the primary instruments for future satellites.</p>
<p>The first ITOS satellite demonstrated the utility of these new technologies and began a longer time series of polar-orbiting spacecraft, which were now called NOAA satellites after the name of the agency that operated them. A series of eight satellites with approximately the same suite of equipment filled in the years between 1970 and 1976. The practice was to designate the satellites as NOAA a, b, c, etc. when they were built, and then transition them to NOAA 1, 2, 3.etc. once they were operating on orbit. The fact that not all of the NOAA satellites achieved orbit or failed early on orbit led to the fact that alpha and numeric designations do not map one to one.</p>
<p>Now the orbital altitude is about 1271 km and the orbit is Sun-synchronous with an 80-degree inclination in a retrograde orbit with a period of about 111 min.</p>
<p>A big change over this evolution of satellite capabilities was the size and weight of the spacecraft. The original TIROS satellites weighed about 150 kg, which increased to 250 kg with the change to the ESSA wheel satellites. The shift to three-axes stabilization increased the ITOS satellite up to 400 kg, which then increased by over a factor of three to the modern NOAA and Defense Meteorological Satellite Program (DMSP) satellites that weigh about 1500 kg.</p>
<p>The analog radiometer data from the NOAA satellites were digitized on the ground so that the images could be digitally processed and enhanced to geometrically correct the image geolocation and bring out various features in the atmosphere and on the ground. The geometric corrections for Earth curvature and rotation compensated for the distortions of satellite viewing. Additional corrections were also needed for satellite attitude and time, which influences the viewing angle.</p>
<p>Radiance enhancement was needed to bring out the weaker gradients in some of the radiometer channels such as the thermal IR patterns in the ocean. An example is shown here in Fig. 1.19, which is an image of the Gulf of Mexico and the east coast of Florida, which shows the warm water (dark gray shades) associated with the loop current in the Gulf of Mexico and the subsequent Gulf Stream off the east of Florida. The colder water closer to the shore off Florida represents the colder “shelf water” that flows southward inshore of the Gulf Stream. Colder waters also bound the dark pattern of the loop current in the center of the Gulf of Mexico.</p>
<p>This image has been remapped to correct for geometric distortion, which can be seen in the appearance of Florida at the edge of the image, which would be highly distorted if seen in satellite perspective. It is very difficult to quantitatively study features in satellite imagery without being able to “navigate” the imagery, which includes the geometric corrections for Earth curvature and rotation as well as corrections for spacecraft attitude and timing errors.</p>
<p>The ITOS and NOAA satellites carried two different radiometers. The primary instrument was the scanning radiometer (SR), which had an 8 km resolution and was limited to only three channels: (1) a wide band visible, (2) a near-IR channel (0.7e1.1 mm), and (3) a thermal IR (11 mm) channel. The instrument was used to map clouds and later applied to the mapping of sea surface temperature (SST) using the 11 mm channel. A sophisticated processing system was developed that used a histogram method to filter out pixels dominated by clouds to produce SST over large 50 km boxes. This system was found to introduce a lot of errors by letting some cloudy pixels slip through and used an objective analysis (Cressman, 1959) routine that “filled” in erroneous data.</p>
<p>Another instrument flown on the NOAA satellites was the very high resolution radiometer (VHRR), which was the first instrument to demonstrate a real capability for being able to map SST. It had channels in the visible, the near-IR wavelengths, and the midrange IR and the thermal IR wavelengths (again 11 mm). Using the visible and near-IR channels for cloud clearing the VHRR data were then used to produce a 1 km resolution SST, which was the native resolution of the instrument. The image in Fig. 1.19 is from the VHRR sensor.</p>
<p>The biggest change in satellites and sensors came in the fall of 1978 with the advent of TIROS-N (“N” for new). An advanced version of this series of NOAA polar-orbiting satellites the last of which is still operating as this text is being written. These are the 1500 kg spacecraft referred to earlier where the added weight reflects greatly increased capabilities with these new spacecraft. They were fully digital systems that downlinked their data digitally. A new imager called the advanced very high resolution radiometer (AVHRR) became the workhorse radiometer on this spacecraft. With its basic 1 km footprint in four channels the AVHRR data have been used for a wide range of studies of ocean, land, and atmospheric processes. Over the subsequent three decades, this instrument has evolved from having only four channels to one that now has six different channels, is called AVHRR-3, and has the characteristics as described in Table2.</p>
<p>The original four channels covered the visible ( channel 1), the near-IR (channel 2), the mid- range IR (channel 3 only at 3.7 mm), and the 11 mm (channel 4) thermal IR. The first improvement in this sensor led to the AVHRR-2, which added the fifth channel at 12 mm. This channel was added to provide a “split-window” in the thermal IR to ma ke it possible to correct for atmospheric water vapor attenuation of the thermal IR signal i n computing SST. The nominal sensor spatial resolution of 1.09 km meant that all of the channe ls delivered images with essentially the same resolution.</p>
<p>Channel 3 is now broken into two parts. The approximately 3.7 mm channel (now called channel 3B) is continued at night, but during the day this channel shifts over to 1.6 mm to better resolve at- mospheric aerosols and clouds. The visible and near-IR channels are widely used for mapping vegetation, snow cover, and atmospheric aerosols. These channels are also used for mapping snow and ice cover. The thermal IR channels are also used to compute land surface temperature in addition to SST.</p>
<p>The TIROS-N satellites also carried a variety of other instruments. The high-resolution IR sounder is the primary sensor in the TIROS operational sounder system that also includes data from the British stratospheric sounding unit , and the microwave sounding unit (MSU). Together these three in- struments are used to retrieve atmospheric temperature and water vapor profiles for use in numerical model assimilation. Actually it was learned that it was better to directly assimilate satellite instrument radiances from this system into the numerical weather forecast models than it would be to retrieve temperature and water vapor profiles to be assimilated into the models.</p>
<p>Other instruments on TIROS-N (Fig. 1.20) are the search and rescue (SAR in Fig. 1.20B) and Argos data collection system (UHF data collection system antenna in Fig. 1.20A). Both of these systems collect data transmitted from the Earth’s surface and use the Doppler shift of these signals to accurately locate these platforms. The Argos system also has the capability of collecting a limited amount (approximately 256 data words) of geophysical data collected on the platform.</p>
<p>This diagram shows how this spacecraft has considerable extra capacity and other sensors of opportunity have been flown on this satellite such as the Earth Radiation Budget Experiment in- struments that flew only on NOAA-9. These TIROS-N satellites continued to carry the name of NOAA satellites. A picture of a TIROS-N satellite being worked on in storage is shown in Fig. 1.21, to give the reader a better appreciation of the size of these satellites.</p>
<p>A summary of the evolution of polar-orbiting environmental satellite (POES) weather satellites is given here in Fig. 1.22, which contains pictures of the important satellites and the relevant characteristics.</p>
<h1 id="paper-quick-look">Paper quick look</h1>
<h2 id="sarma-v.-v.-s.-s.-et-al.-influence-of-eddies-on-phytoplankton-composition-in-the-bay-of-bengal.-continental-shelf-research-2020-104241.">Sarma, V. V. S. S., et al. "Influence of eddies on phytoplankton composition in the Bay of Bengal." <em>Continental Shelf Research</em> (2020): 104241.</h2>
<p>A in-situ study. Phytoplankton composition measured by HPLC</p>
<p>Picoplankton was high in the entire study region with dominant nanoplankton in the cyclonic eddies and microplankton in anticyclonic eddies.</p>
<h2 id="effects-of-changing-phytoplankton-species-composition-on-carbon-and-nitrogen-uptake-in-benthic-invertebrates">Effects of changing phytoplankton species composition on carbon and nitrogen uptake in benthic invertebrates</h2>
<p>We found that all three macrofauna species fed on both diatoms and cyanobacteria. A linear pattern was found for all three species in assimilation of carbon and nitrogen from diatoms, with increasing assimilation associated with higher proportion of diatoms. There was no clear pattern found between proportion of cyanobacteria and assimilation of carbon and nitrogen for any of the species. This study shows that the investigated macrofaunal species display a selective feeding behavior with preference for spring‐bloom associated diatoms. Thus, changes in phytoplankton bloom composition are likely affecting benthic species composition and production.</p>
<h2 id="seasonal-physical-fronts-and-associated-biogeochemicalecological-effects-off-the-jiangsu-shoal-in-the-western-yellow-sea-china">Seasonal physical fronts and associated biogeochemical‐ecological effects off the Jiangsu Shoal in the western Yellow Sea, China</h2>
<p>Due to favorable conditions, the frontal region off the shoal is prone to high chlorophyll‐a (Chl‐a) and may act as oases in either summer or winter. A conceptual diagram is assembled to provide an overview of physical‐biogeochemical‐ecological interactions off the Jiangsu Shoal in the western YS.</p>
<h2 id="decreasing-phytoplankton-size-adversely-affects-ocean-food-chains">Decreasing phytoplankton size adversely affects ocean food chains</h2>
<p>An increase in the proportion of primary production by nano‐ and picophytoplankton has qualitative as well as quantitative consequences for future food production from the oceans, since this is where the biosynthesis of important components of our diet takes place.</p>
<h2 id="seasonal-and-spatial-variability-in-surface-pco2-and-airwater-co2-flux-in-the-chesapeake-bay">Seasonal and spatial variability in surface <em>p</em>CO2 and air–water CO2 flux in the Chesapeake Bay</h2>
<p>our observations showed higher river discharge could decrease CO2 efflux. In contrast to many other estuaries worldwide that are strong sources of CO2 to the atmosphere, the Chesapeake Bay and potentially other large estuaries are very weak CO2 sources in dry years, and could even turn into a CO2 sink in wet years.</p>
<h2 id="composite-of-typhooninduced-sea-surface-temperature-and-chlorophylla-responses-in-the-south-china-sea">Composite of Typhoon‐Induced Sea Surface Temperature and Chlorophyll‐a Responses in the South China Sea</h2>
<p>Decreases in SST and increases in Chl‐a occur after 73% and 70% of the typhoons, respectively, with overall averaged changes equal to −0.42 ± 0.015°C and 0.056 ± 0.003 log10 mg/m3, respectively.</p>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Remote Sensing</tag>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.17-11.20</title>
    <url>/posts/179aa5a3.html</url>
    <content><![CDATA[<p>虽然自己还有好几个没有更新完，但是为了组会和AWOC就先把这个做出来吧。。。</p>
<a id="more"></a>
<h1 id="iop-reflectance-relationships-revisited-accepted">IOP-Reflectance relationships revisited Accepted</h1>
<p>doi: 10.1029/2020JC016661.</p>
<h2 id="introduction">Introduction</h2>
<p>The quasi-single scattering approximation (QSSA) (Gordon 1973; Gordon et al., 1975) models are widely employed in standard ocean colour processing and applications because they provide an explicit relationship between IOPs and rrs(λ), as formulated by Gordon et al. (1988), coupled with a simple relationship for converting Rrs(λ) to rrs(λ) (Lee et al., 2002). The weakness of QSSA models is their inability to account for multiple scattering effects and their lower accuracy, compared to radiative transfer (RT) codes (Werdell et al., 2018).</p>
<p>On the other hand, <strong>forward RT model</strong>s such as HydroLight (Sequoia Scientific, Inc.) can provide the full radiance distribution below and above the water, as a direct solution to the RT equation (Mobley, 1994). Therefore, given a set of <strong>input IOPs</strong> and appropriate boundary conditions, it is possible to generate <strong>precise estimates of a full set of AOPs</strong>, including rrs(0-, λ) and Rrs(0+, λ).</p>
<p>However, the <strong>inverse problem</strong> of determining <strong>IOPs from AOPs</strong> is not straightforward and relies on empirical and/or semi-analytical relationships.</p>
<p>Early work in this area focused on irradiance reflectance below the sea surface, R(0-,λ) (nondim), defined as the ratio of the upwards to downwards planar irradiances, Eu(0-,λ) (Wm-2nm-1)/ Ed(0-,λ) (Wm-2nm-1), as this was both practically measureable with available instrumentation and computationally convenient (e.g. Kirk, 1984).</p>
<p>At least two different expressions are found to approximate the relationship between R and absorption and backscattering coefficients</p>
<p>Morel and Prieur (1977), modelling the results from radiative transfer calculations, found that <span class="math display">\[
R(0^{-},\lambda)=f\frac{b_{b}(\lambda)}{a(\lambda)},
\]</span> while Gordon et al. (1975) showed that <span class="math display">\[
R(0^{-},\lambda)=F(\frac{b_b(\lambda)}{a(\lambda)+b_b(\lambda)})
\]</span> while <em>f</em> in Eq(1) is a variable in natural conditions(Morel &amp; Gentili 1991; 1996) accounting for most of the directional effects due to changes in the light field, degrees of multiple scattering and in water bio-optical characteristics. <em>F</em> in Eq(2) represents a polynomial function with factors for up to 3rd order given in the original paper.</p>
<p>The exact form of F in Equation 2 (2nd or 3rd order polynomial) and the associated polynomial coefficients have not been unambiguously established for all situations, though in several cases a second order polynomial has been adopted (e.g. Feng et al., 2005).</p>
<p>Rrs(0+,<span class="math inline">\(\lambda\)</span>) measurements are converted to below surface rrs(0-,<span class="math inline">\(\lambda\)</span>)using <span class="math display">\[
R_{rs}(0^+,\lambda)=T.r_{rs}(0^-,\lambda)
\]</span> where <em>T</em> is a transmission factor incorporating information including the Fresnel transmittance from water to air, the refractive index of seawater (invoking the n2 law of radiances) and several additional factors to deal with propagation of downwards irradiance (see Mobley 1999 and IOCCG 2019 for more details). The resulting conversion factor T exhibits only limited variability (0.50 &lt; T &lt; 0.57) and is usually assumed to have a value of 0.54.</p>
<p>Morel and Prieur (1977) adapted equation (1) to express sub-surface remote sensing reflectance rrs(0-,λ) as a function of the ratio bb(λ)/a(λ) (wM from here onward): <span class="math display">\[
r_{rs}(0^-,\lambda)=\frac{L_u(0^-,\lambda)}{E_d(0^-,\lambda)}=\frac{R(0^-,\lambda)}{Q}=\frac{f}{Q}\frac{b_b(\lambda)}{a(\lambda)}=\frac{f}{Q}w_M
\]</span> where Q (sr) is the bidirectional function defined by Morel and Gentili (1996) as the ratio of upwards irradiance Eu(0-,λ) to upwards radiance, Lu(0-,λ), and expresses the non-isotropic character of the radiance distribution<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>In contemporary ocean colour processing (Werdell et al., 2018), rrs(0-,λ) is more often expressed as a function of IOPs following the approach of Gordon et al. (1988) using the ratio of bb(λ)/[a(λ)+bb(λ)] (wG from here onward) <span class="math display">\[
r_{rs}(0^-,\lambda)=\frac{L_u(0^-,\lambda)}{E_d(0^-,\lambda)}=\frac{R(0^-,\lambda)}{Q}=g_0w_G+g_1w_G^2
\]</span> Taking Equations 3, 4 and 5 together, it is clear that Rrs(0+,λ) can be related to IOPs through either wG or wM. However, the apparently simple form of equations 4 and 5 is <strong>deceptive</strong>. <em>f</em> and <em>Q</em> are variables from a series of paper.</p>
<p>Morel and Gentili (1991, 1993, 1996) explored variability in f and Q, with the f/Q factor found to be variable in the range 0.075- 0.12 in oceanic (Case 1) waters and affected by solar zenith angle, sensor viewing geometry, in- water constituent concentrations and wavelength.</p>
<p>Furthermore, in coastal (Case 2) waters, additional concentrations of CDOM and mineral particles that do not co-vary with the chlorophyll concentration were expected to influence the variability of f/Q, though this variability was found to be minimal in the nadir viewing direction and the f/Q factor was almost insensitive to different wavelengths when the Sun is at the zenith (Loisel &amp; Morel, 2001)</p>
<p>One possible reason for the relative popularity of IOP-reflectance relationships operating on wG is that the quadratic form expressed in Equation 5 captures some of the nonlinear behavior in the relationship with IOPs that is less obviously elucidated in the LUT approach for f/Q. The limiting factor for Gordon-style versions of the relationship with IOPs stems from failure to achieve consensus on a single form or set of coefficients that performs equally well across the known range of variability for natural waters.</p>
<p>Gordon et al. (1988) suggested a quadratic form with g0=0.0949 and g1=0.0794 for Case 1 waters, while for highly scattering coastal waters Lee et al. (1999) suggested g0=0.084 and g1=0.17. Later Lee et al. (2002), aiming at applying the forward model to both coastal and open-ocean waters, proposed average values of the coefficients from previous studies, g0=0.0895 and g1=0.1247.</p>
<p>Subsequently, focusing on above surface Rrs, Albert and Mobley (2003) and Park and Ruddick (2005) developed 4th order polynomial relationships in deep and shallow waters, while more recently Lee et al. (2011) and Hlaing et al. (2012) presented 2nd and 3rd order polynomial variants respectively.</p>
<p>Whilst there has been considerable improvement in our understanding of IOP-reflectance relationships since the pioneering studies by Morel and Gordon, there remains confusion in the field about the relative merits of wM and wG approaches. Moreover, there is an outstanding requirement to develop easily implemented relationships that permit end users to relate IOPs and reflectance values for both above and below surface reflectances corresponding to remote sensing and in situ applications. Most importantly, it is essential that the performance of any such relationship is equivalent across the wide range of concentrations of optical constituents found in natural waters and can be applied equally well in both clear Case 1 waters and optically complex Case 2 waters.</p>
<p>Aim of this study</p>
<p><strong>Exploit the strength of forward RT modelling to generate a consistent set of IOPs and corresponding simulated rrs and Rrs values which enables investigation of IOP-reflectance relationships across a wide variety of optically complex water conditions. </strong></p>
<h2 id="material-and-method">Material and method</h2>
<h3 id="field-data">Field data</h3>
<h3 id="in-situ-optical-measurements">In situ Optical Measurements</h3>
<p>All in situ data used in this study were collected in March 2009 during the BP09 cruise in the Ligurian Sea (Figure 1). Located in the northwest part of the Mediterranean Sea, this area includes both deep clear oceanic waters (considered Case 1) and shallow turbid coastal waters (considered Case 2). Among 60 sampled stations, 11 offshore stations and 23 onshore stations returned sufficient data set for the purpose of this work. A detailed description of the sampling location, data and methods can be found in McKee et al. (2014), Bengil et al. (2016) and Ramírez- Pérez et al. (2018)</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117160903264.png" alt="image-00021117160903264"><figcaption aria-hidden="true">image-00021117160903264</figcaption>
</figure>
<h3 id="laboratory-measurement">Laboratory measurement</h3>
<h3 id="bio-optical-model-developement">Bio-optical model developement</h3>
<p>Following the methodology reported in Ramírez-Pérez et al. (2018) for Case 2 waters, each total IOP can be considered as the sum of partial IOPs, and each partial IOP can be expressed as the product of SIOPs, and associated constituent concentrations:</p>
<p><span class="math display">\[
a_{Tot}(\lambda)=a_{ph}^{*}(\lambda)CHL+a_{bdet}^{*}(\lambda)CHL+a_{ndet}^{*}(\lambda)MSS+a_{cdom}^{*}(\lambda)CDOM+a_w(\lambda)
\]</span></p>
<p><span class="math display">\[
b_{Tot}(\lambda)=b_{ph}^{*}CHL+b_{ndet}^{*}(\lambda)MSS+b_w(\lambda)
\]</span></p>
<p><span class="math display">\[
c_{Tot}(\lambda)=a_{Tot}(\lambda)+b_{Tot}(\lambda)
\]</span></p>
<p><span class="math display">\[
b_{b \ Tot}=b_{bph}^{*}(\lambda)CHL+b_{bndet}^{*}(\lambda)MSS+b_{b \ w}{\lambda}
\]</span></p>
<p>where the subscripts represent the following five bio-optical constituents: phytoplankton (ph), <strong>biogenic detritus (bdet)</strong>, <strong>non-biogenic detritus (ndet)</strong>, coloured dissolved organic material (cdom) and pure water (w). The constituent concentrations are: chlorophyll, CHL, absorption of coloured dissolved organic material at 440 nm, CDOM, and mineral suspended solids, MSS (the non- biogenic detrital component of total suspended solids). Here</p>
<p>Here the detrital particulate absorption has been considered as the sum of two separate biogenic and non-biogenic components. Unfortunately it is <strong>not possible</strong> to experimentally partition scattering and backscattering measurements so the level of discrimination possible for these parameters is reduced.</p>
<p><strong>Biogenic partial IOPs are assumed to co-vary with CHL, while the non-biogenic partial IOPs are assumed to co-vary with MSS</strong></p>
<p>In this study, only values at each standard AC-9 wavelength have been considered.</p>
<p>These SIOPs have been determined by simple linear regressions forced through zero of partitioned IOPs against associated constituent concentrations from surface water samples.</p>
<p>The optimal SIOP value has been estimated using the linear regression slope with the 95% Confidence Interval (CI) representing the associated uncertainty (Figure 2, red dashed lines).</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/20201117154622.png"></p>
<p>Figure 2. Material-specific IOPs (black lines) with 95% confidence bounds (red dashed lines) obtained by linear regression at 9 wavelengths. (a) CHL-specific phytoplankton absorption – full data set. (b) CDOM absorption normalised at the signal at 440 nm – full data set. (c) CHL-specific biogenic detrital absorption – offshore data set. (d) CHL-specific phytoplankton scattering – offshore data set. (e) MSS-specific nonbiogenic detrital absorption coefficient – onshore data set. (f) MSS-specific nonbiogenic detrital scattering coefficient – onshore data set. SIOPs in (a)-(f) are recalculated SIOPs from Ramírez-Pérez et al. (2018) after further quality control measures were implemented. (g) the CHL-specific phytoplankton backscattering coefficient has been determined by linear regression forced through zero applied to the offshore data set, and (h) MSS-specific non biogenic detrital backscattering coefficient has been determined with the same methodology. Regressions on backscattering coefficients returned average R2 values of 0.78</p>
<p>In addition to the previously provided SIOPs for partitioned absorption and scattering coefficients, the material-specific backscattering coefficients are presented here following the same methodology. The chlorophyll-specific phytoplankton backscattering coefficient, shown in Figure 2g, was determined using data from offshore stations (considered Case 1 waters), where the particle population is assumed to be biogenic in origin. However,<strong>it is assumed to be representative of algal and biogenic detrital backscattering for all stations,</strong> offshore and onshore.</p>
<p>For onshore stations (considered Case 2 waters) it is assumed that there will be an additional non-biogenic contribution, <span class="math inline">\(b_{bndet}(\lambda)\)</span>, that can be found after subtraction of the water and biogenic contribution $(b_{bph}^{<em>}()</em>CHL) $ from <span class="math inline">\(b_{bTot}(\lambda)\)</span>. The MSS-∗ specific non biogenic detrital backscattering coefficient, <span class="math inline">\(b_{bpndet}^{*}(\lambda)\)</span>shown in Figure 2h was obtained by regressing <span class="math inline">\(b_{bpndet}(\lambda)\)</span> against MSS.</p>
<h3 id="radiative-transfer-simulations">Radiative transfer simulations</h3>
<p>Input IOPs for the simulations were generated by populating the bio-optical model, described in the previous section at 9 standard AC-9 wavelengths(412, 440, 488, 510, 532, 555, 650, 676, and 715 nm). A total of 1690 unique combinations of constituent concentrations and associated IOPs were calculated from log-spaced distributions of constituent concentrations in specific ranges (0.01&lt;CHL&lt;100 mg/m3, n = 13; 0.01&lt;MSS&lt;100 g/m3, n = 13; 0.01&lt;CDOM&lt;10 m- 1, n = 10)).</p>
<p>The data set of modeled IOPs was arranged in the form of 1690 virtual AC-9 and BB- 9 type files in the Matlab® environment (MathWorks Inc.).</p>
<p>The radiative transfer numerical model HydroLight 5.2 (Sequoia Scientific Inc.) was used to process the input IOP data and generate a synthetic dataset of remote sensing reflectance spectra, both below and above the sea-air interface, rrs(0-, λ) and Rrs(0+, λ) respectively.</p>
<p><strong>Flow of this simulation: SIOP-&gt;IOP-&gt;AOP, the first step just randomly input, the second step is using Hydrolight, this process is reversion/forward</strong></p>
<p>Based on the considered constituent concentration ranges, the total absorption at 412 nm, a(412), <strong>was in the range 0.0218–27.1346 m−1</strong>, while the total backscattering coefficient, bb(412),<strong>varied from 0.0036 to 2.3240 m−1</strong>, where the minimum (maximum) values represent the total IOPs when all the constituent concentrations are at their lowest (highest). Pure water absorption and scattering values were taken from Pope and Fry (1997) and Smith and Baker (1981).</p>
<p>Sky radiance was modelled using RADTRAN-X (Gregg &amp; Carder, 1990) with no wind and the mean Earth-Sun distance was employed.</p>
<p>Other atmospheric conditions such as sea-level pressure, relative humidity, horizontal visibility, and ozone concentration were set at default values, which are described in the HydroLight 5 technical documentation (Mobley &amp; Sundman, 2008).Raman (inelastic) scattering by water itself is ubiquitous and was considered since it is easy to model without any extra information, while <strong>fluorescence</strong> emissions due to chlorophyll and CDOM were not included, <strong>due to lack of information about fluorescence quantum yields</strong>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h2 id="result">Result</h2>
<h3 id="establishing-the-nature-of-iop---reflectance-relationships">Establishing the nature of IOP - reflectance relationships</h3>
<h4 id="fq-and-t">f/Q and T</h4>
<p>Variations in the bidirectional properties of the radiant flux leaving the water and returned toward the atmosphere have been extensively studied (Morel &amp; Gentili, 1991, 1993, 1996; Morel et al., 2002). The term f/Q in Equation 4 implicitly describes the magnitude of these variations, mainly due to changes in the light field geometry and bio-optical characteristics of the water body. Figure 3 shows distributions of f/Q as obtained in this study from RT simulations, calculated from Equation 4.<strong>These results are broadly consistent with Morel and Gentili (1993) who found values in the range 0.075 – 0.12.</strong> f/Q also influenced by variations in sun angles and viewing geometries. This is confirmed in Figures 4c and 4d where it can be seen that changing solar zenith angle has a <strong>small but defined</strong> impact on relationships between Rrs and both wM and wG.</p>
<p>In the present study, unless otherwise stated, the results refer only to a zenith Sun and a vertical viewing direction, <strong>meaning that the variability of the f/Q factor here is due mainly to differences in water constituent concentrations</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117172752050.png" alt="image-00021117172752050"><figcaption aria-hidden="true">image-00021117172752050</figcaption>
</figure>
<p>Figure 3. Frequency distribution (in the range 0-1, with 1 corresponding to 100%) of the ratio f/Q at 4 different wavelengths (440, 510, 555 and 676 nm), as in Figure 9(b) of Morel and Gentili (1993). Values of f/Q have been estimated from Equation 4.</p>
<p>The radiative transfer simulations can also be used to assess variability in the transmission factor T by rearranging Equation 3. Mobley (1999) suggested a range between 0.50 - 0.57 for typical ocean waters and solar and sensor geometries. In this study, T was found to vary in the range 0.52 - 0.63 considering the Sun at the zenith and the sensor in the vertical direction,with the differences in ranges between the two studies presumably associated with the range of water conditions (and therefore IOPs) considered.</p>
<p><strong>Overall, it is reasonable to suggest that the variability described by f/Q and T factors observed in this study are broadly consistent with previous studies.</strong></p>
<h4 id="rrs-and-iop">rrs and IOP</h4>
<p><strong>This study investigates relationships between IOPs and both rrs(λ) and Rrs(λ) considering both wM and wG forms, and also considers both forward and inverse directions.</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117173724526.png" alt="image-00021117173724526"><figcaption aria-hidden="true">image-00021117173724526</figcaption>
</figure>
<p>Plotting the HydroLight output rrs(λ) values against the input IOP terms, wM and wG,(Figure 4a and 4b), the relationships between rrs(λ) and either wM or wG are found to be non-linear but, crucially, monotonic.</p>
<p>Whereas the frequency distributions shown in Figure 3 do not offer any means of predicting a particular value of f/Q, Figure 4 suggests the possibility of establishing relationships between rrs and either wM or wG with strong predictive power in both the forward and reverse directions.</p>
<ul>
<li>both approaches (wM and wG) are equivalently valid</li>
<li>dependence of the sub-surface remote sensing reflectance on wavelength (400 nm &lt; λ &lt; 700 nm) is minimal in Case 2 waters(in fig. a and fig.b, different wavelength almost in same curve)</li>
<li>Changing the solar zenith angle (θs=0⁰; 30⁰; 60⁰) generates similar but non-identical nonlinear, monotonic relationships (Figures 4c and 4d) #### Rrs and IOP</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117192242014.png" alt="image-00021117192242014"><figcaption aria-hidden="true">image-00021117192242014</figcaption>
</figure>
<ul>
<li>Rrs and w_m/w_G has analogous behavior compared to the corresponding case of sub-surface reflectance, with slightly less sensitivity to changing solar angles.</li>
</ul>
<h3 id="determination-of-optimal-iop-rrs-relationships">Determination of optimal IOP-rrs relationships</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117193004264.png" alt="image-00021117193004264"><figcaption aria-hidden="true">image-00021117193004264</figcaption>
</figure>
<ul>
<li>significant divergence in the performance of each best- fit polynomial for low values of both wM and wG, and similarly when these parameters are derived from rrs(λ).</li>
<li>performance for high values of rrs(λ), wM and wG is less sensitive to choice of polynomial</li>
</ul>
<p><strong>It is therefore important to consider performance over all relevant ranges of signal strength when attempting to establish a set of optimal empirical relationships.</strong></p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117193140185.png" alt="image-00021117193140185"><figcaption aria-hidden="true">image-00021117193140185</figcaption>
</figure>
<p>When estimating rrs(λ) from wM or wG (Figure 7a and 7b) it is possible to directly compare the two approaches because the derived term in both cases is rrs(λ). However, when comparing retrievals of bb(λ)/a(λ) and bb(λ)/[a(λ)+bb(λ)], <strong>it is important to bear in mind that the two variables are not numerically equivalent (Figure 7c and 7d).</strong></p>
<ul>
<li>The results of this systematic exercise show that higher order polynomial models provide better performance than second order models to ensure similar goodness of fit across all decades of signal variation.</li>
<li>recommended relationships in retrieving rrs(λ) from wM and vice versa are 6th and 5th order polynomials respectively (Figure 7a and 7c)</li>
<li>A 3rd order polynomial is the suggested choice for retrieving rrs(λ) from wG, (Figure 7b),</li>
<li>while a 6th order polynomial is needed for estimating wG from rrs(λ) (Figure 7d).</li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117194324597.png" alt="image-00021117194324597"><figcaption aria-hidden="true">image-00021117194324597</figcaption>
</figure>
<p>It is interesting to note that wM and wG approaches produce similar levels of MAE if sufficiently well-tuned polynomials are selected.</p>
<p>Overall there is no significant accuracy benefit of one form of IOP expression over the other.</p>
<p>The results of this exercise show that with suitably careful selection of empirical relationship, using wM or wG is broadly equivalent.</p>
<h3 id="determination-of-optimal-iop-rrs-relationshops">Determination of optimal IOP-Rrs relationshops</h3>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200844135.png" alt="image-00021117200844135"><figcaption aria-hidden="true">image-00021117200844135</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200909132.png" alt="image-00021117200909132"><figcaption aria-hidden="true">image-00021117200909132</figcaption>
</figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117200924727.png" alt="image-00021117200924727"><figcaption aria-hidden="true">image-00021117200924727</figcaption>
</figure>
<p>This part is almost the same with previous one. Here is the summary.</p>
<ul>
<li>higher order polynomials are suggested to ensure similar goodness of fit across all decades of signal variation, with the greatest impact occurring at small data values.</li>
<li>the recommended relationships in retrieving Rrs(λ) from wM and vice versa are the 5th order polynomials in both case</li>
<li>for retrieving Rrs(λ) from wG, a 4th order polynomial is the suggested choice (Figure 9b), while a 7th order polynomial is needed for estimating wG from Rrs(λ) (Figure 9d).</li>
<li>Rrs(λ) can be expressed as a function of the absorption and backscattering coefficients of the water and it is equally valid to represent the IOPs using wM or wG.</li>
<li>The limiting factor is not choice of either wM or wG, rather it is in selecting an appropriate formulation to represent variation the non-linear relationship with IOPs.</li>
</ul>
<h3 id="comparison-with-previous-studies">Comparison with previous studies</h3>
<p>the existing established models for representing rrs(λ) (Gordon et al., 1988 and Lee et al., 2002, 2004) or Rrs(λ), based on low order polynomial relationships, are unable to fully account for the effect of multiple scattering which is particularly relevant in Case 2 waters (Wong et al., 2019).</p>
<p>Interestingly, the results presented above suggest that the <strong>performance of low-order polynomials tends to be worst for clear waters.</strong> It is clear from this analysis that higher order polynomials are generally necessary in order to achieve optimal performance across the full range of natural variability.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117202129722.png" alt="image-00021117202129722"><figcaption aria-hidden="true">image-00021117202129722</figcaption>
</figure>
<ul>
<li><p>Poly5 model is very close to the version of Gordon’s model with coefficients suggested by Lee et al. (2002) which was intended to be applicable to both Case 1 and Case 2 waters.</p></li>
<li><p>Applying the Wong et al. (2019) approach to our data set presents smaller MAEs for lower values of wG, but higher MAE for higher values of wG.</p></li>
<li><p>It is important to note that the family of curve models shown in Figure 10a falls within the 95% confidence bounds of the proposed Poly5 relationship at the high end of the range (Figure 10c) while the 95% confidence bounds at the low end (Figure 10d) are an order of magnitude greater than the MAE differences between the various proposed relationships for the equivalent range in Figure 10b.</p></li>
</ul>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021117202148259.png" alt="image-00021117202148259"><figcaption aria-hidden="true">image-00021117202148259</figcaption>
</figure>
<h2 id="discussion-and-conclusion">Discussion and conclusion</h2>
<p>In this paper</p>
<ul>
<li><p>a series of radiative transfer simulations across a very broad range of optical conditions has been conducted using the HydroLight RT code.</p></li>
<li><p>Input IOPs have been supplied through a linear spectral bio-optical model, varying the concentrations of in-water optical constituents across a wide range of concentrations to simulate natural variability</p></li>
<li><p>The resulting set of synthetic above and below surface reflectances have enabled investigation of relationships with IOPs expressed as either wM or wG.</p></li>
<li><p>The results demonstrate that the relationship between IOPs and either rrs or Rrs are highly predictable and can be well modelled by a non-linear but monotonic curve, which is not significantly wavelength dependent for 400nm&lt;λ&lt;700nm.</p></li>
<li><p>However, it has been shown here that in order to achieve consistent levels of prediction performance across the broad range of optical coastal water conditions considered, it is generally necessary to consider higher order polynomial relationships.</p></li>
<li><p>Comparison of wM and wG variants demonstrate effectively equivalent performance: there is no immediate advantage or disadvantage to use of either form in coastal waters.</p></li>
<li><p>The general proposition that either combination of absorption and backscattering contains sufficient relevant information to both predict and interpret remote sensing signals.</p></li>
<li><p>There may be situations where future end users may have reason to prefer use of one form over another and this study suggests there is no reason to be concerned over either</p></li>
</ul>
<h2 id="annotation">Annotation</h2>
<p>This is a very fundamental paper related to the relationship between IOP and AOP. Specifically, this paper examine two relationship, f/Q and polynomial. I do not tend to make a summary for this paper all.</p>
<p>One thing I can learn from this paper is that how f/Q and polynomial effected by the environment. f/Q is mainly influenced by the water constitution, and small influenced by the sun angles, viewing geometries and solar zenith. It is in the range of 0.075 – 0.12.</p>
<p>For the relationship between rrs and IOP, the author examined different order of polynimal. The poly5 the author used seems slightly better than Lee 02 and Wong 2019, but the author said that this conclusion might be only true in the area they collected data. The poly5 is difficult to solve in the inversion problem, but I can try it in the reversion problem.</p>
<p>One interested thing is that the author use SIOP to generate IOP dataset. I'm wondering what could influence SIOP.</p>
<h1 id="algorithm-to-derive-inherent-optical-properties-from-remote-sensing-reflectance-in-turbid-and-eutrophic-lakes">Algorithm to derive inherent optical properties from remote sensing reflectance in turbid and eutrophic lakes</h1>
<p>10.1364/ao.58.008549</p>
<p>This paper is just to explore the failure and effort could do to improve QAA. So I haven't read it totally.</p>
<p>There are several things need to be noticed in this algorithm.</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021118153124186.png" alt="image-00021118153124186"><figcaption aria-hidden="true">image-00021118153124186</figcaption>
</figure>
<ol type="1">
<li><p>This paper changed the refferenced band to 750</p></li>
<li><p>First use emprical method to estimated ap750, and treat it as a constant value. Here is use ad750 from other paper</p></li>
<li><p>Then use analytical to built bbp750</p></li>
<li><p>Then an optimized parameter to get Y, the power exponent of bop shape</p></li>
<li><p>Then retrieve <span class="math inline">\(a_{nw}\)</span>, non-water absorption.</p></li>
<li><p>At last it retrieve <span class="math inline">\(a_{ph}\)</span> first, then get<span class="math inline">\(a_{dg}\)</span></p>
<p>The most important contribution I think is 2 4 6</p></li>
</ol>
<h1 id="modeling-the-remote-sensing-reflectance-of-highly-turbid-waters">Modeling the remote-sensing reflectance of highly turbid waters</h1>
<p>This paper acutually similar with the first one I read. He made a ploy4 model from IOP to rrs</p>
<h1 id="variability-in-the-chlorophyll-specific-absorption-coefficients-of-natural-phytoplankton-analysis-and-parameterization">Variability in the chlorophyll-specific absorption coefficients of natural phytoplankton: Analysis and parameterization</h1>
<p>https://doi.org/10.1029/95JC00463</p>
<p>I finally know how band shifting using that equation to estimate <span class="math inline">\(a_{ph}\)</span> at different wavelength.</p>
<p>Actually I think I need to check the SIOP paper Ramírez- Pérez et al. (2018), I really think.</p>
<p>In this paper, the author parameteration the app spectra shape by the following formula: <span class="math display">\[
a_{ph}^{*}(\lambda)=A(\lambda)*CHL^{-B(\lambda)}
\]</span> Although in the table they attached, they found in some wavelength the r^2 is relative low, they still use this.</p>
<p>Substitute the SIOP by IOP, we can get another form of the former equation: <span class="math display">\[
a_{ph}(\lambda)=A(\lambda)*CHL^{1-B(\lambda)}
\]</span></p>
<p>After using QAA, we can got <span class="math inline">\(a_{ph}(443)\)</span></p>
<p>So for <span class="math inline">\(a_{ph}(443)\)</span>, we can know that <span class="math display">\[
a_{ph}(443)=A(443)*CHL^{1-B(443)}
\]</span> Just divide these two equations.</p>
<p>And maybe I can found some other parameteration in coastal area for a ph spectra shape.</p>
<h1 id="section"></h1>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>R(0-,λ) (nondim), defined as the ratio of the upwards to downwards planar irradiances,R(0-,λ)= Eu(0-,λ)/ Ed(0-,λ);Q=Eu(0-,λ)/Lu(0-,λ);so Lu(0-,λ)=Eu(0-,λ)/Q, substitute and get<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The detailed information about phytoplankton fluorescence is in the Book 'Real-time Coastal Observing Systems <em>for</em> Marine Ecosystem Dynamics <em>and</em> Harmful Algal Blooms', Chapter 7, 'Phytoplankton fluorescence: theory, current literature and <em>in situ</em> measurement'<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Research Basis</tag>
        <tag>Ocean Color</tag>
        <tag>Ocean Optics</tag>
        <tag>Inherent Optical Properties</tag>
      </tags>
  </entry>
  <entry>
    <title>MODIS水色数据处理教程</title>
    <url>/posts/ce08f3a2.html</url>
    <content><![CDATA[<p>这个教程主要分为两部分：</p>
<ol type="1">
<li>应用python分析MODIS水色遥感数据</li>
<li>SeaDAS OCSSW的安装与应用</li>
</ol>
<p>English version is coming soon.</p>
<a id="more"></a>
<h1 id="应用python分析modis水色遥感数据">应用python分析MODIS水色遥感数据</h1>
<h2 id="程序包及工作环境">程序包及工作环境</h2>
<p>如果这个步骤你花了很久才搞定的话，去用R吧，我朋友想跟我学python的都让我劝退学R了。</p>
<h3 id="anaconda和-pycharm">Anaconda和 pycharm</h3>
<p>Anaconda里涵盖了很多科学计算要用到的包，同时也给了一个很好用的包管理工具。下载地址https://www.anaconda.com/；如果在国内的话，推荐使用清华镜像进行下载https://mirror.tuna.tsinghua.edu.cn/help/anaconda/，然后再更换为国内源https://www.cnblogs.com/yikemogutou/p/11396045.html。</p>
<p>下载完anaconda之后，打开anaconda navigator把Jupyter notebook(或者Jupyter lab)安装好，我个人通常会用这个用一张遥感数据进行程序的调试，然后在pycharm里改成批处理。</p>
<p>pycharm是一个编辑器，同时支持python,R和markdown。对于本菜鸡来说，这个编辑器可以很方便的打开Terminal和python console，添加TODO和利用git备份，最重要的是管理环境方便，不用每次都active啥啥啥。下载地址https://www.jetbrains.com/pycharm/。</p>
<h3 id="环境创建">环境创建</h3>
<h4 id="地理信息数据分析环境">地理信息数据分析环境</h4>
<p>打开pycharm，新建一个项目或者打开你之前的项目，然后preference-project interpreter-show all，右下角小加号添加一个python interpreter，选择Conda Environment，用你刚刚安装好的anaconda来创建一个新的环境。</p>
<p>结束之后回到编辑器界面，最下面有四个选项 TODO,Version Control,Terminal,Python Console。这四个东西和刚才那个project interpreter基本是我平时比较喜欢用pycharm的最主要原因了。在写程序时#TODO然后写上要做的事情，就可以在下面TODO页面里看到要做的东西;Version Control 可以提供本地或者github的版本控制，具体设置方法可以参考https://www.jetbrains.com/help/pycharm/manage-projects-hosted-on-github.html；Terminal其实就是一个bash，并且是在你刚才创建的环境里面，不需要去确认环境啥的，也不用添加全局变量，就相当于一个anaconda prompt; python console就相当于一个命令行的python，在右上角绿色小三角附近点下拉菜单Edit configuration，然后选择run in python console，就可以在右边框里看到变量，比较适合我这种从matlab迁移过来的人。</p>
<p>先打开Terminal，依次运行</p>
<p><code>conda install -c conda-forge numpy h5py netcd4 opencv-python requests matplotlib pandas scipy scikit-learn</code></p>
<p><code>conda update -all</code></p>
<p>在这里一般不会出问题，-c conda-forge可以安装由大佬在开源社区里上传的程序包</p>
<p><code>conda install -c conda-forge pyresample</code></p>
<p>这里可能会遇到问题，这里有可能有两种问题，一个是C语言编译器的问题，下载安装Microsoft Visual Studio Community 2017然后再运行一下这句话就好了；另一种就是GDAL的问题。</p>
<p>GDAL(Geospatial Data Abstraction Library)是一个在X/MIT许可协议下的开源栅格空间数据转换库，可以参考大佬翻译的这份中文教程https://www.osgeo.cn/python_gdal_utah_tutorial/index.html来学习一下。之前电脑上没有安装过python相关的东西的话一般不会遇到这个问题。如果你是在windows平台，那么我推荐你来安装OSGeo4W来搞定这个问题https://trac.osgeo.org/osgeo4w/；除此之外，还有两种方法，一个是你重新搞个环境，不要加入之前的包再来安装一次，另一个是下载whl文件来安装。</p>
<p>记得每次装完新的都来个conda update -all。</p>
<p>最后</p>
<p><code>conda install -c conda-forge basemap basemape-data-hires</code></p>
<p><code>conda install -c conda-forge gdal</code></p>
<p><code>conda update -all</code></p>
<p>如果一切顺利，恭喜你完成了最麻烦的一步。</p>
<p>之后可以参照我之前写过的这篇文章里面的python包，https://lifeodyssey.github.io/post/3aa0ed1a.html ,这些包都安装之后基本够用了。</p>
<p>其实环境这个问题可以用Docker来解决，之前有看到过这个大佬https://zhuanlan.zhihu.com/p/108012664的文章，我也还在研究，争取尽快搞出来一个水色人的Docker。</p>
<h4 id="pycharm及jupyter插件">pycharm及Jupyter插件</h4>
<p>这个是属于个人喜好。</p>
<p>在pycharm-preference-plugins里可以安装插件，我安装了.*ignore,Dart,Kite和Material Theme UI，因为我有的时候还会用R，虽然R studio更好用，但是我也装了R Language for IntelliJ这个，来进行一些小的调试。</p>
<p>Jupyter个人一般只用来学习新的知识、调试和改bug，或者用来教别人的时候用，所以我这里用的还是Jupyter notebook,没有升级到Jupyterlab，安装教程可见https://github.com/ipython-contrib/jupyter_contrib_nbextensions。</p>
<p>在Terminal里依次输入</p>
<p><code>conda install -c conda-forge jupyter_contrib_nbextensions</code></p>
<p><code>jupyter contrib nbextension install --user</code></p>
<p><code>conda update -all</code></p>
<p>然后在Terminal里输入</p>
<p><code>Jupyter notebook</code></p>
<p>就可以看到浏览器里蹦出来一个Jupyter notebook</p>
<p>点开Configurable nbextensions中勾选variable inspector，然后随便新建一个notebook，点开那个小瞄准镜就可以看到变量了。我平时没事就只用这个了。</p>
<h2 id="modis-数据读取重投影及绘图">MODIS 数据读取、重投影及绘图</h2>
<p>数据的下载可以参考https://lifeodyssey.github.io/post/8636bca2.html</p>
<p>直接上我写的代码，造福千万家，但是希望你直接用的时候能够知其然也知其所以然。感谢实验室之前毕业的前辈给我提供的代码样本</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> netCDF4 <span class="keyword">as</span> nc4</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> geo_Collection <span class="keyword">import</span> geo_web <span class="keyword">as</span> gs</span><br><span class="line"><span class="keyword">from</span> QAAV6 <span class="keyword">import</span> QAAv6</span><br><span class="line">minlat = <span class="number">32.5</span></span><br><span class="line">minlon = <span class="number">130.5</span></span><br><span class="line">maxlat = <span class="number">35</span></span><br><span class="line">maxlon = <span class="number">136</span></span><br><span class="line"><span class="comment"># area of full seto-inland sea</span></span><br><span class="line">x = np.arange(minlon, maxlon, <span class="number">0.01</span>)  <span class="comment"># 1 km grid,</span></span><br><span class="line">y = np.arange(maxlat, minlat, <span class="number">-0.01</span>)</span><br><span class="line">nc_file = nc4.Dataset(filename, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">lon = nc_file.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;longitude&#x27;</span>][:]</span><br><span class="line">lat = nc_file.groups[<span class="string">&#x27;navigation_data&#x27;</span>].variables[<span class="string">&#x27;latitude&#x27;</span>][:]</span><br><span class="line">variables = nc_file.groups[<span class="string">&#x27;geophysical_data&#x27;</span>].variables</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> variables:</span><br><span class="line">    var = variables[i][:]</span><br><span class="line">    np.where(var &lt;= <span class="number">0</span>, var, np.nan)</span><br><span class="line">    <span class="keyword">if</span> i != <span class="string">&#x27;l2_flags&#x27;</span>:</span><br><span class="line">        var_re, grid = gs.swath_resampling(var, lon, lat, x, y, <span class="number">5000</span>)  <span class="comment"># 1 km grid</span></span><br><span class="line">        <span class="comment"># var_re=var_re.filled()</span></span><br><span class="line">        <span class="keyword">if</span> np.ma.is_mask(var_re):</span><br><span class="line">            var_re.mask=np.ma.nomask</span><br><span class="line">            var_re[var_re==<span class="number">-32767.0</span>]=np.nan</span><br><span class="line">         variables[i] = var_re</span><br><span class="line">     <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># var_re = var_re.filled()</span></span><br><span class="line">          variables[i] = var</span><br><span class="line">lons = grid.lons</span><br><span class="line">lats = grid.lats</span><br><span class="line"><span class="comment">#以叶绿素为例</span></span><br><span class="line">chl = variables[<span class="string">&#x27;chlor_a&#x27;</span>]</span><br><span class="line">plot_geo_image(chl, lon, lat, label=<span class="string">&#x27;CHL [mg/m$^3$]&#x27;</span>,</span><br><span class="line">               title=os.path.basename(file))</span><br><span class="line">ncfile.close()<span class="comment">#一定要记得这句</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>同时给出这里面用到的两个子函数和QAA的代码。</p>
<p>（QAA的代码还需要一些改进）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pyresample</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.basemap <span class="keyword">import</span> Basemap</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> colors</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> RectSphereBivariateSpline</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> LogNorm</span><br><span class="line"><span class="comment">#from  deco import *</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">swath_resampling</span>(<span class="params">src_data: np.ma.array, src_lon: np.array, src_lat: np.array,</span></span></span><br><span class="line"><span class="function"><span class="params">                     trg_lon: np.array, trg_lat: np.array, search_radius: float</span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(trg_lon.shape) == <span class="number">1</span>:</span><br><span class="line">        grid_def = pyresample.geometry.SwathDefinition(*np.meshgrid(trg_lon, trg_lat))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        grid_def = pyresample.geometry.SwathDefinition(lons=trg_lon, lats=trg_lat)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#source grid with original swath data</span></span><br><span class="line">    <span class="comment"># if len(src_lon.shape) == 1:</span></span><br><span class="line">    <span class="comment">#     swath_def = pyresample.geometry.SwathDefinition(*np.meshgrid(src_lon, src_lat,sparse=True))</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#     swath_def = pyresample.geometry.SwathDefinition(lons=src_lon, lats=src_lat)</span></span><br><span class="line"></span><br><span class="line">    swath_def = pyresample.geometry.SwathDefinition(lons=src_lon, lats=src_lat)</span><br><span class="line">    <span class="comment"># resample (here we use nearest. Bilinear, gaussian and custom defined methods are available)</span></span><br><span class="line">    <span class="comment"># for more, visit https://pyresample.readthedocs.io/en/latest/</span></span><br><span class="line">    result = pyresample.kd_tree.resample_nearest(swath_def, src_data, grid_def, epsilon=<span class="number">0.5</span>,</span><br><span class="line">                                                 fill_value=np.nan, radius_of_influence=search_radius)</span><br><span class="line">    <span class="keyword">return</span> result, grid_def</span><br><span class="line"></span><br><span class="line"><span class="comment">#@concurrent</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_geo_image</span>(<span class="params">sds: np.ma.array, lon: np.ndarray, lat: np.ndarray, log10: bool = True, title: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   label: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   caxis: list = None, lon_range: list = None, lat_range: list = None, save_image: str = None,</span></span></span><br><span class="line"><span class="function"><span class="params">                   dpi: int = <span class="number">400</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> len(lon.shape) == <span class="number">1</span>:</span><br><span class="line">        print(<span class="string">&#x27;MeshGridding...&#x27;</span>)</span><br><span class="line">        lon, lat = np.meshgrid(lon, lat)</span><br><span class="line"></span><br><span class="line">    lon_0 = (lon.min() + lon.max()) / <span class="number">2</span></span><br><span class="line">    lat_0 = (lat.min() + lat.max()) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">f&#x27;Lat: [<span class="subst">&#123;lat.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;lat.max():<span class="number">.3</span>f&#125;</span>] | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;Lon: [<span class="subst">&#123;lon.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;lon.max():<span class="number">.3</span>f&#125;</span>] | &#x27;</span></span><br><span class="line">          <span class="string">f&#x27;SDS: [<span class="subst">&#123;sds.min():<span class="number">.3</span>f&#125;</span>, <span class="subst">&#123;sds.max():<span class="number">.3</span>f&#125;</span>]&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lon_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (lat_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        m = Basemap(llcrnrlon=min(lon_range), llcrnrlat=min(lat_range),</span><br><span class="line">                    urcrnrlon=max(lon_range), urcrnrlat=max(lat_range),</span><br><span class="line">                    resolution=<span class="string">&#x27;f&#x27;</span>, lon_0=lon_0, lat_0=lat_0, projection=<span class="string">&#x27;tmerc&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        m = Basemap(llcrnrlon=lon.min(), llcrnrlat=lat.min(),</span><br><span class="line">                    urcrnrlon=lon.max(), urcrnrlat=lat.max(),</span><br><span class="line">                    resolution=<span class="string">&#x27;f&#x27;</span>, lon_0=lon_0, lat_0=lat_0, projection=<span class="string">&#x27;tmerc&#x27;</span>)</span><br><span class="line">    x2d, y2d = m(lon, lat)</span><br><span class="line"></span><br><span class="line">    fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span> * m.aspect))</span><br><span class="line">    ax = fig.add_axes([<span class="number">0.08</span>, <span class="number">0.1</span>, <span class="number">0.7</span>, <span class="number">0.7</span>], facecolor=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">    <span class="comment"># changed to facecolor 8 October 2019</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (lon_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>) <span class="keyword">and</span> (lat_range <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>):</span><br><span class="line">        parallels = np.arange(min(lat_range), max(lat_range), <span class="number">3</span>)</span><br><span class="line">        meridians = np.arange(min(lon_range), max(lon_range), <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        parallels = meridians = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> caxis <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        cmn, cmx = min(caxis), max(caxis)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        cmn, cmx = sds.min(), sds.max()</span><br><span class="line">    <span class="comment"># m.drawparallels(parallels, fontsize=10, linewidth=0.25, dashes=[7, 15],</span></span><br><span class="line">    <span class="comment">#                  color=&#x27;k&#x27;, labels=[1, 0, 1, 1])</span></span><br><span class="line">    <span class="comment"># m.drawmeridians(meridians, fontsize=10, dashes=[7, 15],</span></span><br><span class="line">    <span class="comment">#                  linewidth=0.3, color=&#x27;k&#x27;, labels=[1, 1, 0, 1])</span></span><br><span class="line">    <span class="comment">#ncl = 150</span></span><br><span class="line">    <span class="comment">#if log10 is True:</span></span><br><span class="line">    <span class="comment">#    norm = colors.LogNorm(vmin=cmn, vmax=cmx)</span></span><br><span class="line">    <span class="comment">#else:</span></span><br><span class="line">     <span class="comment">#   bounds = np.linspace(cmn, cmx, ncl)</span></span><br><span class="line">     <span class="comment">#   norm = colors.BoundaryNorm(boundaries=bounds, ncolors=ncl)</span></span><br><span class="line"></span><br><span class="line">    p = m.pcolor(x2d, y2d, sds, vmin=cmn,vmax=cmx, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.title(title)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># divider = make_axes_locatable(ax)</span></span><br><span class="line">    <span class="comment"># cax = divider.append_axes(&#x27;vertical&#x27;, size=&quot;3%&quot;, pad=0.05)</span></span><br><span class="line">    <span class="comment">#cax = plt.axes([cmn, 0, cmx])  # setup colorbar axes</span></span><br><span class="line"></span><br><span class="line">    cb = m.colorbar(p,location=<span class="string">&quot;right&quot;</span>,size=<span class="string">&quot;5%&quot;</span>,pad=<span class="number">0.1</span>)  <span class="comment"># draw colorbar</span></span><br><span class="line">    <span class="comment">#if label is not None:</span></span><br><span class="line">    <span class="comment"># cb.set_label(&quot;%s&quot; % label)</span></span><br><span class="line">    <span class="comment"># plt.sca(ax)  # make the original axes current again</span></span><br><span class="line">    <span class="comment"># plt.clim(cmn, cmx)</span></span><br><span class="line">    <span class="comment">#unit=&#x27;Elevation to the sea level&#x27;</span></span><br><span class="line">    <span class="comment">#cb.set_label(unit, rotation=270, labelpad=10.0, fontsize=10)</span></span><br><span class="line">    cb.ax.tick_params(labelsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    m.drawcoastlines()</span><br><span class="line">    m.drawcountries()</span><br><span class="line">    m.fillcontinents()</span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> save_image <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        plt.savefig(save_image, dpi=dpi, facecolor=<span class="string">&#x27;w&#x27;</span>, edgecolor=<span class="string">&#x27;w&#x27;</span>, orientation=<span class="string">&#x27;portrait&#x27;</span>)</span><br><span class="line">        plt.show()</span><br><span class="line">        plt.close()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">creategrid</span>(<span class="params">min_lon, max_lon, min_lat, max_lat, cell_size_deg, mesh=False</span>):</span></span><br><span class="line"><span class="comment">#Output grid within geobounds and specifice cell size</span></span><br><span class="line"><span class="comment">#cell_size_deg should be in decimal degrees’’’</span></span><br><span class="line"></span><br><span class="line">    min_lon = math.floor(min_lon)</span><br><span class="line">    max_lon = math.ceil(max_lon)</span><br><span class="line">    min_lat = math.floor(min_lat)</span><br><span class="line">    max_lat = math.ceil(max_lat)</span><br><span class="line">    lon_num = (max_lon - min_lon)/cell_size_deg</span><br><span class="line">    lat_num = (max_lat - min_lat)/cell_size_deg</span><br><span class="line">    grid_lons = np.zeros(lon_num) <span class="comment"># fill with lon_min</span></span><br><span class="line">    grid_lats = np.zeros(lat_num) <span class="comment"># fill with lon_max</span></span><br><span class="line">    grid_lons = grid_lons + (np.assary(range(lon_num))*cell_size_deg)</span><br><span class="line">    grid_lats = grid_lats + (np.assary(range(lat_num))*cell_size_deg)</span><br><span class="line">    grid_lons, grid_lats = np.meshgrid(grid_lons, grid_lats)</span><br><span class="line">    grid_lons = np.ravel(grid_lons)</span><br><span class="line">    grid_lats = np.ravel(grid_lats)</span><br><span class="line">    <span class="comment">#if mesh = True:</span></span><br><span class="line">    <span class="comment"># grid_lons = grid_lons</span></span><br><span class="line">    <span class="comment"># grid_lats = grid_lats</span></span><br><span class="line">    <span class="keyword">return</span> grid_lons, grid_lats</span><br></pre></td></tr></table></figure>
<p>QAAv6</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.interpolate <span class="keyword">import</span> Akima1DInterpolator <span class="keyword">as</span> Akima</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> deco <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> math <span class="keyword">as</span> m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># wavelengths = &#123;</span></span><br><span class="line"><span class="comment">#     &#x27;OLI&#x27;   : [442.98, 482.49, 561.33, 654.61],</span></span><br><span class="line"><span class="comment">#     &#x27;MSI&#x27;   : [443.93, 496.54, 560.01, 664.45],</span></span><br><span class="line"><span class="comment">#     &#x27;OLCI&#x27;  : [411.3999939, 442.63000488, 490.07998657, 510.07000732, 560.05999756, 619.97998047, 664.85998535, 673.61999512, 681.15002441], # 9 band insitu</span></span><br><span class="line"><span class="comment">#     &#x27;OLCI2&#x27; : [400, 412.5, 442.5, 490, 510, 560, 620, 665, 673.75, 681.25, 708.75, 753.75, 761.25, 764.375, 767.5, 778.75], # 16 band LUT</span></span><br><span class="line"><span class="comment">#     &#x27;VI&#x27;    : [412.49, 444.17, 486.81, 549.99, 670.01],</span></span><br><span class="line"><span class="comment">#     &#x27;AER&#x27;   : [412, 442, 490, 530, 551, 668],</span></span><br><span class="line"><span class="comment">#     &#x27;MOSIA&#x27; : [412, 443, 469,488,531,547,555,645,667,678],</span></span><br><span class="line"><span class="comment">#     &#x27;GOCI&#x27;  : [412, 443, 490, 555, 660, 680],</span></span><br><span class="line"><span class="comment">#     &#x27;SGLI&#x27;  : [380,412,443,490,530,565,673.5]</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment">#@concurrent</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QAAv6</span>(<span class="params">Rrs</span>):</span></span><br><span class="line">    <span class="comment">#acording to Lee,QAAv6</span></span><br><span class="line">    <span class="comment">#write by Zhou,20191130</span></span><br><span class="line">    <span class="comment">#Input data need to be an arrary that contain 10 bands Rrs of MODIS,from short wavelength to long wavelength in a certain station</span></span><br><span class="line">    <span class="comment">#Output is a tuple, first array is aph,second array is bbp</span></span><br><span class="line">    <span class="comment">#use as import QAAV6</span></span><br><span class="line"><span class="comment"># B1: 412 nm 0</span></span><br><span class="line"><span class="comment"># B2: 443 nm 1</span></span><br><span class="line"><span class="comment"># B3: 469 nm 2</span></span><br><span class="line"><span class="comment"># B4: 488 nm 3</span></span><br><span class="line"><span class="comment"># B5: 531 nm 4</span></span><br><span class="line"><span class="comment"># B6: 547 nm 5</span></span><br><span class="line"><span class="comment"># B7: 555 nm 6</span></span><br><span class="line"><span class="comment"># B8: 645 nm 7</span></span><br><span class="line"><span class="comment"># B9: 667 nm 8</span></span><br><span class="line"><span class="comment"># B10: 678 nm 9</span></span><br><span class="line"></span><br><span class="line">    Lambda=np.array([<span class="number">412</span>, <span class="number">443</span>, <span class="number">469</span>,<span class="number">488</span>,<span class="number">531</span>,<span class="number">547</span>,<span class="number">555</span>,<span class="number">645</span>,<span class="number">667</span>,<span class="number">678</span>])</span><br><span class="line">    nbands=np.shape(Lambda)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    IOPw=np.array([[<span class="number">0.003344468</span>,<span class="number">0.004572564</span>],</span><br><span class="line">    [<span class="number">0.00244466</span>,<span class="number">0.00635</span>],</span><br><span class="line">    [<span class="number">0.001910803</span>,<span class="number">0.010483637</span>],</span><br><span class="line">    [<span class="number">0.001609567</span>,<span class="number">0.014361745</span>],</span><br><span class="line">    [<span class="number">0.00111757</span>,<span class="number">0.043747657</span>],</span><br><span class="line">    [<span class="number">0.000983055</span>,<span class="number">0.053262848</span>],</span><br><span class="line">    [<span class="number">0.000923288</span>,<span class="number">0.0595</span>],</span><br><span class="line">    [<span class="number">0.000482375</span>,<span class="number">0.325</span>],</span><br><span class="line">    [<span class="number">0.00041731</span>,<span class="number">0.433497423</span>],</span><br><span class="line">    [<span class="number">0.00038884</span>,<span class="number">0.457440162</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     if(Rrs=np.nan):</span></span><br><span class="line">    <span class="comment">#     return np.nan</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment"># bbw from Morel (1974).aw  from Pope and Fry (1997)</span></span><br><span class="line">    bbp = np.ones(<span class="number">10</span>)</span><br><span class="line">    adg = np.ones(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">if</span>(np.nan <span class="keyword">in</span> Rrs):</span><br><span class="line">        bbp[:]=np.nan</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        bw=IOPw[:,<span class="number">0</span>]<span class="comment">#backscaterring of pure water</span></span><br><span class="line">        aw=IOPw[:,<span class="number">1</span>]<span class="comment">#absorption of pure water</span></span><br><span class="line">        rrs = Rrs / (<span class="number">0.52</span> + <span class="number">1.7</span> * Rrs)</span><br><span class="line">        g0 = <span class="number">0.089</span></span><br><span class="line">        g1 = <span class="number">0.1245</span></span><br><span class="line">        u = (-g0 + ((g0 ** <span class="number">2</span>) + <span class="number">4</span> * g1 * rrs) ** <span class="number">0.5</span>) / (<span class="number">2</span> * g1)</span><br><span class="line"></span><br><span class="line">        aph = np.ones(<span class="number">10</span>)<span class="comment">#adg is the absorption of CDOM and NAP</span></span><br><span class="line">        <span class="keyword">if</span> Rrs[<span class="number">6</span>]&lt;<span class="number">0.0015</span>:<span class="comment">#select 555 as reference</span></span><br><span class="line">            r=<span class="number">550</span></span><br><span class="line">            p1=(rrs[<span class="number">1</span>] + rrs[<span class="number">3</span>])</span><br><span class="line">            p2 = rrs[<span class="number">6</span>] + <span class="number">5</span> * (((rrs[<span class="number">8</span>]) ** <span class="number">2</span>)) / (rrs[<span class="number">3</span>])</span><br><span class="line">            x = np.log10(p1 / p2)</span><br><span class="line">            ar = aw[<span class="number">6</span>] + np.power(<span class="number">10</span>, (<span class="number">-1.146</span> - <span class="number">1.366</span> * x - <span class="number">0.469</span> * (x ** <span class="number">2</span>)))<span class="comment"># step 2</span></span><br><span class="line">            bbpr=((u[<span class="number">6</span>]*ar)/(<span class="number">1</span>-u[<span class="number">6</span>]))-bw[<span class="number">6</span>]<span class="comment">#step3</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            r=<span class="number">670</span></span><br><span class="line">            p1 = Rrs[<span class="number">8</span>] / (Rrs[<span class="number">1</span>] + Rrs[<span class="number">3</span>])</span><br><span class="line">            p2 = <span class="number">0.39</span> * (p1 ** <span class="number">1.14</span>)</span><br><span class="line">            ar = (aw[<span class="number">8</span>]) + p2  <span class="comment"># step2</span></span><br><span class="line">            bbpr = (u[<span class="number">8</span>] * ar / (<span class="number">1</span> - (u[<span class="number">8</span>])) - (bw[<span class="number">8</span>]))  <span class="comment"># step3</span></span><br><span class="line">        eta=<span class="number">2</span>*(<span class="number">1</span><span class="number">-1.2</span>*np.exp(<span class="number">-0.9</span>*(rrs[<span class="number">1</span>]/rrs[<span class="number">6</span>]))) <span class="comment">#step4</span></span><br><span class="line"></span><br><span class="line">        zeta = <span class="number">0.74</span> + <span class="number">0.2</span> / (<span class="number">0.8</span> + rrs[<span class="number">1</span>] / rrs[<span class="number">6</span>])<span class="comment">#step 7&amp;8</span></span><br><span class="line">        S = <span class="number">0.015</span> + <span class="number">0.002</span> / (<span class="number">0.6</span> + rrs[<span class="number">1</span>] / rrs[<span class="number">6</span>])</span><br><span class="line">        xi = np.exp(S * (<span class="number">442.5</span> - <span class="number">415.5</span>))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(nbands):</span><br><span class="line">            bbp[i]= bbpr * np.power(r/Lambda[i], eta)<span class="comment">#step5</span></span><br><span class="line">        a = ((<span class="number">1</span> - u) * (bw + bbp)) / u<span class="comment">#step6</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(nbands):</span><br><span class="line"></span><br><span class="line">            ag443=((a[<span class="number">0</span>]-zeta*a[<span class="number">1</span>])/(xi-zeta))-((aw[<span class="number">0</span>]-zeta*aw[<span class="number">1</span>])/(xi-zeta))</span><br><span class="line">            adg[i]=ag443*np.exp(-S*(Lambda[i]<span class="number">-443</span>))</span><br><span class="line">            aph[i]=a[i]-adg[i]-aw[i]</span><br><span class="line">        <span class="keyword">return</span> bbp,a</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>QAA的代码还需要很多的改进，目前正在参考https://github.com/BrandonSmithJ/band-adjustment进行改进，欢迎同行交流。</p>
<h2 id="程序加速">程序加速</h2>
<p>因为python自己的问题，如果你要处理大量遥感图像的话会很慢，这个一方面是matplotlib自己出图慢，另一方面是因为没有充分利用多核cpu。</p>
<p>批量出图可以参考https://cloud.tencent.com/developer/article/1584962 这篇文章。</p>
<p>解决多核cpu最好用的方法是并行。</p>
<p>像上面那个程序，用并行来加速的话可以这么写：</p>
<ol type="1">
<li>把它改写成一个函数，一般是把文件名作为输入，或者是文件在datalist之中的顺序，我用的是后面这种。</li>
<li>a1=np.arange(len(datalist))，创建一个list，并行的时候传入的变量只能是list</li>
<li>将代码改写成如下样子</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>()</span></span><br><span class="line"><span class="function">#这里是你刚才改写的程序</span></span><br><span class="line">pool=mp.Pool(processes=7)#电脑8核，给自己空余了一个核用来处理其他任务</span><br><span class="line">pool.map(main,a1)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以先不做并行查看内存占用情况，如果有很多内存没用的话，开了并行一般都会提速，我的程序需要处理140张卫星图像，缩短到原来的1/3左右。</p>
<h1 id="seadas-ocssw的安装与应用">SeaDAS OCSSW的安装与应用</h1>
<p>SeaDAS是NASA出品的一个水色遥感处理软件，其中的OCSSW更是内置了很多美国发射的卫星的标准处理流程算法（欧洲的那几个用的SNAP，韩国的GOCI用的GDPS，日本的SGLI，也许哪天我用OLCI数据的时候会把SNAP的教程搞一下），我主要是用他的l2gen这个功能。OCSSW只能在Linux或者Mac OS系统下安装。下载地址https://seadas.gsfc.nasa.gov/，这里讲Linux系统下的安装方法，我用的是Ubuntu 18.04LTS.</p>
<h2 id="安装">安装</h2>
<p>如果你像我一样肉身翻墙的话，那恭喜你真的是非常方便了。</p>
<h3 id="seadas-安装">SeaDAS 安装</h3>
<p>NASA官方的tutorial在https://seadas.gsfc.nasa.gov/tutorials/installation_tutorial/</p>
<p>基本按照这个来就可以了，除了Java版本，我第一次装的时候用的是最新版Java，结果SeaDAS无法作为一个独立程序运行（就是在程序页面里找不到这个程序的图标？启动器？本Ubuntu菜鸡虚心求教），最后按照如下方法安装了Java8:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo add-apt-repository ppa:ts.sch.gr/ppa </span><br><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install oracle-java8-installer</span><br></pre></td></tr></table></figure>
<h3 id="ocssw安装">OCSSW安装</h3>
<h4 id="python环境设置">Python环境设置</h4>
<p>我们一般现在用来干活的python一般都是3版本的，但是Ubuntu系统内置的python是2版本，SeaDAS OCSSW会使用默认的内置版本，所以在这里需要搞定一些程序库的问题（如果没搞好的话后面一般会显示你没有requests这个包）。</p>
<p>这时候就用到我刚才安装的Pycharm来手动管理了，打开pycharm-preference-Project Interpreter,如果你没有装别的东西的话，你的电脑里应该就只有几个python的解释器，你刚才通过anacoonda安装的是3版本，在Add Python Interpreter里面，系统自带的解释器一般会在Pipenv、System或者Virtualenv这里找到，通过路径判断出来哪个是系统自带的，创建一个新环境，然后在Terminal里安装requests这个包就可以了</p>
<h4 id="安装-1">安装</h4>
<p>完成这一步之后，如果你肉身翻墙或者依靠金钱的力量翻墙的话，就可以在GUI里面手动点选安装了；如果在国内，可以按照刚才放的官方的页面，把每个Bundle都下载下来离线安装。</p>
<h2 id="应用">应用</h2>
<p>我这里主要用的是l2gen这个函数，这里放一个在seadas forum找到然后自己修改的脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># source /Users/zhenjia/.bash_profile </span></span><br><span class="line"><span class="comment">#先运行上面这个文件来搞定全局变量</span></span><br><span class="line"><span class="comment">#Example script to process L1A files up to L2, put in same directory as </span></span><br><span class="line"><span class="comment"># your L1A files</span></span><br><span class="line"><span class="comment"># Run script by typing on Terminal Command Line: </span></span><br><span class="line"><span class="comment"># bash l1a_to_l2.sh input.txt</span></span><br><span class="line"><span class="comment"># input.txt contains list of files [ create by: ls -1 *L1A_LAC* &gt; input.txt ]</span></span><br><span class="line"></span><br><span class="line">LIST=<span class="variable">$1</span></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$LIST</span>&quot;</span> ]</span><br><span class="line">  <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No input file list supplied&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ ! -a <span class="variable">$LIST</span> ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$LIST</span> does not exist!&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">mkdir -p <span class="keyword">done</span></span><br><span class="line">mkdir -p l2_lac</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> FILE <span class="keyword">in</span> $(cat <span class="variable">$LIST</span>);</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Working on <span class="variable">$FILE</span>&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;FILE&#125;</span></span><br><span class="line">    <span class="comment"># get file basename (no file extension)</span></span><br><span class="line">    BASE=`basename <span class="variable">$FILE</span> .L1A_LAC.x.hdf`</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;BASE&#125;</span></span><br><span class="line">    GEOFILE=<span class="variable">$&#123;BASE&#125;</span>.GEO</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;GEOFILE&#125;</span></span><br><span class="line">    L1BFILE=<span class="variable">$&#123;BASE&#125;</span>.L1B_LAC.x.hdf</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;L1BFILE&#125;</span></span><br><span class="line">    L2FILE=<span class="variable">$&#123;BASE&#125;</span>.L2_LAC.x.hdf</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$&#123;L2FILE&#125;</span></span><br><span class="line">    ancfile=<span class="variable">$&#123;BASE&#125;</span>.L1A_LAC.x.hdf.anc</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating GEOFILE <span class="variable">$GEOFILE</span>&quot;</span></span><br><span class="line">    modis_GEO.py -v <span class="variable">$FILE</span> -o <span class="variable">$GEOFILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating L1B file&quot;</span></span><br><span class="line">    modis_L1B.py -v <span class="variable">$FILE</span> <span class="variable">$GEOFILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Creating anc file&quot;</span></span><br><span class="line">    getanc.py -v <span class="variable">$FILE</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Create L2 file&quot;</span></span><br><span class="line">    l2gen ifile=<span class="variable">$L1BFILE</span> geofile=<span class="variable">$GEOFILE</span> ofile=<span class="variable">$L2FILE</span> par=<span class="variable">$ancfile</span> l2prod=<span class="string">&quot;Kd_490 Rrs_nnn angstrom aot_869 chlor_a ipar nLw_nnn nflh par pic poc rhos_nnn&quot;</span> aer_opt=-2</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Cleaning up&quot;</span></span><br><span class="line">    rm -v <span class="variable">$&#123;BASE&#125;</span>.L1B* <span class="variable">$GEOFILE</span> <span class="variable">$ancfile</span></span><br><span class="line">    <span class="comment">#mv -v $FILE done/</span></span><br><span class="line">    mv -v <span class="variable">$L2FILE</span> l2_lac/</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ocean Color</tag>
        <tag>Research</tag>
        <tag>Oceanography</tag>
      </tags>
  </entry>
  <entry>
    <title>book reading note 1</title>
    <url>/posts/2adc6f01.html</url>
    <content><![CDATA[<p>Chapter 5.4-5.5 of book 《Dynamics of Marine Ecosystems: Biological-Physical Interactions in the Oceans》 <a id="more"></a></p>
<h1 id="comparasion-with-the-humboldt-current-system">5.4Comparasion with the Humboldt Current System</h1>
<p>A complex set of flow between the coast and 100km offshore(Alheit and Bernal 1993)</p>
<ol type="1">
<li>Furthest: sluggish wide flow towards the equator: Chile-Peru Oceanic Current</li>
<li>Towards the coast: Peruvian Oceanic Counter-Current</li>
<li>Closer: equatorward-flowing Humboldt Current, the prime driving force for coastal upwelling</li>
</ol>
<p>The area of upwelling migrates north and south with the seasons, but overall extends from about 38° S in central Chile, through northern Chile and the whole of Peru to parts of Ecuador just north of the equator.</p>
<p>Early work on the upwelling system off Peru, recent details of Chilean upwelling system have been added.</p>
<ul>
<li>Off central Peru, upwelling is year-round but reaches a maximum in winter.</li>
<li>Off northern Chile, upwelling peaks during spring</li>
<li>Off central Chile, peaks during late spring and summer</li>
</ul>
<p>JOINT II multidisciplinary cruises studied the Peruvian upwelling system at 15°S in 1976-7.</p>
<p>Three important differences between the upwelling site off Peru and that off northwest Africa.</p>
<ol type="1">
<li><p>The shelf off Peru is narrower(20km A 50) and drops off more steeply(200m versus 110m).</p></li>
<li><p>Deep water off Peru has more nutrient(20-25 vs 5-10) .</p></li>
<li><p>Wind stress is less and more constant(0.79+-0.4 vs 1.55+-1)</p>
<p>Net result(实际效果):</p>
<ul>
<li>When Ekman transport is active, offshore transport occurs mainly in the top 20m.</li>
<li>Shoreward transport is in an intermediate layer over the shelf, at the depth of about 30-80m(in Africa is whole)</li>
<li>Off Peru, the water close to the bottom is relatively still, and there is marked accumulation of organic matter to give chemically reducing sediment.</li>
</ul></li>
</ol>
<p>Two further differences:</p>
<ul>
<li>since the wind stress is less, the wind-induced mixing does not penetrate so deeply. During periods of strong upwelling, phytoplankton is still retained within the euphotic zone→t primary production is maintained at a relatively constant level, whether the wind stress is high or low。</li>
<li>poleward counter- current, flowing beneath the equatorward coastal jet, is situated at intermediate depth over the continental shelf off Peru, whereas off northwest Africa it is located on the shelf slope</li>
</ul>
<p>A detailed analysis of the primary production cycle in a segment at 15° S(MacIsaac et al.1985):</p>
<p>Because the upwelling is relatively constant it is possible to trace a distinct plume of cold water moving out from the coast and to recognize a number of zones along the axis of the plume.</p>
<ul>
<li>Zone I: the area of intense upwelling within about 7 km of the coast, where nutrients are abundant but phytoplankton biomass is relatively low.</li>
<li>Zone II: I the water column is stabilized by solar warming and the phytoplankton cells are found to increase their rates of nutrient uptake, photosynthesis, and synthesis of macro- molecules, a process known as “shift-up.”</li>
<li>Zone III: characterized by the rapid depletion of nutrients by the “shifted-up” phytoplankton, so that there is a rapid accumulation of biomass and all processes occur at maximal rates.</li>
<li>Zone IV nutrient depletion occurs, so that the cells experience nutrient limitation.</li>
</ul>
<p>Using drogues to track water masses, MacIsaac et al. (1985) estimated that phytoplankton cells moved from zone I to zone IV in 8–10 days, during which time they traveled 30–60 km away from the coast. The chlorophyll maximum occurred about 18 km offshore.</p>
<h2 id="interannual-variability-in-the-peruvian-upwelling-system">5.4.1 Interannual variability in the Peruvian upwelling system</h2>
<p>Normal State: the source of upwelled water off Peru in April–May 1977 was at a depth of 30–60 m. The water was at a temperature of 15.5–16.5 °C, and contained 20–25 µg nitrate.</p>
<p>Anomalous State: the trade winds weaken or reverse, thermocline off the coast of Peru sinks to a depth of about 100 m; Ekman transport along this coast continues, but the water that is upwelled is now much warmer and not rich in nutrients.</p>
<p>As a result, there is a sharp reduction in the biomass and productivity of the phytoplankton.</p>
<p>Reason: El Niño – Southern Oscillation (ENSO). t the Peruvian upwelling system seems to be uniquely vulnerable to such drastic changes, so that its interannual variability in productivity is very great.</p>
<p>1982-3: serious in the periodicity of 100 years or more (Rasmusson and Wallace 1983)</p>
<p>the height of the 1982–3 anomaly, in May 1983, the upwelling waters were at 29 °C instead of the usual 16–18 °C, and mean primary productivity was only 10mgCm−3 d−1(Barber et al.1985) Two months later conditions had returned to normal and mean primary productivity was 219 mg C m−3 d−l</p>
<h2 id="total-primary-production-in-the-peruvian-upwelling-system">5.4.2 Total primary production in the Peruvian upwelling system</h2>
<p>Many attempts have been made to calculate the total primary productivity of the Peruvian upwelling system.</p>
<ol type="1">
<li>Lack of agreement about upwelling area leads out many different result. Cushing (1969) used 479,000 km2 in his calculation while Ryther (1969) used 60,000 km2</li>
<li>Chavez and Barber (1987) argued that the offshore dimension of coastal upwelling is limited by the Rossby deformation scale (Section 5.2.3). From Eqn. 5.11 we see that the formula for this scale is (g′ H0 )1/2/f.Thus the radius is a function of the Coriolis force f (which varies with latitude), the depth H0, and the vertical density gradient.</li>
<li>Chavez and Barber (1987) calculated that the width of the Peruvian upwelling system varied from 270 km at 4° S to 60 km at 18° S. Calculating the width at degree intervals they arrived at an area of 182,000 km2, intermediate between the two values quoted above.</li>
<li>The mean of the large number of determinations of primary production in 1983–4, after the recovery from the El Niño event, was 2.28 g C m−2 d−1 or 834 g C m−2 y−1 . This value converted into a total production of 1.52 × 1014 gCy−1 .</li>
<li>With increased availability of satellite pictures of chloro- phyll distribution, it should be possible to refine the estimate of the average area affected by upwelling, and to determine its variability. For example, Carr (2002) defined the area of an upwelling system as the area over which surface chlorophyll concentrations, as estimated by remote sensing, exceeded 1 mg m−3 on average (see Section 5.9).</li>
</ol>
<h2 id="secondary-production-in-the-humboldt-current-system">5.4.3 Secondary production in the Humboldt Current system</h2>
<p>Cushing(1971) the type of fish in HCS is the same in CCS.</p>
<p>The sardines and anchovies usually spawn in the areas of most intense upwelling, close to shore, and Cushing speculated that both the juveniles and the adults make use of the two counter-currents (onshore and poleward) to maintain themselves within the upwelling system.</p>
<p>lack of agreement about whether the anchovies and sardines predominantly consume phytoplankton. It seems that larvae consume mainly microzooplankton, while adults feed mainly on larger phytoplankton.</p>
<p>Barber et al. (1985) showed (Fig. 5.12) that the years of temperature anomalies (El Niño years) were associated with reduced landings of anchoveta Engraulis ringens.</p>
<p>Possible explanations:</p>
<ol type="1">
<li>the adults could have starved for lack of phytoplankton food,</li>
<li>the fish could have migrated away from the areas where they are usually caught</li>
<li>or the larvae could have failed to survive through lack of both phytoplankton and zooplankton.</li>
</ol>
<p>Some Evidence for each hypothesis.</p>
<p>h1: . There were reports of anchoveta having moved to cooler, deeper water at about 100 m, but such water has very little phytoplankton and it seems likely that the fish would not survive there long. Barber et al. (1985)</p>
<p>h2: anchoveta seek out the upwelling areas by exhibiting a preference for water of 16–18 °C. Barber et al. (1985).migration south to find cooler waters may well have been one of the strategies for survival (Valdivia 1978).</p>
<p>h3:</p>
<ul>
<li>The anchovies spread their spawning over 7–8 months of the year, presumably as an adaptation to the occurrence of unfavorable conditions at particular times and places.</li>
<li>However, there are two peak periods: the austral winter–spring spawning (July–September) and the summer spawning (February–March) (Valdivia 1978).</li>
<li>Walsh et al. (1980), investigating the survival of larvae off the northern coast of Peru during winter, found that survival was higher when dinoflagellates in relatively high concentrations were available to the first-feeding larvae. Strong wind events had the effect of dispersing the dinoflagellate concentrations and adversely affected survival. We shall return to this topic in <strong>Section 5.5</strong> on the California Current.(把这个加上)</li>
<li>At the onset of the 1976 El Niño there was a bloom of the dinoflagellate Gymnodinium splendens along 1000 km of the coast from March until the end of May. It was attributable to the stabilization of the water column as the warm water invaded the area. While it provided an excellent feeding environment for the early larvae, it apparently was not a suitable food for the adult fish, which had smaller fat content, a reduced weight at a given length, and reduced length at sexual maturity. The 1977 recruitment of fish spawned in 1976 was extremely poor and the stock along the Peruvian coast fell to the lowest levels ever observed (Barber et al. 1985)</li>
</ul>
<h2 id="exploitation-of-the-humboldt-current-fish-stock">5.4.4 Exploitation of the Humboldt Current fish stock</h2>
<p>History of the anchoveta fishery in Peru was reviewed by Glantz (1985)</p>
<ol type="1">
<li>Mining of bird-drooping</li>
</ol>
<ul>
<li>beginning in the 1840s, the major industrial activity along the Peruvian coast had been the mining of the bird- droppings, guano, from the rocky islands.</li>
<li>Large populations of fish-eating birds are characteristic of upwelling populations worldwide, and prominent white accumulations of droppings at their roosting sites are an inevitable concomitant. As Cushing (1971) remarked, it is no accident that upwelling areas commonly have a Cabo Blanco, Cap Blanc, or Cape Blanc.</li>
<li>The guano of Peru was mined and exported for fertilizer to many parts of the world.</li>
</ul>
<ol start="2" type="1">
<li>Anchoveta fishing</li>
</ol>
<ul>
<li>Beginning in the 1950s, a lucrative industry to harvest the anchoveta and convert them to fishmeal was developed in Peru.</li>
<li>The landings increased rapidly to a peak of about 12 million tons in 1970, then dropped to 2–3 million tons for a few years.</li>
<li>After 1977 the catch hovered around 1 million tons but in 1985 there began a recovery which has persisted into the twenty-first century (Fig. 5.13)</li>
<li>Alheit and Bernal (1993) sug- gested that there may have been massive migrations from the southern part of the Humboldt system.</li>
</ul>
<p>Whether these fluctuations have been part of a natural cycle of events that has occurred many times in the past, or whether they are primarily the result of gross overfishing?</p>
<p>regime shift→</p>
<p>The authors pointed out that anchovy can recover from an ENSO event in 1–2 years (Fig. 5.13). They made a partial recovery after the 1972–3 El Niño, and a full recovery after the 1997–8 event, but the decadal-scale period of warm anomalies, which began in 1968, held the anchovy populations at low levels from 1977 to 1985. Alheit and Niquen (2004) therefore concluded that the well-known crash of the anchovy fishery in the 1970s was caused primarily by the decadal- scale regime shift rather than by the 1972–3 ENSO events</p>
<p>Overfishing</p>
<p>Climate Change(ENSO, regime shift)</p>
<h1 id="the-california-current-system">5.5 The California Current System</h1>
<p>Driven by prevailing northerly winds, and upwelling occurs along the Pacific coast of the United States from the Canadian border south to Baja California and beyond.</p>
<p>The situation of upwelling system off Oregon in several respects resembles that off Peru(这个是谁做的，Huyer1976做的是非洲).The poleward undercurrent appears over the shelf as well as the slope, and the shoreward flow is strongest at mid-depths over the shelf. Upwelling events are less strong and of shorter duration off Oregon than they are off northwest Africa.</p>
<p>Bakun(1973) gave the Bakun upwelling index, a 20-year aver- age of monthly mean Ekman transport for different parts of the coast. The range is from 300 m3 s−1(offshore direction) to −212 m−3 s−1 (onshore).It can be seen that the index indicates year-round upwelling off southern California, with stronger upwelling in summer, but off Oregon and Washington in the north there is strong downwelling in winter, and upwelling is confined to the period April–September.</p>
<p>in summer there is a negative temperature anomaly, indicative of upwelling of cold water, all the way along the coast from Oregon in the north to Baja California in the south, with the exception of a warm anomaly off San Diego. The upwelling is obviously most intense between Cape Mendocino and Monterey. Although the temperature anomaly in Fig. 5.16 shows an apparently uniform area of cold water, this area is an artifact of the method of calculation(why?).</p>
<p>The situation at any one time, as seen by satellite, is extremely com- plex, with coastal upwelling systems tending to be centered on topographical features such as capes and canyons, and with plumes of upwelled water extending far out into the California Current. As in other coastal upwelling systems, the strength of upwelling is strongly dependent on wind speed and direction, and changes from day to day.</p>
<p>Fig. 5.17 shows the distribution of temperature and nitrate off Point Sur, California, on June 9, 1980, as inferred from satellite imagery supplemented by shipboard observations (Traganza et al. 1983). This situation is typical of an early phase of an upwelling event at this site. If the event persists for many days, interaction with the California Current may give rise to a cyclonic structure about 100 km in diameter, with high biological production along the associated fronts, or it may extend into a plume up to 250 km long (Traganza et al.1981, 1987). In summer time, patterns of this kind may be found in various stages of development or decline all the way from Oregon to Baja California. As winter approaches, the upwelling is progressively restricted to the southern portion of the region and in spring the region of upwelling spreads north again.</p>
<p>heterogeneous nature of the California Current, with its admixture of advected and upwelled water.</p>
<p>It is now possible to simulate both physical and biological events in the coastal transition zone, that zone characterized by the presence of highly productive jets, squirts, or filaments of highly productive upwelled water. Moisan and Hofmann (1996) modeled the fate of Lagrangian drifters placed in newly upwelled water and allowed to travel with a filament. Coupled physical and biological models were used, the biological parameters being determined from shipborne observations. The models reproduced well the formation of a subsurface chlorophyll maximum and the changing structure of the food web as the drifters moved offshore. 物理海洋学的东西我就不懂了</p>
<p>Digiacomo (2000) and Digiacomo and Holt (2001) used the latest satellite technology to study the mesoscale and sub-mesoscale eddies in the Southern California Bight. All the eddies were less than 50 km in diameter, and 70% were less than 10 km. They were observed to lie between the equatorward-flowing California Current and the shore, and appeared to be caused by topography (especially islands), wind, and current instabilities. There was also evidence of lateral entrainment of highly productive coastal waters. Associated with the eddies were patches of high chlorophyll density, up to 15 km wide and 60 km long. The authors discussed the potential for influencing nutrient flux, plankton productivity, larval transport and recruitment, and dispersal of pollutants. This smaller-scale pattern was observed to interact with the large-scale variations in time and space of the California Current.</p>
<h2 id="fish-production-in-the-california-current-system">5.5.1 Fish production in the California Current system</h2>
<p>most abundant fishes in the California Current system are sardines, anchovies, hake, jack mackerel, and mackerel.</p>
<ul>
<li>Sardines Sardinops sagax were heavily exploited from 1916 to 1967.. The peak landings were in 1936–7 and exceeded 700,000 tons. The catch fell drastically in the 1950s and 1960s and in 1967 the California state legislature imposed a moratorium on the sardine fishery.</li>
<li>The sardines of the California current system are divisible into four stocks. Of these, the largest by far before overfishing was the one that spawned in the Southern California Bight and migrated to the upwelling areas off northern California to exploit the dense zooplankton stocks that are associated with the coastal upwelling.</li>
<li>biomass of sardines declined, and some postulated that the two were in competition so that the decline of sardine stocks released resources for the anchovies. However, Soutar and Isaacs (1969) studied the 1850-year record of fish scales in the anaerobic sediments off California and concluded that northern anchovy scales were present in large numbers throughout the series, while sardine scales appeared intermittently for periods of 20–150 years, with absences that averaged 80 years in duration. They concluded that the two species were not in competition.</li>
<li>The anchovies also have several subpopulations. The stock off Oregon spawns at about 44–46° N, mainly in July at the time of the northern upwelling. The central subpopulation spawns principally in the Southern California Bight. Eggs and larvae can be found throughout the year, but the peak abundance is in the spring, while the minimum is in the autumn. The fish remain in the Southern California Bight throughout their lives and in recent years this has been the largest stock. There is a southern stock off Baja California, for which peak larval abundance is from January to March.</li>
</ul>
<p>It thus appears that the largest stocks of both sardine and anchovy spawn in the Southern California Bight. Upwelling is relatively weak and phytoplankton production is lower than in the California Current proper. Bakun and Parrish (1982) have suggested that strong offshore flow associated with Ekman transport is likely to carry eggs and larvae too far offshore, to positions from which they may never return, and that the choice of the Southern California Bight for spawning area reflects a need to avoid areas of strong upwelling. They also suggested that areas of strong Ekman transport are areas where there are strong winds that may destroy the fine-scale strata of food organisms needed by first-feeding larvae. This idea, attributable to Lasker (1975), will be examined in more detail in Section 5.5.2.</p>
<ul>
<li>Schwartzlose et al. (1999) showed that the exploitation of sardines in the California Current reached its peak with landings of 700,000 tons in 1936, but was down to extremely low levels by 1952.</li>
<li>From 1916 to 1952 the catches of anchovy were negligible (Fig. 5.18).</li>
<li>From 1952 to 1966 there were small catches of both sardines and anchovies, and in 1967 the sardine fishery was closed.</li>
<li>After 1967 there was an expansion of anchovy populations, resulting in a catch of 310,000 tons in 1981, but in 1990 there was a switch to dominance of sardines once again, with a catch of 110,000 tons in 1997.</li>
<li>The various hypotheses to explain the alternation of species have been discussed, but in the light of the findings of Alheit and Niquen (2004) for the Humboldt Current system, we may expect to find some influence of decadal-scale climate changes.</li>
</ul>
<p>The various hypotheses to explain the alternation of species have been discussed, but in the light of the findings of Alheit and Niquen (2004) for the Humboldt Current system, we may expect to find some influence of decadal-scale climate changes. These will be discussed in Chapter 9</p>
<h2 id="the-survival-of-first-feeding-larvae">5.5.2 The survival of first-feeding larvae</h2>
<p>Anchovy egg are most abundant in the shorthorn California Bight during February, March, and April. 3 day old first-feeding larvae need a very high density of food organisms about 1790 dinoflagellates per liter.</p>
<p>the larvae were stimulated to feed only when the phytoplankton was at a population density of at least 20–30 cells mL−1</p>
<p>The first-feeding larvae rely on high concentrations of phytoplankton such as naked dinoflagellates of a size class close to 40 µm.</p>
<p>To summarize our understanding of factors influencing anchovy and sardine production in the California Current, we see that strong wind stress and associated upwelling, which are the most characteristic features of eastern boundary currents, appear in themselves to be detrimental to the success of the larvae. For good survival the larvae require a well-developed horizontal layer of high phytoplankton density, in which dinoflagellates are the dominant form.</p>
<p>A second factor to be considered in relation to larval survival is the risk that strong offshore transport will carry the larvae away from the favorable coastal environment.</p>
<p>In our present stage of understanding, there is no way to integrate these two mortality factors, beyond pointing out that both sardine and anchovy appear to avoid the regions of strongest upwelling in their choice of spawning location.</p>
<p>The role of environmental controls in determining sardine and anchovy population cycles in the California Current: Analysis of an end-to-end model 这文章可以看看</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Oceanography</tag>
        <tag>Book Reading</tag>
        <tag>Seminar</tag>
      </tags>
  </entry>
  <entry>
    <title>python绘图基础</title>
    <url>/posts/720e5580.html</url>
    <content><![CDATA[<p>这两天在收拾画图的事情，发现我matplotlib这些东西学的真的差，这个笔记用来整理一下自己会用到的东西，除了cartopy之外的。</p>
<a id="more"></a>
<h1 id="matplotlib">matplotlib</h1>
<h2 id="基础知识">基础知识</h2>
<p>Matplotlib最重要一个基础概念就是figure和axes。</p>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/v2-6e4429872eeb8a155433c0ee7c75b6ea_720w.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>在Matplotlib中，figure的意思是画板，axes的意思是画布，而axis的意思是坐标轴。比如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">20</span>)  <span class="comment"># 生成数据</span></span><br><span class="line">y = x * x + <span class="number">2</span></span><br><span class="line"></span><br><span class="line">fig = plt.figure()  <span class="comment"># 新建图形对象</span></span><br><span class="line">axes = fig.add_axes([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.8</span>, <span class="number">0.8</span>])  <span class="comment"># 控制画布的左，下，宽度，高度</span></span><br><span class="line">axes.plot(x, y, <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>在同一个画板上，我们可以画好几个画布</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure()  <span class="comment"># 新建画板</span></span><br><span class="line">axes1 = fig.add_axes([<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.8</span>])  <span class="comment"># 大画布</span></span><br><span class="line">axes2 = fig.add_axes([<span class="number">0.2</span>, <span class="number">0.5</span>, <span class="number">0.4</span>, <span class="number">0.3</span>])  <span class="comment"># 小画布</span></span><br><span class="line"></span><br><span class="line">axes1.plot(x, y, <span class="string">&#x27;r&#x27;</span>)  <span class="comment"># 大画布</span></span><br><span class="line">axes2.plot(y, x, <span class="string">&#x27;g&#x27;</span>)  <span class="comment"># 小画布</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/output_80_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除此之外， 还有一种方法增加画布，就是plt.subplots()</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>)  <span class="comment"># 子图为 1 行，2 列</span></span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> axes:</span><br><span class="line">    ax.plot(x, y, <span class="string">&#x27;r&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/output_86_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>即便是只画一个画布，也建议通过fig,axses=plt.subplots()来生成画布和画板，方便调节，而不是使用plt.plot()</p>
<h2 id="基础样式调整">基础样式调整</h2>
<h3 id="添加图标题图例">添加图标题、图例</h3>
<p>绘制包含图标题、坐标轴标题以及图例的图形，举例如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">axes.set_xlabel(<span class="string">&#x27;x label&#x27;</span>)  <span class="comment"># 横轴名称</span></span><br><span class="line">axes.set_ylabel(<span class="string">&#x27;y label&#x27;</span>)</span><br><span class="line">axes.set_title(<span class="string">&#x27;title&#x27;</span>)  <span class="comment"># 图形名称</span></span><br><span class="line"></span><br><span class="line">axes.plot(x, x**<span class="number">2</span>)</span><br><span class="line">axes.plot(x, x**<span class="number">3</span>)</span><br><span class="line">axes.legend([<span class="string">&quot;y = x**2&quot;</span>, <span class="string">&quot;y = x**3&quot;</span>], loc=<span class="number">0</span>)  <span class="comment"># 图例</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_98_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>图例中的 <code>loc</code> 参数标记图例位置，<code>1，2，3，4</code> 依次代表：右上角、左上角、左下角，右下角；<code>0</code> 代表自适应</p>
<h3 id="线型颜色透明度">线型、颜色、透明度</h3>
<p>在 Matplotlib 中，你可以设置线的颜色、透明度等其他属性。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">axes.plot(x, x+<span class="number">1</span>, color=<span class="string">&quot;red&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes.plot(x, x+<span class="number">2</span>, color=<span class="string">&quot;#1155dd&quot;</span>)</span><br><span class="line">axes.plot(x, x+<span class="number">3</span>, color=<span class="string">&quot;#15cc55&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_103_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>而对于线型而言，除了实线、虚线之外，还有很多丰富的线型可供选择。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线宽</span></span><br><span class="line">ax.plot(x, x+<span class="number">1</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">0.25</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">2</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">0.50</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">3</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">1.00</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">4</span>, color=<span class="string">&quot;blue&quot;</span>, linewidth=<span class="number">2.00</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 虚线类型</span></span><br><span class="line">ax.plot(x, x+<span class="number">5</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, linestyle=<span class="string">&#x27;-&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">6</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;-.&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">7</span>, color=<span class="string">&quot;red&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 虚线交错宽度</span></span><br><span class="line">line, = ax.plot(x, x+<span class="number">8</span>, color=<span class="string">&quot;black&quot;</span>, lw=<span class="number">1.50</span>)</span><br><span class="line">line.set_dashes([<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 符号</span></span><br><span class="line">ax.plot(x, x + <span class="number">9</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">10</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">11</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">12</span>, color=<span class="string">&quot;green&quot;</span>, lw=<span class="number">2</span>, ls=<span class="string">&#x27;--&#x27;</span>, marker=<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 符号大小和颜色</span></span><br><span class="line">ax.plot(x, x+<span class="number">13</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">2</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">14</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">4</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">15</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>,</span><br><span class="line">        marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">8</span>, markerfacecolor=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">ax.plot(x, x+<span class="number">16</span>, color=<span class="string">&quot;purple&quot;</span>, lw=<span class="number">1</span>, ls=<span class="string">&#x27;-&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, markersize=<span class="number">8</span>,</span><br><span class="line">        markerfacecolor=<span class="string">&quot;yellow&quot;</span>, markeredgewidth=<span class="number">2</span>, markeredgecolor=<span class="string">&quot;blue&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_106_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="画布网格坐标轴范围">画布网格、坐标轴范围</h3>
<p>有些时候，我们可能需要显示画布网格或调整坐标轴范围。设置画布网格和坐标轴范围。这里，我们通过指定 <code>axes[0]</code> 序号，来实现子图的自定义顺序排列。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示网格</span></span><br><span class="line">axes[<span class="number">0</span>].plot(x, x**<span class="number">2</span>, x, x**<span class="number">3</span>, lw=<span class="number">2</span>)</span><br><span class="line">axes[<span class="number">0</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置坐标轴范围</span></span><br><span class="line">axes[<span class="number">1</span>].plot(x, x**<span class="number">2</span>, x, x**<span class="number">3</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_ylim([<span class="number">0</span>, <span class="number">60</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_xlim([<span class="number">2</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_110_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除了折线图，Matplotlib 还支持绘制散点图、柱状图等其他常见图形。下面，我们绘制由散点图、梯步图、条形图、面积图构成的子图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">4</span>, figsize=(<span class="number">16</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">axes[<span class="number">0</span>].scatter(x, x + <span class="number">0.25</span>*np.random.randn(len(x)))</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;scatter&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">1</span>].step(n, n**<span class="number">2</span>, lw=<span class="number">2</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;step&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">2</span>].bar(n, n**<span class="number">2</span>, align=<span class="string">&quot;center&quot;</span>, width=<span class="number">0.5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes[<span class="number">2</span>].set_title(<span class="string">&quot;bar&quot;</span>)</span><br><span class="line"></span><br><span class="line">axes[<span class="number">3</span>].fill_between(x, x**<span class="number">2</span>, x**<span class="number">3</span>, color=<span class="string">&quot;green&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes[<span class="number">3</span>].set_title(<span class="string">&quot;fill_between&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_113_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="图形标注方法">图形标注方法</h3>
<p>当我们绘制一些较为复杂的图像时，阅读对象往往很难全面理解图像的含义。而此时，图像标注往往会起到画龙点睛的效果。图像标注，就是在画面上添加文字注释、指示箭头、图框等各类标注元素。</p>
<p>Matplotlib 中，文字标注的方法由 <code>matplotlib.pyplot.text()</code> 实现。最基本的样式为 <code>matplotlib.pyplot.text(x, y, s)</code>，其中 x, y 用于标注位置定位，s 代表标注的字符串。除此之外，你还可以通过 <code>fontsize=</code> , <code>horizontalalignment=</code> 等参数调整标注字体的大小，对齐样式等。</p>
<p>下面，我们举一个对柱形图进行文字标注的示例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">x_bar = [<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>, <span class="number">50</span>]  <span class="comment"># 柱形图横坐标</span></span><br><span class="line">y_bar = [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.8</span>]  <span class="comment"># 柱形图纵坐标</span></span><br><span class="line">bars = axes.bar(x_bar, y_bar, color=<span class="string">&#x27;blue&#x27;</span>, label=x_bar, width=<span class="number">2</span>)  <span class="comment"># 绘制柱形图</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> enumerate(bars):</span><br><span class="line">    x_text = rect.get_x()  <span class="comment"># 获取柱形图横坐标</span></span><br><span class="line">    y_text = rect.get_height() + <span class="number">0.01</span>  <span class="comment"># 获取柱子的高度并增加 0.01</span></span><br><span class="line">    plt.text(x_text, y_text, <span class="string">&#x27;%.1f&#x27;</span> % y_bar[i])  <span class="comment"># 标注文字</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_119_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>除了文字标注之外，还可以通过 <code>matplotlib.pyplot.annotate()</code> 方法向图像中添加箭头等样式标注。接下来，我们向上面的例子中增添一行增加箭头标记的代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, axes = plt.subplots()</span><br><span class="line"></span><br><span class="line">bars = axes.bar(x_bar, y_bar, color=<span class="string">&#x27;blue&#x27;</span>, label=x_bar, width=<span class="number">2</span>)  <span class="comment"># 绘制柱形图</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> enumerate(bars):</span><br><span class="line">    x_text = rect.get_x()  <span class="comment"># 获取柱形图横坐标</span></span><br><span class="line">    y_text = rect.get_height() + <span class="number">0.01</span>  <span class="comment"># 获取柱子的高度并增加 0.01</span></span><br><span class="line">    plt.text(x_text, y_text, <span class="string">&#x27;%.1f&#x27;</span> % y_bar[i])  <span class="comment"># 标注文字</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 增加箭头标注</span></span><br><span class="line">    plt.annotate(<span class="string">&#x27;Min&#x27;</span>, xy=(<span class="number">32</span>, <span class="number">0.3</span>), xytext=(<span class="number">36</span>, <span class="number">0.3</span>),</span><br><span class="line">                 arrowprops=dict(facecolor=<span class="string">&#x27;black&#x27;</span>, width=<span class="number">1</span>, headwidth=<span class="number">7</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_122_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>上面的示例中，<code>xy=()</code> 表示标注终点坐标，<code>xytext=()</code> 表示标注起点坐标。在箭头绘制的过程中，<code>arrowprops=()</code> 用于设置箭头样式，<code>facecolor=</code> 设置颜色，<code>width=</code> 设置箭尾宽度，<code>headwidth=</code> 设置箭头宽度，可以通过 <code>arrowstyle=</code> 改变箭头的样式。</p>
<h2 id="cheatsheet">cheatsheet</h2>
<p>matplotlib官方提供了cheatsheets，建议打印下来贴在显眼的地方</p>
<p>https://github.com/matplotlib/cheatsheets</p>
<h2 id="三维图形绘制">三维图形绘制</h2>
<h3 id="基础三维图形">基础三维图形</h3>
<p>前面，我们已经了解了如果使用 Matplotlib 中的 pyplot 模块绘制简单的 2D 图像。其实，Matplotlib 也可以绘制 3D 图像，与二维图像不同的是，绘制三维图像主要通过 <code>mplot3d</code> 模块实现。但是，使用 Matplotlib 绘制三维图像实际上是在二维画布上展示，所以一般绘制三维图像时，同样需要载入 <code>pyplot</code> 模块。</p>
<p><code>mplot3d</code> 模块下主要包含 4 个大类，分别是：</p>
<ul>
<li><code>mpl_toolkits.mplot3d.axes3d()</code></li>
<li><code>mpl_toolkits.mplot3d.axis3d()</code></li>
<li><code>mpl_toolkits.mplot3d.art3d()</code></li>
<li><code>mpl_toolkits.mplot3d.proj3d()</code></li>
</ul>
<p>其中，<code>axes3d()</code> 下面主要包含了各种实现绘图的类和方法。<code>axis3d()</code> 主要是包含了和坐标轴相关的类和方法。<code>art3d()</code> 包含了一些可将 2D 图像转换并用于 3D 绘制的类和方法。<code>proj3d()</code> 中包含一些零碎的类和方法，例如计算三维向量长度等。</p>
<p>一般情况下，我们用到最多的就是 <code>mpl_toolkits.mplot3d.axes3d()</code> 下面的 <code>mpl_toolkits.mplot3d.axes3d.Axes3D()</code> 类，而 <code>Axes3D()</code> 下面又存在绘制不同类型 3D 图的方法。</p>
<p>下面，我们通过几组示例，来学习 Matplotlib 绘制三维图形。首先，是三维散点图的绘制。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># x, y, z 均为 0 到 1 之间的 100 个随机数</span></span><br><span class="line">x = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">y = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line">z = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.scatter(x, y, z)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_14_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>三维图形和二维图形在数据上的区别在于，三维图形多了一组数据用于度量多出来的一个维度。</p>
<p>当我们在桌面环境中绘制 3D 图形时，是可以通过鼠标任意拖动角度的，但在 Jupyter Notebook 环境中不支持，只会展示三维图形的默认视角静态图像。</p>
<p>线形图和散点图相似，需要传入 x,y,z<em>x</em>,<em>y</em>,<em>z</em> 三个坐标的数值。详细的代码如下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">x = np.linspace(<span class="number">-6</span> * np.pi, <span class="number">6</span> * np.pi, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">z = np.cos(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line">ax.plot(x, y, z)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_19_1_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制完线型图，我们继续尝试绘制三维柱状图，其实它的绘制步骤和上面同样非常相似。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据并绘图</span></span><br><span class="line">x = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> x:</span><br><span class="line">    y = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]</span><br><span class="line">    z = abs(np.random.normal(<span class="number">1</span>, <span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    ax.bar(y, z, i, zdir=<span class="string">&#x27;y&#x27;</span>, color=[<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;y&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_22_0.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>接下来需要绘制的三维曲面图要麻烦一些，我们需要对数据进行矩阵处理。其实和画二维等高线图很相似，只是多增加了一个维度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 3D 图形对象</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成数据</span></span><br><span class="line">X = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">Y = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = np.sqrt(X ** <span class="number">2</span> + Y ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制曲面图，并使用 cmap 着色</span></span><br><span class="line">ax.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_25_1_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>cmap=plt.cm.winter</code> 表示采用了 <code>winter</code> 配色方案。除了通过 <code>Axes3D()</code> 声明三维图形，我们也可以通过 <code>projection='3d'</code> 参数声明 3D 图形。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 projection=&#x27;3d&#x27; 声明绘制 3D 图形</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_28_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="三维混合图">三维混合图</h3>
<p>混合图就是将两种不同类型的图绘制在一张图里。绘制混合图一般有前提条件，那就是两种不同类型图的范围大致相同，否则将会出现严重的比例不协调，而使得混合图失去意义。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 创建 3D 图形对象</span><br><span class="line">fig &#x3D; plt.figure()</span><br><span class="line">ax &#x3D; Axes3D(fig)</span><br><span class="line"></span><br><span class="line"># 生成数据并绘制图 1</span><br><span class="line">x1 &#x3D; np.linspace(-3 * np.pi, 3 * np.pi, 500)</span><br><span class="line">y1 &#x3D; np.sin(x1)</span><br><span class="line">ax.plot(x1, y1, zs&#x3D;0, c&#x3D;&#39;red&#39;)</span><br><span class="line"></span><br><span class="line"># 生成数据并绘制图 2</span><br><span class="line">x2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">y2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">z2 &#x3D; np.random.normal(0, 1, 100)</span><br><span class="line">ax.scatter(x2, y2, z2)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_32_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h3 id="三维子图">三维子图</h3>
<p>我们已经学习过二维子图的绘制，其实三维情况下也是一样的。我们可以将二维图像和三维图像绘制在一起，又或者将几个三维图像绘制在一起。这里我们就拿上面绘制过的线形图和曲面图为例，看一看需要增删哪些代码。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建 1 张画布</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向画布添加子图 1</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"><span class="comment"># 生成子图 1 数据</span></span><br><span class="line">x = np.linspace(<span class="number">-6</span> * np.pi, <span class="number">6</span> * np.pi, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line">z = np.cos(x)</span><br><span class="line"><span class="comment"># 绘制第 1 张图</span></span><br><span class="line">ax1.plot(x, y, z)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向画布添加子图 2</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"><span class="comment"># 生成子图 2 数据</span></span><br><span class="line">X = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">Y = np.arange(<span class="number">-2</span>, <span class="number">2</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">Z = np.sqrt(X ** <span class="number">2</span> + Y ** <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 绘制第 2 张图</span></span><br><span class="line">ax2.plot_surface(X, Y, Z, cmap=plt.cm.winter)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/matplotlib-basic/output_36_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>三维图形的绘制，实际上是二维图形的衍生。在绘制方法上并无较大差别，你需要组织合适的数据，并声明三维绘图对象即可。</p>
<p>以上出自https://huhuhang.com/post/machine-learning/matplotlib-basic</p>
<h1 id="seaborn">seaborn</h1>
<p>Seaborn 基于 Matplotlib 核心库进行了更高阶的 API 封装，可以让你轻松地画出更漂亮的图形。Seaborn 的漂亮主要体现在配色更加舒服、以及图形元素的样式更加细腻，下面是 Seaborn 官方给出的参考图。</p>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/document-uid214893labid3264timestamp1501118752821.jpg" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="快速优化图形">快速优化图形</h2>
<p>当我们使用 Matplotlib 绘图时，默认的图像样式算不上美观。此时，就可以使用 Seaborn 完成快速优化。下面，我们先使用 Matplotlib 绘制一张简单的图像。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">x = [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">15</span>, <span class="number">17</span>, <span class="number">19</span>]</span><br><span class="line">y_bar = [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">11</span>, <span class="number">7</span>, <span class="number">8</span>]</span><br><span class="line">y_line = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"></span><br><span class="line">plt.bar(x, y_bar)</span><br><span class="line">plt.plot(x, y_line, <span class="string">&#x27;-o&#x27;</span>, color=<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_11_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>使用 Seaborn 完成图像快速优化的方法非常简单。只需要将 Seaborn 提供的样式声明代码 <code>sns.set()</code> 放置在绘图前即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">sns.set()  <span class="comment"># 声明使用 Seaborn 样式</span></span><br><span class="line"></span><br><span class="line">plt.bar(x, y_bar)</span><br><span class="line">plt.plot(x, y_line, <span class="string">&#x27;-o&#x27;</span>, color=<span class="string">&#x27;y&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_15_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>我们可以发现，相比于 Matplotlib 默认的纯白色背景，Seaborn 默认的浅灰色网格背景看起来的确要细腻舒适一些。而柱状图的色调、坐标轴的字体大小也都有一些变化。</p>
<p><code>sns.set()</code> 的默认参数为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.set(context=<span class="string">&#x27;notebook&#x27;</span>, style=<span class="string">&#x27;darkgrid&#x27;</span>, palette=<span class="string">&#x27;deep&#x27;</span>, font=<span class="string">&#x27;sans-serif&#x27;</span>, font_scale=<span class="number">1</span>, color_codes=<span class="literal">False</span>, rc=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li><code>context=''</code> 参数控制着默认的画幅大小，分别有 <code>&#123;paper, notebook, talk, poster&#125;</code> 四个值。其中，<code>poster &gt; talk &gt; notebook &gt; paper</code>。</li>
<li><code>style=''</code> 参数控制默认样式，分别有 <code>&#123;darkgrid, whitegrid, dark, white, ticks&#125;</code>，你可以自行更改查看它们之间的不同。</li>
<li><code>palette=''</code> 参数为预设的调色板。分别有 <code>&#123;deep, muted, bright, pastel, dark, colorblind&#125;</code> 等，你可以自行更改查看它们之间的不同。</li>
<li>剩下的 <code>font=''</code> 用于设置字体，<code>font_scale=</code> 设置字体大小，<code>color_codes=</code> 不使用调色板而采用先前的 <code>'r'</code> 等色彩缩写。</li>
</ul>
<h2 id="seaborn-绘图-api">Seaborn 绘图 API</h2>
<p>Seaborn 一共拥有 50 多个 API 类，相比于 Matplotlib 数千个的规模，可以算作是短小精悍了。其中，根据图形的适应场景，Seaborn 的绘图方法大致分类 6 类，分别是：关联图、类别图、分布图、回归图、矩阵图和组合图。而这 6 大类下面又包含不同数量的绘图函数。</p>
<p>接下来，我们就通过实际数据进行演示，使用 Seaborn 绘制不同适应场景的图形。</p>
<h2 id="关联图">关联图</h2>
<p>当我们需要对数据进行关联性分析时，可能会用到 Seaborn 提供的以下几个 API。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">关联性分析</th>
<th style="text-align: center;">介绍</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">relplot</td>
<td style="text-align: center;">绘制关系图</td>
</tr>
<tr class="even">
<td style="text-align: center;">scatterplot</td>
<td style="text-align: center;">多维度分析散点图</td>
</tr>
<tr class="odd">
<td style="text-align: center;">lineplot</td>
<td style="text-align: center;">多维度分析线形图</td>
</tr>
</tbody>
</table>
<p><a href="https://seaborn.pydata.org/generated/seaborn.relplot.html"><code>relplot</code></a> 是 relational plots 的缩写，其可以用于呈现数据之后的关系，主要有散点图和条形图 2 种样式。我们载入鸢尾花示例数据集。</p>
<p>在绘图之前，先熟悉一下 iris 鸢尾花数据集。数据集总共 150 行，由 5 列组成。分别代表：萼片长度、萼片宽度、花瓣长度、花瓣宽度、花的类别。其中，前四列均为数值型数据，最后一列花的分类为三种，分别是：Iris Setosa、Iris Versicolour、Iris Virginica。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris = sns.load_dataset(<span class="string">&quot;iris&quot;</span>)</span><br><span class="line">iris.head()</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th>sepal_length</th>
<th>sepal_width</th>
<th>petal_length</th>
<th>petal_width</th>
<th>species</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>5.1</td>
<td>3.5</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td>1</td>
<td>4.9</td>
<td>3.0</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td>2</td>
<td>4.7</td>
<td>3.2</td>
<td>1.3</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="even">
<td>3</td>
<td>4.6</td>
<td>3.1</td>
<td>1.5</td>
<td>0.2</td>
<td>setosa</td>
</tr>
<tr class="odd">
<td>4</td>
<td>5.0</td>
<td>3.6</td>
<td>1.4</td>
<td>0.2</td>
<td>setosa</td>
</tr>
</tbody>
</table>
<p>此时，我们指定 x<em>x</em> 和 y<em>y</em> 的特征，默认可以绘制出散点图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_33_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>但是，上图并不能看出数据类别之间的联系，如果我们加入类别特征对数据进行着色，就更加直观了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_36_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Seaborn 的函数都有大量实用的参数，例如我们指定 <code>style</code> 参数可以赋予不同类别的散点不同的形状。更多的参数，希望大家通过阅读官方文档了解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>,</span><br><span class="line">            hue=<span class="string">&quot;species&quot;</span>, style=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_42_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>你会发现，上面我们一个提到了 3 个 API，分别是：<code>relplot</code>，<a href="https://seaborn.pydata.org/generated/seaborn.scatterplot.html"><code>scatterplot</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.lineplot.html"><code>lineplot</code></a>。实际上，你可以把我们已经练习过的 <code>relplot</code> 看作是 <code>scatterplot</code> 和 <code>lineplot</code> 的结合版本。</p>
<p>这里就要提到 Seaborn 中的 API 层级概念，Seaborn 中的 API 分为 Figure-level 和 Axes-level 两种。<code>relplot</code> 就是一个 Figure-level 接口，而 <code>scatterplot</code> 和 <code>lineplot</code> 则是 Axes-level 接口。</p>
<p>Figure-level 和 Axes-level API 的区别在于，Axes-level 的函数可以实现与 Matplotlib 更灵活和紧密的结合，而 Figure-level 则更像是「懒人函数」，适合于快速应用。</p>
<p>例如上方的图，我们也可以使用 <code>lineplot</code> 函数绘制，你只需要取消掉 <code>relplot</code> 中的 <code>kind</code> 参数即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lineplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;petal_length&quot;</span>,</span><br><span class="line">             hue=<span class="string">&quot;species&quot;</span>, style=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_48_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="类别图">类别图</h2>
<p>与关联图相似，类别图的 Figure-level 接口是 <code>catplot</code>，其为 categorical plots 的缩写。而 <code>catplot</code> 实际上是如下 Axes-level 绘图 API 的集合：</p>
<ul>
<li>分类散点图：<a href="https://seaborn.pydata.org/generated/seaborn.stripplot.html"><code>stripplot()</code></a> (<code>kind="strip"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.swarmplot.html"><code>swarmplot()</code></a> (<code>kind="swarm"</code>)</li>
<li>分类分布图：<a href="https://seaborn.pydata.org/generated/seaborn.boxplot.html"><code>boxplot()</code></a> (<code>kind="box"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.violinplot.html"><code>violinplot()</code></a> (<code>kind="violin"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.boxenplot.html"><code>boxenplot()</code></a> (<code>kind="boxen"</code>)</li>
<li>分类估计图：<a href="https://seaborn.pydata.org/generated/seaborn.pointplot.html"><code>pointplot()</code></a> (<code>kind="point"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.barplot.html"><code>barplot()</code></a> (<code>kind="bar"</code>)<a href="https://seaborn.pydata.org/generated/seaborn.countplot.html"><code>countplot()</code></a> (<code>kind="count"</code>)</li>
</ul>
<p>下面，我们看一下 <code>catplot</code> 绘图效果。该方法默认是绘制 <code>kind="strip"</code> 散点图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_54_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>kind="swarm"</code> 可以让散点按照 beeswarm 的方式防止重叠，可以更好地观测数据分布。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;swarm&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_56_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>同理，<code>hue=</code> 参数可以给图像引入另一个维度，由于 iris 数据集只有一个类别列，我们这里就不再添加 <code>hue=</code> 参数了。如果一个数据集有多个类别，<code>hue=</code> 参数就可以让数据点有更好的区分。</p>
<p>接下来，我们依次尝试其他几种图形的绘制效果。绘制箱线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;box&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_59_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制小提琴图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;violin&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_62_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制增强箱线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;species&quot;</span>, y=<span class="string">&quot;sepal_length&quot;</span>, kind=<span class="string">&quot;boxen&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_65_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制点线图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;point&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_68_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制条形图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.catplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;species&quot;</span>, kind=<span class="string">&quot;bar&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_71_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="分布图">分布图</h2>
<p>分布图主要是用于可视化变量的分布情况，一般分为单变量分布和多变量分布。当然这里的多变量多指二元变量，更多的变量无法绘制出直观的可视化图形。</p>
<p>Seaborn 提供的分布图绘制方法一般有这几个：<a href="https://seaborn.pydata.org/generated/seaborn.jointplot.html"><code>jointplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.pairplot.html"><code>pairplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.distplot.html"><code>distplot</code></a>，<a href="https://seaborn.pydata.org/generated/seaborn.kdeplot.html"><code>kdeplot</code></a>。接下来，我们依次来看一下这些绘图方法的使用。</p>
<p>Seaborn 快速查看单变量分布的方法是 <code>distplot</code>。默认情况下，该方法将会绘制直方图并拟合核密度估计图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.distplot(iris[<span class="string">&quot;sepal_length&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_80_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>istplot</code> 提供了参数来调整直方图和核密度估计图，例如设置 <code>kde=False</code> 则可以只绘制直方图，或者 <code>hist=False</code> 只绘制核密度估计图。当然，<code>kdeplot</code> 可以专门用于绘制核密度估计图，其效果和 <code>distplot(hist=False)</code> 一致，但 <code>kdeplot</code> 拥有更多的自定义设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.kdeplot(iris[<span class="string">&quot;sepal_length&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_83_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>jointplot</code> 主要是用于绘制二元变量分布图。例如，我们探寻 <code>sepal_length</code> 和 <code>sepal_width</code>二元特征变量之间的关系。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_86_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>jointplot</code> 并不是一个 Figure-level 接口，但其支持 <code>kind=</code> 参数指定绘制出不同样式的分布图。例如，绘制出核密度估计对比图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;kde&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_89_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>六边形计数图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;hex&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_92_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>回归拟合图：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris, kind=<span class="string">&quot;reg&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_95_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>最后要介绍的 <code>pairplot</code> 更加强大，其支持一次性将数据集中的特征变量两两对比绘图。默认情况下，对角线上是单变量分布图，而其他则是二元变量分布图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pairplot(iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_98_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>此时，我们引入第三维度 <code>hue="species"</code> 会更加直观。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.pairplot(iris, hue=<span class="string">&quot;species&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_101_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="回归图">回归图</h2>
<p>接下来，我们继续介绍回归图，回归图的绘制函数主要有：<a href="https://seaborn.pydata.org/generated/seaborn.lmplot.html"><code>lmplot</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.regplot.html"><code>regplot</code></a>。</p>
<p><code>regplot</code> 绘制回归图时，只需要指定自变量和因变量即可，<code>regplot</code> 会自动完成线性回归拟合。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.regplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_106_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p><code>lmplot</code> 同样是用于绘制回归图，但 <code>lmplot</code> 支持引入第三维度进行对比，例如我们设置 <code>hue="species"</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sns.lmplot(x=<span class="string">&quot;sepal_length&quot;</span>, y=<span class="string">&quot;sepal_width&quot;</span>, hue=<span class="string">&quot;species&quot;</span>, data=iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_109_2.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<h2 id="矩阵图">矩阵图</h2>
<p>矩阵图中最常用的就只有 2 个，分别是：<a href="https://seaborn.pydata.org/generated/seaborn.heatmap.html"><code>heatmap</code></a> 和 <a href="https://seaborn.pydata.org/generated/seaborn.clustermap.html"><code>clustermap</code></a>。</p>
<p>意如其名，<code>heatmap</code> 主要用于绘制热力图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">sns.heatmap(np.random.rand(<span class="number">10</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_114_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>热力图在某些场景下非常实用，例如绘制出变量相关性系数热力图。</p>
<p>除此之外，<code>clustermap</code> 支持绘制层次聚类结构图。如下所示，我们先去掉原数据集中最后一个目标列，传入特征数据即可。当然，你需要对层次聚类有所了解，否则很难看明白图像多表述的含义。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iris.pop(<span class="string">&quot;species&quot;</span>)</span><br><span class="line">sns.clustermap(iris)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://cdn.jsdelivr.net/gh/huhuhang/cdn/images/2019/seaborn-basic/output_118_1.png" alt="img"><figcaption aria-hidden="true">img</figcaption>
</figure>
<p>如果你浏览官方文档，你会发现 Seaborn 中还存在大量已大些字母开始的类，例如 <code>JointGrid</code>，<code>PairGrid</code> 等。实际上这些类只是其对应小写字母的函数 <code>jointplot</code>，<code>pairplot</code> 的进一步封装。当然，二者可能稍有不同，但并没有本质的区别。</p>
<p>除此之外，<span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWw=">Seaborn 官方文档<i class="fa fa-external-link-alt"></i></span> 中还有关于 <span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWwjc3R5bGUtY29udHJvbA==">样式控制<i class="fa fa-external-link-alt"></i></span> 和 <span class="exturl" data-url="aHR0cHM6Ly9zZWFib3JuLnB5ZGF0YS5vcmcvYXBpLmh0bWwjY29sb3ItcGFsZXR0ZXM=">色彩自定义<i class="fa fa-external-link-alt"></i></span> 等一些辅助组件的介绍。对于这些 API 的应用没有太大的难点，重点需要勤于练习。</p>
<p>来自https://huhuhang.com/post/machine-learning/seaborn-basic</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>广义加性模型</title>
    <url>/posts/17683e80.html</url>
    <content><![CDATA[<h1 id="广义加性模型">广义加性模型</h1>
<p>去年这个时候准备SRDP立项就看到了一堆用广义加性模型的例子，国内关于这个的资源实在太少了，大半年之后我才开始学习用这玩意。把自己找到的各种参考文献整理一下作为学习笔记发出来，给别人一个方便。</p>
<a id="more"></a>
<p>（吐槽一句关于机器学习，感觉就是一个生造的概念，我在这里就把所有的这些东西称为统计学习——应用统计学的方法，让机器自行学习规律，然后给出结果。)</p>
<p>线性模型简单、只管、便于理解，但是很多时候在实际情况中并不能满足线性的假设。这时有两种方法，一个是通过降低模型的复杂度和估计量的方差来改善模型，另一种方法就是改变线性假设。由第二种方法引出的就是广义加性模型。</p>
<h2 id="gam-广义相加模型generalized-additive-model">GAM 广义相加模型Generalized additive model</h2>
<table>
<colgroup>
<col style="width: 16%">
<col style="width: 83%">
</colgroup>
<thead>
<tr class="header">
<th>项目</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>概念</td>
<td>回归模型中部分或全部的自变量采用平滑函数，降低线性设定带来的模型风险，对模型的假定不严，如不需要假定自变量线性相关于因变量（线性或非线性都可以）。</td>
</tr>
<tr class="even">
<td>方程</td>
<td>，<em>g</em>是一个链接函数，y是独立变量,为未知的光滑函数,代替经典线性回归中的，对样本要求少，适用性广</td>
</tr>
<tr class="odd">
<td>参数估计方法</td>
<td>最小二乘法，极大似然法</td>
</tr>
<tr class="even">
<td>检验</td>
<td>残差Pseduo系数(PCf)估计，PCf = 1 - RD / ND (RD残差偏差，ND 无效偏差)</td>
</tr>
<tr class="odd">
<td>分类</td>
<td>可加/非参数（Aditive/Nonparametric): 参数（Parametric): 半参数/部分线性（Semiparametric/Partial Linear）: 薄板样条（Thin-plate spline）：允许两个自变量里有交互作用</td>
</tr>
<tr class="even">
<td>前提</td>
<td>如x1和x2并非独立而存在交互作用，则应设为Thin-plate spline: f(x1, x2)（之所以有这一项是因为广义加性模型假定各项之间是相互独立的，这样计算最后的期望的时候就可以把他们加起来，如果不是相互独立的，需要手动设置交叉相互作用项） 模型中不必每一项都是非线性的，如都非线性会出现计算量大、过拟合等问题，通过查看xi与y的是否存在线性关系来判断是否使用平滑函数。 要遵循统计学和操作中的注意事项</td>
</tr>
<tr class="odd">
<td>光滑函数</td>
<td>见”样条函数”</td>
</tr>
<tr class="even">
<td>缺点</td>
<td>样条函数参数的不确定性使之不能直接用于预估新的数据</td>
</tr>
<tr class="odd">
<td>Q&amp;A</td>
<td>如何确定光滑项？ 这是个比较哲学的问题（掐死吧！） 1.计算每一种可能性，然后使用拟合效果最好的那个（利用一些标准来衡量，例如AIC） 2.使用最能够反应数据产生过程的那一个模型</td>
</tr>
</tbody>
</table>
<p>（参考<span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdGV4dGJveS9hcnRpY2xlL2RldGFpbHMvNDcyNzcxMzE=">http://blog.csdn.net/textboy/article/details/47277131<i class="fa fa-external-link-alt"></i></span>）</p>
<p>样条函数函数</p>
<p>我理解的这个模型就是说，和之间是线性关系，这样就可以使用线性回归的计算方法和检验方法来得到结果了，然后是一个平滑函数。这里样条函数是啥…对我就是不明白这一点，网上查到的资料说是和三次样条插值的那个函数差不多，但是这样不就变成插值了吗摔。</p>
<p>先给自己一个存疑，留待日后解决，然后更详细的参考资料如下</p>
<p><span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdG9uZ3dlaWdhbmdscC9hcnRpY2xlL2RldGFpbHMvNTM0MjIzMjQ=">http://blog.csdn.net/tongweiganglp/article/details/53422324<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cDovL3d3dy5sb3lob21lLmNvbS8lZTIlODklYWElZTclYmIlOWYlZTglYWUlYTElZTUlYWQlYTYlZTQlYjklYTAlZTclYjIlYmUlZTglYTYlODF0aGUtZWxlbWVudHMtb2Ytc3RhdGlzdGljYWwtbGVhcm5pbmclZTIlODklYWIlZTglYWYlYmUlZTUlYTAlODIlZTclYWMlOTQlZTglYWUlYjAlZWYlYmMlODglZTUlOGQlODElZTQlYmElOGMlZWYlYmMlODkv">http://www.loyhome.com/%e2%89%aa%e7%bb%9f%e8%ae%a1%e5%ad%a6%e4%b9%a0%e7%b2%be%e8%a6%81the-elements-of-statistical-learning%e2%89%ab%e8%af%be%e5%a0%82%e7%ac%94%e8%ae%b0%ef%bc%88%e5%8d%81%e4%ba%8c%ef%bc%89/<i class="fa fa-external-link-alt"></i></span></p>
<p>mgcv manual</p>
<p>Generalized Additive Models:An inroduction with R</p>
<h1 id="aic-bic-roc与auc">AIC BIC ROC与AUC</h1>
<p>任何一个统计学方法都会有过拟合欠拟合的问题，在吴恩达的课程里给出来了一种比较直观的感性的判断方式（以后会整理的抱头鼠窜）在这里介绍另一类方法，通过一个评价的函数来p安短，这里给出其中三种：AIC、BIC和ROC与AUC</p>
<p>（其实还有交叉验证方法，在后一个吴老师课程里讲的非常详细我也会整理的抱头鼠窜）</p>
<h2 id="aic">AIC</h2>
<p>AIC是衡量统计模型拟合优良性的一种标准，由日本统计学家赤池弘次在1974年提出，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。</p>
<p>通常情况下，AIC定义为：</p>
<p>其中k是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。假设条件是模型的误差服从独立正态分布。 让n为观察数，RSS为剩余平方和,则AIC变为：</p>
<p>当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。</p>
<p>一般而言，当模型复杂度提高（k增大）时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。</p>
<h2 id="bic">BIC</h2>
<p>BIC（Bayesian InformationCriterion）贝叶斯信息准则与AIC相似，用于模型选择，1978年由Schwarz提出。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。</p>
<p>其中，k为模型参数个数，n为样本数量，L为似然函数，kln(n)惩罚项在维数过大且训练样本数据相对较少的情况下，可以有限避免出现维度灾难现象。</p>
<h2 id="roc与auc-衡量分类器的好坏">ROC与AUC-衡量分类器的好坏</h2>
<h3 id="二元分类器">二元分类器</h3>
<p>二元分类器是指要输出(预测)的结果只有两种类别的模型。例如预测阳性/阴性，有病/没病，在银行信用评分模型中，也用来预测用户是否会违约，等等。</p>
<p>  既然是一种预测模型，则实际情况一定是有些结果猜对了，有些结果猜错了。因为二元分类器的预测结果有两种类别(以下以阴/阳为例)，对应其真实值，则会有以下四种情形:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Actual</th>
<th>class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>predict</td>
<td>true positive</td>
<td>false positive</td>
</tr>
<tr class="even">
<td>class</td>
<td>false negative</td>
<td>true negative</td>
</tr>
</tbody>
</table>
<p><a href="http://beader.me/imgs/auc-roc/9686a1f19149fe16eb4b6b383904d086.png"><img src="http://beader.me/imgs/auc-roc/9686a1f19149fe16eb4b6b383904d086.png" alt="img"></a></p>
<p>图1.confusion matrix (混乱矩阵)</p>
<p>精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是对的。召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。</p>
<p>当且仅当两者都高的时候，我们才可以说这种算法很NICE。在某些情况下我们可能要设定threshold来进行trade-off</p>
<ul>
<li>如果我们希望在很确信的情况下才告诉病人有cancer，也就是说不要给病人太多惊吓，我告诉你有cancer，你肯定有cancer；我告诉你没cancer，你也有可能有cancer，那么该情况下有：higher threshold，higher precision，lower recall</li>
<li>如果我们不希望让病人错过提前治疗，与上例相反，就有：lower threshold，lower precision，higher recall</li>
</ul>
<p>除此之外，还有另外一个评价标准来进行trade-off</p>
<p>越大越好</p>
<h3 id="roc空间与roc曲线">ROC空间与ROC曲线</h3>
<p>在信号检测理论中，接收者操作特征曲线（receiver operating characteristic curve，或者叫<span class="exturl" data-url="aHR0cDovL3poLndpa2lwZWRpYS5vcmcvd2lraS9ST0MlRTYlOUIlQjIlRTclQkElQkY=">ROC曲线<i class="fa fa-external-link-alt"></i></span>）是一种座标图式的分析工具。  要了解ROC曲线，先要了解一下ROC空间，ROC空间是一个以伪阳性率(FPR, false positive rate)为X轴，真阳性率(TPR, true positive rate)为Y轴的二维坐标系所代表平面。</p>
<ul>
<li>TPR: 真阳性率，所有阳性样本中(TP+FN)，被分类器正确判断为阳的比例。TPR = TP / (TP + FN) = TP / 所有真实值为阳性的样本个数</li>
<li>FPR: 伪阳性率，所有阴性样本中(FP+TN)，被分类器错误判断为阳的比例。FPR = FP / (FP + TN) = FP / 所有真实值为阴性的样本个数</li>
</ul>
<p>  我们想象这样一种场景，接触阳性样本可以给我们带来“收益”，接触阴性样本则会给我们造成”成本”。并且如果我们接触样本中所有的阳性样本，我们的收益是1，接触样本中的所有阴性样本，我们的成本也是1。如果不接触样本，则既不产生收益也不产生成本。  自然的，如果不使用分类器，接触所有样本，则总的效益为1-1=0。现在让我们利用分类器来决定是否接触样本，分类器预测为阳，我们就去接触样本，分类器预测为阴，我们就不去接触。因为不接触样本不会产生收益或是成本，因此我们只需要看分类器预测为阳的样本。预测为阳的样本中，TP将产生 TPR 的收益， FP将产生FPR的成本。  那么一个分类器的分类效果就对应ROC空间里的一个点:</p>
<p><a href="http://beader.me/imgs/auc-roc/1a02adedd70816dcd49461354390aaed.png"><img src="http://beader.me/imgs/auc-roc/1a02adedd70816dcd49461354390aaed.png" alt="img"></a></p>
<p>图2.ROC空间</p>
<p>A,B,C三个点可以分别代表三个不同的分类器对同样的样本做预测的结果。最好的方法是A，因为他的收益大于成本(TPR &gt; FPR)，最差的是C(TPR &lt; FPR)。中等的是B，相当于随机分类器。这里有趣的一点是若把C以(0.5, 0.5)为中点作一个镜像，得到C’， C’的效果比A要来的好。C’相当于一个做与C预测结果完全相反的分类器。  实际的应用当中，分类器还会给出它预测某个样本为阳的概率，并且有一个事先给定的门槛值(threshold)，概率高于threshold的就预测为阳性，低于threshold的就预测为阴性。假设以下是某个分类器对id为1-10的客户的分类结果:</p>
<p>表1.分类器预测结果</p>
<p><a href="http://beader.me/imgs/auc-roc/95ccbafd95b1ef894b2711d3698d5187.png"><img src="http://beader.me/imgs/auc-roc/95ccbafd95b1ef894b2711d3698d5187.png" alt="img"></a></p>
<p>其中probability of 1为分类器判断该样本为阳性的概率，true class为该样本的真实情况。  如果我们把threshold定位0.5，即去接触id为1~8的客户。此时</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TPR &#x3D; TP &#x2F; 所有真实值为阳性的样本个数 &#x3D; 6 &#x2F; 6 &#x3D; 1</span><br><span class="line">FPR &#x3D; FP &#x2F; 所有真实值为阴性的样本个数 &#x3D; 2 &#x2F; 4 &#x3D; 0.6</span><br></pre></td></tr></table></figure>
<p>同理，如果我们把threshold定位0.8，即去接触id为1~5的客户。此时</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TPR &#x3D; TP &#x2F; 所有真实值为阳性的样本个数 &#x3D; 4 &#x2F; 6 &#x3D; 0.67</span><br><span class="line">FPR &#x3D; FP &#x2F; 所有真实值为阴性的样本个数 &#x3D; 1 &#x2F; 4 &#x3D; 0.25</span><br></pre></td></tr></table></figure>
<p>  这两个threshold分别对应ROC空间中的两个点A、B</p>
<p><a href="http://beader.me/imgs/auc-roc/f3aac8b8603adb924363e766992df3cd.png"><img src="http://beader.me/imgs/auc-roc/f3aac8b8603adb924363e766992df3cd.png" alt="img"></a></p>
<p>图3.不同的threshold对应ROC空间中不同的点</p>
<p>上面的例子当中，共有10笔预测数据，则一共有11种threshold的设定方法，每一个threshold对应ROC空间中的一个点，把这些点连接起来，就成了ROC曲线。</p>
<p><a href="http://beader.me/imgs/auc-roc/92175e2de4a480e52938a836994e823c.png"><img src="http://beader.me/imgs/auc-roc/92175e2de4a480e52938a836994e823c.png" alt="img"></a></p>
<p>图4.ROC曲线</p>
<p>  这里因为数据量太少，所以曲线是一折一折的，数据量大的时候，看上去才像”曲线”。</p>
<h3 id="auc">AUC</h3>
<p>(Area under the Curve of ROC) 曲线下面积</p>
<p>以下直接搬维基百科:</p>
<ul>
<li>因为是在1x1的方格里求面积，AUC必在0~1之间。</li>
<li>假设threshold以上是阳性，以下是阴性；</li>
<li>若随机抽取一个阳性样本和一个阴性样本，分类器正确判断阳性样本的值高于阴性样本之机率。(即前文当中把C做一个镜像变为C’)</li>
<li>简单说：AUC值越大的分类器，正确率越高。</li>
</ul>
<p>  从AUC判断分类器（预测模型）优劣的标准：</p>
<ul>
<li><p>AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。</p></li>
<li><p>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</p></li>
<li><p>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</p></li>
<li><p>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测，因此不存在AUC &lt; 0.5的情况。</p>
<p><a href="http://beader.me/imgs/auc-roc/f03add592a75ef5b5e7346a5209b0cb8.png"><img src="http://beader.me/imgs/auc-roc/f03add592a75ef5b5e7346a5209b0cb8.png" alt="img"></a></p>
<p>图5.用AUC来衡量不同分类器的分类能力(更准确的说是排序能力)</p>
<h3 id="总结">总结</h3>
<p>一个分类模型的分类结果的好坏取决于以下两个部分：</p>
<ol type="1">
<li>分类模型的排序能力(能否把概率高的排前面，概率低的排后面)</li>
<li>threshold的选择</li>
</ol>
<p>  使用AUC来衡量分类模型的好坏，可以忽略由于threshold的选择所带来的影响，因为实际应用中，这个threshold常常由先验概率或是人为决定的。</p>
<h3 id="补充gini-coefficient">补充：Gini coefficient</h3>
<p>在用SAS或者其他一些统计分析软件，用来评测分类器分类效果时，常常会看到一个叫做gini coefficient的东西，那么这个gini coefficient又是什么呢？gini系数通常被用来判断收入分配公平程度，具体请参阅<span class="exturl" data-url="aHR0cDovL3poLndpa2lwZWRpYS5vcmcvd2lraS8lRTUlOUYlQkElRTUlQjAlQkMlRTclQjMlQkIlRTYlOTUlQjA=">wikipedia-基尼系数<i class="fa fa-external-link-alt"></i></span>。<a href="http://beader.me/imgs/auc-roc/1a9a293ac6c97475ebb337fb32081a4d.png"><img src="http://beader.me/imgs/auc-roc/1a9a293ac6c97475ebb337fb32081a4d.png" alt="img"></a>  图6.洛伦茨曲线与基尼系数</p>
<p>  Gini coefficient 是指绝对公平线(line of equality)和洛伦茨曲线(Lorenz Curve)围成的面积与绝对公平线以下面积的比例，即gini coefficient = A面积 / (A面积+B面积) 。</p>
<p>  用在评判分类模型的预测效力时，是指ROC曲线曲线和中线围成的面积与中线之上面积的比例。</p>
<p><a href="http://beader.me/imgs/auc-roc/074c46dccea3031e5ce8fcbb67453cd4.png"><img src="http://beader.me/imgs/auc-roc/074c46dccea3031e5ce8fcbb67453cd4.png" alt="img"></a>  图7.Gini coefficient与AUC</p>
<p>因此Gini coefficient与AUC可以互相转换：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  </span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gini &#x3D; A &#x2F; (A + B) &#x3D; (AUC - C) &#x2F; (A + B) &#x3D; (AUC -0.5) &#x2F; 0.5 &#x3D; 2*AUC - 1</span><br></pre></td></tr></table></figure></li>
</ul>
<p>参考 ：</p>
<p><span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGZkYW5kaW5nL2FydGljbGUvZGV0YWlscy81MDczMjc2Mj9sb2NhdGlvbk51bT04JmFtcDtmcHM9MQ==">http://blog.csdn.net/lfdanding/article/details/50732762?locationNum=8&amp;fps=1<i class="fa fa-external-link-alt"></i></span></p>
<p><span class="exturl" data-url="aHR0cDovL2JlYWRlci5tZS8yMDEzLzEyLzE1L2F1Yy1yb2Mv">http://beader.me/2013/12/15/auc-roc/<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="r语言实现">R语言实现</h2>
<h3 id="r语言实现广义加性模型及相关函数">R语言实现广义加性模型及相关函数</h3>
<p>仅仅列出我最常用的几个 gam gam.check plot.gam predict.gam choose.k gam.selection</p>
<p>(给自己开了一个大坑啊，不知道能不能在生态学下课之前写完)</p>
<p>（看来是写不完了，要下课了…)</p>
<p>这一部分参考了manual和 R语言实现广义加性模型 Generalized Additive Models(GAM) 入门</p>
<h5 id="实现和画图">1.实现和画图</h5>
<p>R语言官网：<span class="exturl" data-url="aHR0cDovL3d3dy5yLXByb2plY3Qub3JnLw==">http://www.r-project.org/<i class="fa fa-external-link-alt"></i></span></p>
<p>R语言软件下载：<span class="exturl" data-url="aHR0cDovL2Z0cC5jdGV4Lm9yZy9taXJyb3JzL0NSQU4v">http://ftp.ctex.org/mirrors/CRAN/<i class="fa fa-external-link-alt"></i></span> 注：下载时点击 install R for the first time</p>
<p>下面进行一个简单的入门程序学习。</p>
<p>先新建一个txt，叫做 Rice_insect.txt，内容为：</p>
<p><a href="https://lifeodyssey.github.io/home/zhenjiazhou/%E5%9B%BE%E7%89%87/%E9%80%89%E5%8C%BA_002.bmp"><img src="https://lifeodyssey.github.io/home/zhenjiazhou/%E5%9B%BE%E7%89%87/%E9%80%89%E5%8C%BA_002.bmp" alt="选区_002"></a></p>
<p>　　Adult为累计蛾量，Day为降雨持续天数，Precipitation为降雨量。</p>
<p>输入代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">library(mgcv)      #加载mgcv软件包，因为gam函数在这个包里</span><br><span class="line">Data &lt;- read.delim(&quot;Rice_insect.txt&quot;)     #读取txt数据，存到Data变量中</span><br><span class="line">Data &lt;- as.matrix(Data)     #转为矩阵形式</span><br><span class="line">#查看Data数据：Data，查看第2列：Data[,2]，第2行：Data[2,]</span><br><span class="line"></span><br><span class="line">result1 &lt;- gam(log(Adult) ~ s(Day))     #此时，Adult为相应变量，Day为解释变量</span><br><span class="line">summary(result1)      #输出计算结果</span><br></pre></td></tr></table></figure>
<p>　　此时可以看到：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Day)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.3562 22.18 4.83e-13 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-values(Day) 1.713 2.139 0.797 0.473</p>
<p>R-sq.(adj) = 0.0471 Deviance explained = 14.3%GCV score = 2.6898 Scale est. = 2.2844 n = 18</p>
<p>Day的影响水平p-value=0.473，解释能力为14.3%，说明影响不明显。</p>
<p>其中，edf为自由度，理论上，当自由度接近1时，表示是线性关系；当自由度比1大，则表示为曲线关系。</p>
<p>接下来使用另一个解释变量Precipitation。输入代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result2 &lt;- gam(log(Adult) ~ s(Precipitation))</span><br><span class="line">summary(result2)</span><br></pre></td></tr></table></figure>
<p>　　发现：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Precipitation)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.2731 28.94 1.87e-12 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-value s(Precipitation) 5.022 6.032 2.561 0.0774 .—Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>R-sq.(adj) = 0.44 Deviance explained = 60.6%GCV score = 2.0168 Scale est. = 1.342 n = 18</p>
<p>此时p-value为0.0774，说明该因子在P&lt;0.1水平下影响显著。（一般情况下p&lt;0.05为显著。）</p>
<p>接下来画图：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plot(result2,se&#x3D;T,resid&#x3D;T,pch&#x3D;16)</span><br></pre></td></tr></table></figure>
<p>　　<a href="file://tmp/wps-zhenjiazhou/ksohtml/wpsoAF24S.jpg"><img src="file://tmp/wps-zhenjiazhou/ksohtml/wpsoAF24S.jpg" alt="img"></a></p>
<p>pch=16这个是图标的序号，比如改成17就是三角形了。</p>
<p>log(Adult)中的log是什么意思呢?</p>
<p>log是数据变换，取对数可以把大范围的数变成小范围的数，这在将几组相差太大的数据画在同一个坐标轴时特别有用，比如一组数据范围是1～10，第二组数据范围是10～100000000，要是不对第二组取常用对数，第一组在坐标轴上只是一点点，都看不到，对第二组取常用对数后，第二组范围变成1～8了，这样两组数据都能看到了。</p>
<p>下面尝试将两个变量同时作为解释变量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result3&lt;-gam(log(Adult)~s(Precipitation)+s(Day))</span><br></pre></td></tr></table></figure>
<p>　　出错：Model has more coefficients than data</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">result3&lt;-gam(log(Adult)~s(Precipitation,k&#x3D;9)+s(Day,k&#x3D;9)</span><br></pre></td></tr></table></figure>
<p>　　k是什么？</p>
<p>　　k is the dimension of the basis used to represent the smooth term. If k is not specified then basis specific defaults are used.</p>
<p>K的最小值是3，最大值是17，为3、4的时候都是直线，说明太小了体现不出来，在不断增大的过程中发现，K越大，曲线原来越平滑，再大时，曲线就出现了一些弯曲，说明更精准了，再大时，图形就基本不变了，说明也没必要设那么大了。</p>
<p>再</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">summary(result3)</span><br></pre></td></tr></table></figure>
<p>　　结果：</p>
<p>Family: gaussian Link function: identity</p>
<p>Formula:log(Adult) ~ s(Precipitation, k = 9) + s(Day, k = 9)</p>
<p>Parametric coefficients:Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 7.9013 0.2831 27.91 8.16e-12 <strong>—Signif. codes: 0 ‘</strong>’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>Approximate significance of smooth terms:edf Ref.df F p-value s(Precipitation) 4.653 5.572 2.546 0.0848 .s(Day) 1.000 1.000 0.500 0.4939 —Signif. codes: 0 ‘<em><strong>’ 0.001 ‘</strong>’ 0.01 ‘</em>’ 0.05 ‘.’ 0.1 ‘ ’ 1</p>
<p>R-sq.(adj) = 0.398 Deviance explained = 59.8%GCV score = 2.288 Scale est. = 1.4423 n = 18</p>
<h5 id="其它函数">2.其它函数</h5>
<p>具体内容请查看manual</p>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 45%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>函数</th>
<th>描述</th>
<th>用法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>gam.check</td>
<td>采用由gam（）生成的拟合的gam对象来产生关于拟合程序和结果的一些诊断信息。 缺省情况是产生4个残差图，关于光滑性选择优化的收敛的一些信息，以及运行基本维度选择是否足够的诊断测试。 应用于由gamm返回的gam对象时应注意解释结果。</td>
<td>gam.check(b,old.style=FALSE, type=c(“deviance”, “pearson”, “response”), k.sample=5000,k.rep=200, rep=0, level=.9, rl.col=2, rep.col=”gray80”, …)参数说明见后</td>
</tr>
<tr class="even">
<td>predict.gam</td>
<td>采用由gam（）生成的拟合gam对象来给出一组新的用于模型协变量或用于模型拟合的原始值的预测值。 基于模型系数的后验分布，预测可以伴随着标准误差。 常规程序可以选择性地返回模型系数的矩阵，这个矩阵必须必须预先倍增（？？？），以便在所提供的协变量值处产生线性预测值的值：这对于从模型中获得的预测值获得置信区间是有用的（例如， 从平滑函数中衍生）以及R之外的查找表预测。</td>
<td>predict(object, newdata, type=”link”, se.fit=FALSE, terms=NULL, exclude=NULL, block.size=NULL, newdata.guaranteed=FALSE, na.action=na.pass,unconditional=FALSE,…)参数说明：object是预测出的模型，newdata是预测基于的自变量的值，注意一个是名字要和之前构建模型的名字一样，另一个是如果缺省，给出的结果是基于之前模型构建样本的因变量值，其余缺省即可</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>gam.check参数说明</p>
<table>
<thead>
<tr class="header">
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>b</td>
<td>由GAM模型产生的结果</td>
</tr>
<tr class="even">
<td>old.style</td>
<td>如果改成true得到word2006版本的图像（黑人问号脸）</td>
</tr>
<tr class="odd">
<td>type</td>
<td>餐叉的类型，具体参见residuals.gam</td>
</tr>
<tr class="even">
<td>k.sample</td>
<td>在这个k值水平上使用一个来自于样本的随机子集来测试</td>
</tr>
<tr class="odd">
<td>k.rep</td>
<td>多少次重新洗牌才能得到k测试的p值（黑人）</td>
</tr>
<tr class="even">
<td>rep, level, rl.col, rep.col</td>
<td>在old.style为false时传递给qq.gam（）的参数，请参阅qq.gam().</td>
</tr>
</tbody>
</table>
<p>剩余的图形参数请参见画图函数的参数</p>
<h4 id="r实现aic-bic-roc-auc">R实现AIC BIC ROC AUC</h4>
<p>非常简单！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">AIC(object, ..., k &#x3D; 2)</span><br><span class="line"></span><br><span class="line">BIC(object, ...)</span><br></pre></td></tr></table></figure>
<p>ROC<span class="exturl" data-url="aHR0cDovL2Jsb2cuY3Nkbi5uZXQvc29sbzc3NzMvYXJ0aWNsZS9kZXRhaWxzLzg2OTk2OTM=">http://blog.csdn.net/solo7773/article/details/8699693<i class="fa fa-external-link-alt"></i></span></p>
<p>AUC <span class="exturl" data-url="aHR0cDovL3d3dy5haWNoZW5neHUuY29tL3B5dGhvbi84OTAwMzQyLmh0bWU=">http://www.aichengxu.com/python/8900342.htme<i class="fa fa-external-link-alt"></i></span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>广义加性模型</tag>
        <tag>统计分析</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>pandas基础</title>
    <url>/posts/50bcdc38.html</url>
    <content><![CDATA[<p>其实我一点儿都不想用pandas的dataframe，总感觉这个东西很难用，也许是我的水平还没达到。但是好多时候读写实验室的excel和输出成excel又必须用这个，之前用的seaborn也是基于pandas的，那就再把基础操作复习一下。</p>
<a id="more"></a>
<h1 id="读写与创建">读写与创建</h1>
<h2 id="数据读写">数据读写</h2>
<h3 id="sql">sql</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line">db = create_engine(<span class="string">&quot;mysql+pymysql://用户名:用户密码@localhost:端口号（3306）/使用的数据库名?charset=utf8&quot;</span>)</span><br><span class="line">sql = <span class="string">&quot;select * from text&quot;</span></span><br><span class="line">df = pd.read_sql(sql, db, index_col=<span class="string">&quot;index&quot;</span>) <span class="comment"># index_col设置索引列，默认自动生成索引</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sql.to_sql(df, name=<span class="string">&#x27;test&#x27;</span>, con=db,</span><br><span class="line">                 if_exists=<span class="string">&quot;append&quot;</span>,<span class="comment"># 如果表存在：append追加 replace删除原表新建并插入 fail不插入</span></span><br><span class="line">                 index=<span class="literal">False</span> <span class="comment"># 设置df的索引不插入数据库</span></span><br><span class="line">                 )</span><br></pre></td></tr></table></figure>
<h3 id="excel">excel</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read_excel(<span class="string">r&#x27;file_path&#x27;</span>,</span><br><span class="line">                   sheet_name=<span class="string">&#x27;指定sheet,默认第一个&#x27;</span>,</span><br><span class="line">                   index=<span class="literal">False</span>, <span class="comment"># 不读取excel中的索引，自动生成新索引</span></span><br><span class="line">                   index_col=<span class="number">0</span>, <span class="comment"># 将第0列设置为索引</span></span><br><span class="line">                   header=<span class="number">0</span>, <span class="comment"># 将第n行设置为columns, 默认是0，可以设置为None（自动生成0-n的columns）</span></span><br><span class="line">                   usecols=[<span class="number">0</span>, <span class="number">2</span>] <span class="comment"># 只导入0, 2列</span></span><br><span class="line">                   )</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">按照不同sheet写入</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment"># 创建表格</span></span><br><span class="line">excelWriter = pd.ExcelFile(<span class="string">&#x27;file_path/test.xlsx&#x27;</span>)</span><br><span class="line"><span class="comment"># 写入表格</span></span><br><span class="line">df.to_excel(</span><br><span class="line">    excelWriter,</span><br><span class="line">    sheet_name=<span class="string">&#x27;&#x27;</span>,</span><br><span class="line">    insex=<span class="literal">False</span>, <span class="comment"># 设置df的索引不传入excel</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定某列写入excel</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值处理（填充为0）</span></span><br><span class="line">    inf_rep=<span class="number">0</span>, <span class="comment"># 无穷值处理（填充为0）</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 保存（不保存不生效）</span></span><br><span class="line">excelWriter.save()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">直接写入</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">df.to_excel(<span class="string">&#x27;file_path/test.xlsx&#x27;</span>) <span class="comment"># 参数：insex、encoding、columns、na_rep、inf_rep</span></span><br></pre></td></tr></table></figure>
<h3 id="csv">csv</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = pd.read(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    sep=<span class="string">&quot;&quot;</span>, <span class="comment"># 指定分隔符，默认是逗号</span></span><br><span class="line">    nrows=<span class="number">2</span>, <span class="comment"># 指定读取行数</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    engine=<span class="string">&#x27;python&#x27;</span>, <span class="comment"># 当路径存在中文会报错，加上这个即解决</span></span><br><span class="line">    usecols=[<span class="number">0</span>, <span class="number">2</span>], <span class="comment"># 仅导入0, 2列</span></span><br><span class="line">    index_col=<span class="number">0</span>, <span class="comment"># 将第0列设置为索引</span></span><br><span class="line">    header=<span class="number">0</span> <span class="comment"># 将第n行设置为columns, 默认是0，可以设置为None（自动生成0-n的columns）</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_csv(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    index=<span class="literal">False</span>, <span class="comment"># 索引列不写入</span></span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定写入的列</span></span><br><span class="line">    sep=<span class="string">&#x27;,&#x27;</span>, <span class="comment"># 设置分隔符（默认是逗号）</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值填充为0</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    <span class="comment">#inf_rep=0 没有这个参数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="txt">txt</h3>
<ul>
<li><strong>读取</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.read_table(<span class="string">r&#x27;file_path/test.txt&#x27;</span>, sep=<span class="string">&#x27;&#x27;</span>) <span class="comment">#也可以用来读取csv文件</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>写入</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.to_csv(</span><br><span class="line">    <span class="string">r&#x27;file_path/test.csv&#x27;</span>,</span><br><span class="line">    index=<span class="literal">False</span>, <span class="comment"># 索引列不写入</span></span><br><span class="line">    columns=[<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], <span class="comment"># 指定写入的列</span></span><br><span class="line">    sep=<span class="string">&#x27;,&#x27;</span>, <span class="comment"># 设置分隔符（默认是逗号）</span></span><br><span class="line">    na_rep=<span class="number">0</span>, <span class="comment"># 缺失值填充为0</span></span><br><span class="line">    encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">    <span class="comment">#inf_rep=0 没有这个参数</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>来源https://www.modb.pro/db/26894</p>
<h2 id="创建">创建</h2>
<p>最让我不爽的就是dataframe没有像np.zeros,np.ones这种根据已有的dataframe来初始化一个空dataframe.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df_empty=pd.Dataframe(columns=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>所以有一种办法就是把已有的datafram列名提取出来，然后再去创建。</p>
<h1 id="索引">索引</h1>
<p>Pandas 数据的索引就像一本书的目录，让我们很快地找到想要看的章节，作为大量数据，创建合理的具有业务意义的索引对我们分析数据至关重要。</p>
<h2 id="认识索引">认识索引</h2>
<p>下图是一个简单的 DataFrame 中索引的示例：</p>
<figure>
<img src="https://www.gairuo.com/file/pic/2020/04/pandas_index_01.jpg" alt="pandas index"><figcaption aria-hidden="true">pandas index</figcaption>
</figure>
<p>其中：</p>
<ul>
<li>行索引是数据的索引，列索引指向的是一个 Series</li>
<li>DataFrame 的索引也是系列形成的 Series 的索引</li>
<li>建立索引让数据更加直观明确，如每行数据是针对一个国家的</li>
<li>建立索引方便数据处理</li>
<li>索引允许重复，但业务上一般不会让它重复</li>
</ul>
<p>有时一个行和列层级较多的数据会出现<span class="exturl" data-url="aHR0cHM6Ly93d3cuZ2FpcnVvLmNvbS9wL3BhbmRhcy1tdWx0aUluZGV4">多层索引<i class="fa fa-external-link-alt"></i></span> 的情况。</p>
<h2 id="建立索引">建立索引</h2>
<p>之前我们学习了加载数据生成 DataFrame 时可以指定索引</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = <span class="string">&#x27;https://www.gairuo.com/file/data/dataset/team.xlsx&#x27;</span></span><br><span class="line">df = pd.read_excel(data, index_col=<span class="string">&#x27;name&#x27;</span>) <span class="comment"># 设置索引为 name</span></span><br><span class="line">df</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">      team  Q1  Q2  Q3  Q4</span></span><br><span class="line"><span class="string">name</span></span><br><span class="line"><span class="string">Liver    E  89  21  24  64</span></span><br><span class="line"><span class="string">Arry     C  36  37  37  57</span></span><br><span class="line"><span class="string">Ack      A  57  60  18  84</span></span><br><span class="line"><span class="string">Eorge    C  93  96  71  78</span></span><br><span class="line"><span class="string">Oah      D  65  49  61  86</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>如果加载时没有指定索引，我们可以使用 <code>df.set_index()</code> 指定：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>) <span class="comment"># 设置月份为索引</span></span><br><span class="line">df.set_index([<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 设置月份和年为多层索引</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            sale</span></span><br><span class="line"><span class="string">month year</span></span><br><span class="line"><span class="string">1     2012    55</span></span><br><span class="line"><span class="string">4     2014    40</span></span><br><span class="line"><span class="string">      2013    84</span></span><br><span class="line"><span class="string">10    2014    31</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">s = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">df.set_index(s) <span class="comment"># 指定一个索引</span></span><br><span class="line">df.set_index([s, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 指定的索引和现有字段同时指定</span></span><br><span class="line">df.set_index([s, s**<span class="number">2</span>]) <span class="comment"># 计算索引</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他的参数</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, drop=<span class="literal">False</span>) <span class="comment"># 保留原列</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, append=<span class="literal">True</span>) <span class="comment"># 保留原来的索引</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>, inplace=<span class="literal">True</span>) <span class="comment"># 建立索引并重写覆盖 df</span></span><br></pre></td></tr></table></figure>
<h2 id="重置索引">重置索引</h2>
<p>有时我们想取消已有的索引，以重新来过，可以使用 <code>df.reset_index()</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.reset_index() <span class="comment"># 清除索引</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>).reset_index() <span class="comment"># 相当于啥也没干</span></span><br><span class="line"><span class="comment"># 删除原索引，month 列没了</span></span><br><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df2.reset_index(inplace=<span class="literal">True</span>) <span class="comment"># 覆盖使生效</span></span><br><span class="line"><span class="comment"># year 一级索引取消</span></span><br><span class="line">df.set_index([<span class="string">&#x27;month&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]).reset_index(level=<span class="number">1</span>)</span><br><span class="line">df2.reset_index(level=<span class="string">&#x27;class&#x27;</span>) <span class="comment"># 同上使用层级索引名</span></span><br><span class="line">df.reset_index(level=<span class="string">&#x27;class&#x27;</span>, col_level=<span class="number">1</span>) <span class="comment"># 列索引</span></span><br><span class="line"><span class="comment"># 不存在层级名称的填入指定名称</span></span><br><span class="line">df.reset_index(level=<span class="string">&#x27;class&#x27;</span>, col_level=<span class="number">1</span>, col_fill=<span class="string">&#x27;species&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="索引类型">索引类型</h2>
<p>为了适应各种业务数据的处理，索引又针对各种类型数据定义了不同的索引类型：</p>
<h3 id="数字索引-numeric-index">数字索引 Numeric Index</h3>
<p>共有以下几种：</p>
<ul>
<li>RangeIndex: 单调整数范围的不可变索引。</li>
<li>Int64Index: int64类型，有序可切片集合的不可变ndarray。</li>
<li>UInt64Index: 无符号整数标签的</li>
<li>Float64Index: Float64 类型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.RangeIndex(<span class="number">1</span>,<span class="number">100</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># RangeIndex(start=1, stop=100, step=2)</span></span><br><span class="line">pd.Int64Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">-4</span>], name=<span class="string">&#x27;num&#x27;</span>)</span><br><span class="line"><span class="comment"># Int64Index([1, 2, 3, -4], dtype=&#x27;int64&#x27;, name=&#x27;num&#x27;)</span></span><br><span class="line">pd.UInt64Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># UInt64Index([1, 2, 3, 4], dtype=&#x27;uint64&#x27;)</span></span><br><span class="line">pd.Float64Index([<span class="number">1.2</span>,<span class="number">2.3</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment"># Float64Index([1.2, 2.3, 3.0, 4.0], dtype=&#x27;float64&#x27;)</span></span><br></pre></td></tr></table></figure>
<h3 id="类别索引-categoricalindex">类别索引 CategoricalIndex</h3>
<p>类别只能包含有限数量的（通常是固定的）可能值（类别）。 可以理解成枚举，比如性别只有男女，但在数据中每行都有，如果按文本处理会效率不高。类别的底层是 pandas.Categorical。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.CategoricalIndex([<span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"><span class="comment"># CategoricalIndex([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;a&#x27;, &#x27;b&#x27;], categories=[&#x27;a&#x27;, &#x27;b&#x27;], ordered=False, dtype=&#x27;category&#x27;)</span></span><br></pre></td></tr></table></figure>
<p>类别后边后有专门的讲解，只有在体量非常大的数据面前才能显示其优势。</p>
<h3 id="间隔索引-intervalindex">间隔索引 IntervalIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.interval_range(start=<span class="number">0</span>, end=<span class="number">5</span>)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]],</span></span><br><span class="line"><span class="string">              closed=&#x27;right&#x27;,</span></span><br><span class="line"><span class="string">              dtype=&#x27;interval[int64]&#x27;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="多层索引-multiindex">多层索引 MultiIndex</h3>
<p>教程后边会有专门的讲解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arrays = [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>], [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>]]</span><br><span class="line">pd.MultiIndex.from_arrays(arrays, names=(<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;color&#x27;</span>))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">MultiIndex([(1,  &#x27;red&#x27;),</span></span><br><span class="line"><span class="string">            (1, &#x27;blue&#x27;),</span></span><br><span class="line"><span class="string">            (2,  &#x27;red&#x27;),</span></span><br><span class="line"><span class="string">            (2, &#x27;blue&#x27;)],</span></span><br><span class="line"><span class="string">           names=[&#x27;number&#x27;, &#x27;color&#x27;])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="时间索引-datetimeindex">时间索引 DatetimeIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从一个日期连续到另一个日期</span></span><br><span class="line">pd.date_range(start=<span class="string">&#x27;1/1/2018&#x27;</span>, end=<span class="string">&#x27;1/08/2018&#x27;</span>)</span><br><span class="line"><span class="comment"># 指定开始时间和周期</span></span><br><span class="line">pd.date_range(start=<span class="string">&#x27;1/1/2018&#x27;</span>, periods=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 以月为周期</span></span><br><span class="line">pd.period_range(start=<span class="string">&#x27;2017-01-01&#x27;</span>, end=<span class="string">&#x27;2018-01-01&#x27;</span>, freq=<span class="string">&#x27;M&#x27;</span>)</span><br><span class="line"><span class="comment"># 周期嵌套</span></span><br><span class="line">pd.period_range(start=pd.Period(<span class="string">&#x27;2017Q1&#x27;</span>, freq=<span class="string">&#x27;Q&#x27;</span>),</span><br><span class="line">                end=pd.Period(<span class="string">&#x27;2017Q2&#x27;</span>, freq=<span class="string">&#x27;Q&#x27;</span>), freq=<span class="string">&#x27;M&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="时间差-timedeltaindex">时间差 TimedeltaIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.TimedeltaIndex(data =[<span class="string">&#x27;06:05:01.000030&#x27;</span>, <span class="string">&#x27;+23:59:59.999999&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;22 day 2 min 3us 10ns&#x27;</span>, <span class="string">&#x27;+23:29:59.999999&#x27;</span>,</span><br><span class="line">                         <span class="string">&#x27;+12:19:59.999999&#x27;</span>])</span><br><span class="line"><span class="comment"># 使用 datetime</span></span><br><span class="line">pd.TimedeltaIndex([<span class="string">&#x27;1 days&#x27;</span>, <span class="string">&#x27;1 days, 00:00:05&#x27;</span>,</span><br><span class="line">                   np.timedelta64(<span class="number">2</span>, <span class="string">&#x27;D&#x27;</span>),</span><br><span class="line">                   datetime.timedelta(days=<span class="number">2</span>, seconds=<span class="number">2</span>)])</span><br></pre></td></tr></table></figure>
<h3 id="周期索引-periodindex">周期索引 PeriodIndex</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">t = pd.period_range(<span class="string">&#x27;2020-5-1 10:00:05&#x27;</span>, periods=<span class="number">8</span>, freq=<span class="string">&#x27;S&#x27;</span>)</span><br><span class="line">pd.PeriodIndex(t,freq=<span class="string">&#x27;S&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="索引对象">索引对象</h2>
<p>行和列的索引在 Pandas 里其实是一个 <code>Index</code> 对象，以下是创建一个 <code>index</code> 对象的方法：</p>
<h3 id="创建对象">创建对象</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.Index([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># Int64Index([1, 2, 3], dtype=&#x27;int64&#x27;)</span></span><br><span class="line">pd.Index(list(<span class="string">&#x27;abc&#x27;</span>))</span><br><span class="line"><span class="comment"># Index([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line"><span class="comment"># 可以定义一相 name</span></span><br><span class="line">pd.Index([<span class="string">&#x27;e&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;b&#x27;</span>], name=<span class="string">&#x27;something&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看">查看</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.index</span><br><span class="line"><span class="comment"># RangeIndex(start=0, stop=4, step=1)</span></span><br><span class="line">df.columns</span><br><span class="line"><span class="comment"># Index([&#x27;month&#x27;, &#x27;year&#x27;, &#x27;sale&#x27;], dtype=&#x27;object&#x27;)</span></span><br></pre></td></tr></table></figure>
<h3 id="属性">属性</h3>
<p>以下方法也适用于 <code>df.columns</code>, 因为都是 index 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 属性</span></span><br><span class="line">df.index.name <span class="comment"># 名称</span></span><br><span class="line">df.index.array <span class="comment"># array 数组</span></span><br><span class="line">df.index.dtype <span class="comment"># 数据类型</span></span><br><span class="line">df.index.shape <span class="comment"># 形状</span></span><br><span class="line">df.index.size <span class="comment"># 元素数量</span></span><br><span class="line">df.index.values <span class="comment"># array 数组</span></span><br><span class="line"><span class="comment"># 其他，不常用</span></span><br><span class="line">df.index.empty <span class="comment"># 是否为空</span></span><br><span class="line">df.index.is_unique <span class="comment"># 是否不重复</span></span><br><span class="line">df.index.names <span class="comment"># 名称列表</span></span><br><span class="line">df.index.is_all_dates <span class="comment"># 是否全是日期时间</span></span><br><span class="line">df.index.has_duplicates <span class="comment"># 是否有重复值</span></span><br><span class="line">df.index.values <span class="comment"># 索引的值 array</span></span><br></pre></td></tr></table></figure>
<h3 id="操作">操作</h3>
<p>以下方法也适用于 <code>df.columns</code>, 因为都是 index 对象：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 方法</span></span><br><span class="line">df.index.astype(<span class="string">&#x27;int64&#x27;</span>) <span class="comment"># 转换类型</span></span><br><span class="line">df.index.isin() <span class="comment"># 是否存在，见下方示例</span></span><br><span class="line">df.index.rename(<span class="string">&#x27;number&#x27;</span>) <span class="comment"># 修改索引名称</span></span><br><span class="line">df.index.nunique() <span class="comment"># 不重复值的数量</span></span><br><span class="line">df.index.sort_values(ascending=<span class="literal">False</span>,) <span class="comment"># 排序,倒序</span></span><br><span class="line">df.index.map(<span class="keyword">lambda</span> x:x+<span class="string">&#x27;_&#x27;</span>) <span class="comment"># map 函数处理</span></span><br><span class="line">df.index.str.replace(<span class="string">&#x27;_&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="comment"># str 替换</span></span><br><span class="line">df.index.str.split(<span class="string">&#x27;_&#x27;</span>) <span class="comment"># 分隔</span></span><br><span class="line">df.index.to_list() <span class="comment"># 转为列表</span></span><br><span class="line">df.index.to_frame(index=<span class="literal">False</span>, name=<span class="string">&#x27;a&#x27;</span>) <span class="comment"># 转成 DataFrame</span></span><br><span class="line">df.index.to_series() <span class="comment"># 转 series</span></span><br><span class="line">df.index.to_numpy() <span class="comment"># 转为 numpy</span></span><br><span class="line">df.index.unique() <span class="comment"># 去重</span></span><br><span class="line">df.index.value_counts() <span class="comment"># 去重及数量</span></span><br><span class="line">df.index.where(df.index==<span class="string">&#x27;a&#x27;</span>) <span class="comment"># 筛选</span></span><br><span class="line">df.index.rename(<span class="string">&#x27;grade&#x27;</span>, inplace=<span class="literal">False</span>) <span class="comment"># 重命名索引名称</span></span><br><span class="line">df.index.rename([<span class="string">&#x27;species&#x27;</span>, <span class="string">&#x27;year&#x27;</span>]) <span class="comment"># 多层，重命名索引名称</span></span><br><span class="line">df.index.max() <span class="comment"># 最大值</span></span><br><span class="line">df.index.argmax() <span class="comment"># 最大索引值</span></span><br><span class="line">df.index.any()</span><br><span class="line">df.index.all()</span><br><span class="line">df.index.T <span class="comment"># 转置，多层索引里很有用</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其他，不常用</span></span><br><span class="line">df.index.append(pd.Index([<span class="number">4</span>,<span class="number">5</span>])) <span class="comment"># 追加</span></span><br><span class="line">df.index.repeat(<span class="number">2</span>) <span class="comment"># 重复几次</span></span><br><span class="line">df.index.inferred_type <span class="comment"># 推测数据类型</span></span><br><span class="line">df.index.hasnans <span class="comment"># 有没有空值</span></span><br><span class="line">df.index.is_monotonic_decreasing <span class="comment"># 是否单调递减</span></span><br><span class="line">df.index.is_monotonic <span class="comment"># 是否单调递增</span></span><br><span class="line">df.index.is_monotonic_increasing <span class="comment"># 是否单调递增</span></span><br><span class="line">df.index.nbytes <span class="comment"># 基础数据中的字节数</span></span><br><span class="line">df.index.ndim <span class="comment"># 维度数，维数</span></span><br><span class="line">df.index.nlevels <span class="comment"># 索引层级数，通常为 1</span></span><br><span class="line">df.index.min() <span class="comment"># 最小值</span></span><br><span class="line">df.index.argmin() <span class="comment"># 最小索引值</span></span><br><span class="line">df.index.argsort() <span class="comment"># 顺序值组成的数组</span></span><br><span class="line">df.index.asof(<span class="number">2</span>) <span class="comment"># 返回最近的索引</span></span><br><span class="line"><span class="comment"># numpy dtype or pandas type</span></span><br><span class="line">df.index.astype(<span class="string">&#x27;int64&#x27;</span>, copy=<span class="literal">True</span>) <span class="comment"># 深拷贝</span></span><br><span class="line"><span class="comment"># 拷贝</span></span><br><span class="line">df.index.copy(name=<span class="string">&#x27;new&#x27;</span>, deep=<span class="literal">True</span>, dtype=<span class="string">&#x27;int64&#x27;</span>)</span><br><span class="line">df.index.delete(<span class="number">1</span>) <span class="comment"># 删除指定位置</span></span><br><span class="line"><span class="comment"># 对比不同</span></span><br><span class="line">df.index.difference(pd.Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>]), sort=<span class="literal">False</span>)</span><br><span class="line">df.index.drop(<span class="string">&#x27;a&#x27;</span>, errors=<span class="string">&#x27;ignore&#x27;</span>) <span class="comment"># 删除</span></span><br><span class="line">df.index.drop_duplicates(keep=<span class="string">&#x27;first&#x27;</span>) <span class="comment"># 去重值</span></span><br><span class="line">df.index.droplevel(<span class="number">0</span>) <span class="comment"># 删除层级</span></span><br><span class="line">df.index.dropna(how=<span class="string">&#x27;all&#x27;</span>) <span class="comment"># 删除空值</span></span><br><span class="line">df.index.duplicated(keep=<span class="string">&#x27;first&#x27;</span>) <span class="comment"># 重复值在结果数组中为True</span></span><br><span class="line">df.index.equals(df.index) <span class="comment"># 与另外一个索引对象是否相同</span></span><br><span class="line">df.index.factorize() <span class="comment"># 分解成（array:0-n, Index）</span></span><br><span class="line">df.index.fillna(<span class="number">0</span>, &#123;<span class="number">0</span>:<span class="string">&#x27;nan&#x27;</span>&#125;) <span class="comment"># 填充空值</span></span><br><span class="line"><span class="comment"># 字符列表, 把 name 值加在第一位, 每个值加10</span></span><br><span class="line">df.index.format(name=<span class="literal">True</span>, formatter=<span class="keyword">lambda</span> x:x+<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回一个 array, 指定值的索引位数组，不在的为 -1</span></span><br><span class="line">df.index.get_indexer([<span class="number">2</span>,<span class="number">9</span>])</span><br><span class="line"><span class="comment"># 获取 指定层级 Index 对象</span></span><br><span class="line">df.index.get_level_values(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 指定索引的位置，见示例</span></span><br><span class="line">df.index.get_loc(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">df.index.insert(<span class="number">2</span>, <span class="string">&#x27;f&#x27;</span>) <span class="comment"># 在索引位 2 插入 f</span></span><br><span class="line">df.index.intersection(df.index) <span class="comment"># 交集</span></span><br><span class="line">df.index.is_(df.index) <span class="comment"># 类似 is 检查</span></span><br><span class="line">df.index.is_categorical() <span class="comment"># 是否分类数据</span></span><br><span class="line">df.index.is_type_compatible(df.index) <span class="comment"># 类型是否兼容</span></span><br><span class="line">df.index.is_type_compatible(<span class="number">1</span>) <span class="comment"># 类型是否兼容</span></span><br><span class="line"></span><br><span class="line">df.index.isna() <span class="comment"># array 是否为空</span></span><br><span class="line">df.index.isnull() <span class="comment"># array 是否缺失值</span></span><br><span class="line">df.index.join(df.index, how=<span class="string">&#x27;left&#x27;</span>) <span class="comment"># 连接</span></span><br><span class="line">df.index.notna() <span class="comment"># 是否不存在的值</span></span><br><span class="line">df.index.notnull() <span class="comment"># 是否不存在的值</span></span><br><span class="line">df.index.ravel() <span class="comment"># 展平值的ndarray</span></span><br><span class="line">df.index.reindex([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>]) <span class="comment"># 新索引 (Index,array:0-n)</span></span><br><span class="line">df.index.searchsorted(<span class="string">&#x27;f&#x27;</span>) <span class="comment"># 如果插入这个值排序后在哪个索引位</span></span><br><span class="line">df.index.searchsorted([<span class="number">0</span>, <span class="number">4</span>]) <span class="comment"># array([0, 3]) 多个</span></span><br><span class="line">df.index.set_names(<span class="string">&#x27;quarter&#x27;</span>) <span class="comment"># 设置索引名称</span></span><br><span class="line">df.index.set_names(<span class="string">&#x27;species&#x27;</span>, level=<span class="number">0</span>)</span><br><span class="line">df.index.set_names([<span class="string">&#x27;kind&#x27;</span>, <span class="string">&#x27;year&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">df.index.shift(<span class="number">10</span>, freq=<span class="string">&#x27;D&#x27;</span>) <span class="comment"># 日期索引向前移动 10 天</span></span><br><span class="line">idx1.symmetric_difference(idx2) <span class="comment"># 两个索引不同的内容</span></span><br><span class="line">idx1.union(idx2) <span class="comment"># 拼接</span></span><br><span class="line"></span><br><span class="line">df.add_prefix(<span class="string">&#x27;t_&#x27;</span>) <span class="comment"># 表头加前缀</span></span><br><span class="line">df.add_suffix(<span class="string">&#x27;_d&#x27;</span>) <span class="comment"># 表头加后缀</span></span><br><span class="line">df.first_valid_index() <span class="comment"># 第一个有值的索引</span></span><br><span class="line">df.last_valid_index() <span class="comment"># 最后一个有值的索引</span></span><br></pre></td></tr></table></figure>
<h2 id="索引重命名">索引重命名</h2>
<p>对行和列的索引名进行修改。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一一对应修改列索引</span></span><br><span class="line">df.rename(columns=&#123;<span class="string">&quot;A&quot;</span>: <span class="string">&quot;a&quot;</span>, <span class="string">&quot;B&quot;</span>: <span class="string">&quot;c&quot;</span>&#125;)</span><br><span class="line">df.rename(str.lower, axis=<span class="string">&#x27;columns&#x27;</span>)</span><br><span class="line"><span class="comment"># 修改行索引</span></span><br><span class="line">df.rename(index=&#123;<span class="number">0</span>: <span class="string">&quot;x&quot;</span>, <span class="number">1</span>: <span class="string">&quot;y&quot;</span>, <span class="number">2</span>: <span class="string">&quot;z&quot;</span>&#125;)</span><br><span class="line">df.rename(&#123;<span class="number">1</span>: <span class="number">2</span>, <span class="number">2</span>: <span class="number">4</span>&#125;, axis=<span class="string">&#x27;index&#x27;</span>)</span><br><span class="line"><span class="comment"># 修改数据类型</span></span><br><span class="line">df.rename(index=str)</span><br><span class="line"><span class="comment"># 重新修改索引</span></span><br><span class="line">replacements = &#123;l1:l2 <span class="keyword">for</span> l1, l2 <span class="keyword">in</span> zip(list1, list2)&#125;</span><br><span class="line">df.rename(replacements)</span><br></pre></td></tr></table></figure>
<h2 id="索引名重命名">索引名重命名</h2>
<p>注意，这是修改索引的名称，不是索引或者列名本身：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.rename_axis(<span class="string">&quot;animal&quot;</span>) <span class="comment"># 索引重命名</span></span><br><span class="line">df.rename_axis([<span class="string">&quot;dow&quot;</span>, <span class="string">&quot;hr&quot;</span>]) <span class="comment"># 多层索引索引名修改</span></span><br><span class="line">df.rename_axis(<span class="string">&#x27;info&#x27;</span>, axis=<span class="string">&quot;columns&quot;</span>) <span class="comment"># 修改行索引名</span></span><br><span class="line"><span class="comment"># 修改多层列索引名</span></span><br><span class="line">df.rename_axis(index=&#123;<span class="string">&#x27;a&#x27;</span>: <span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;B&#x27;</span>&#125;)</span><br><span class="line"><span class="comment"># 修改多层列行索引名</span></span><br><span class="line">df.rename_axis(columns=&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;s_name&#x27;</span>, <span class="string">&#x27;b&#x27;</span>: <span class="string">&#x27;B&#x27;</span>&#125;)</span><br><span class="line">df.rename_axis(columns=str.upper) <span class="comment"># 行索引名变大写</span></span><br></pre></td></tr></table></figure>
<h2 id="部分示例">部分示例</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># idx.isin() 是否存在</span></span><br><span class="line">idx = pd.Index([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">df.index.isin(idx)</span><br><span class="line"><span class="comment"># array([False, False, False, False])</span></span><br><span class="line">df.index.isin([<span class="string">&#x27;a&#x27;</span>,<span class="string">&#x27;b&#x27;</span>])</span><br><span class="line"><span class="comment"># array([ True,  True, False, False])</span></span><br><span class="line">midx = pd.MultiIndex.from_arrays([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],</span><br><span class="line">                                 [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>]],</span><br><span class="line">                                 names=(<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;color&#x27;</span>))</span><br><span class="line">midx.isin([(<span class="number">1</span>, <span class="string">&#x27;red&#x27;</span>), (<span class="number">3</span>, <span class="string">&#x27;red&#x27;</span>)])</span><br><span class="line"><span class="comment"># array([ True, False, False])</span></span><br><span class="line">dates = [<span class="string">&#x27;2000-03-11&#x27;</span>, <span class="string">&#x27;2000-03-12&#x27;</span>, <span class="string">&#x27;2000-03-13&#x27;</span>]</span><br><span class="line">dti = pd.to_datetime(dates)</span><br><span class="line">dti.isin([<span class="string">&#x27;2000-03-11&#x27;</span>])</span><br><span class="line"><span class="comment"># array([ True, False, False])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i.argsort() 排序</span></span><br><span class="line"><span class="comment"># 将对索引进行排序的整数索引，见下文示例</span></span><br><span class="line">idx = pd.Index([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;c&#x27;</span>])</span><br><span class="line">order = idx.argsort() <span class="comment"># array([1, 0, 3, 2])</span></span><br><span class="line">idx[order] <span class="comment"># Index([&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;], dtype=&#x27;object&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># i.asof(2) 返回最近的索引, 支持日期，可实现找最近日期</span></span><br><span class="line"><span class="comment"># 从索引中返回标签；如果不存在，则返回前一个标签</span></span><br><span class="line">idx2 = pd.Index([<span class="number">1</span>,<span class="number">3</span>,<span class="number">6</span>])</span><br><span class="line">idx2.asof(<span class="number">5</span>) <span class="comment"># 3</span></span><br><span class="line">idx2.asof(<span class="number">6</span>) <span class="comment"># 5</span></span><br><span class="line">idx2.asof(<span class="number">-1</span>) <span class="comment"># nan</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># index.get_loc 指定索引的位置，见示例</span></span><br><span class="line">unique_index = pd.Index(list(<span class="string">&#x27;abc&#x27;</span>))</span><br><span class="line">unique_index.get_loc(<span class="string">&#x27;b&#x27;</span>) <span class="comment"># 1</span></span><br><span class="line">monotonic_index = pd.Index(list(<span class="string">&#x27;abbc&#x27;</span>))</span><br><span class="line">monotonic_index.get_loc(<span class="string">&#x27;b&#x27;</span>) <span class="comment"># slice(1, 3, None)</span></span><br><span class="line">non_monotonic_index = pd.Index(list(<span class="string">&#x27;abcb&#x27;</span>))</span><br><span class="line">non_monotonic_index.get_loc(<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="comment"># array([False,  True, False,  True], dtype=bool)</span></span><br></pre></td></tr></table></figure>
<h1 id="查询与修改">查询与修改</h1>
<h2 id="数据检查">数据检查</h2>
<p>我们一拿到数据需要对数据有一个抽查，一方面是了解数据结构，另一方面随机检查一下数据的质量问题。常用的：</p>
<table>
<thead>
<tr class="header">
<th>语法</th>
<th>操作</th>
<th>返回结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>df.head(n)</code></td>
<td>查看 DataFrame 对象的前n行</td>
<td>DataFrame</td>
</tr>
<tr class="even">
<td><code>df.tail(n)</code></td>
<td>查看 DataFrame 对象的最后n行</td>
<td>DataFrame</td>
</tr>
<tr class="odd">
<td><code>df.sample(n)</code></td>
<td>查看 n 个样本，随机</td>
<td>DataFrame</td>
</tr>
</tbody>
</table>
<p>以上都是选择整行。</p>
<h3 id="查看头部-df.head">查看头部 df.head()</h3>
<p>每次加载数据后一般需要看一下头部数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line">out:</span><br><span class="line">    name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">0</span>  Liver    E  <span class="number">89</span>  <span class="number">21</span>  <span class="number">24</span>  <span class="number">64</span></span><br><span class="line"><span class="number">1</span>   Arry    C  <span class="number">36</span>  <span class="number">37</span>  <span class="number">37</span>  <span class="number">57</span></span><br><span class="line"><span class="number">2</span>    Ack    A  <span class="number">57</span>  <span class="number">60</span>  <span class="number">18</span>  <span class="number">84</span></span><br><span class="line"><span class="number">3</span>  Eorge    C  <span class="number">93</span>  <span class="number">96</span>  <span class="number">71</span>  <span class="number">78</span></span><br><span class="line"><span class="number">4</span>    Oah    D  <span class="number">65</span>  <span class="number">49</span>  <span class="number">61</span>  <span class="number">86</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.head(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看尾部-df.tail">查看尾部 df.tail()</h3>
<p>查看最后的尾部数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.head()</span><br><span class="line">out:</span><br><span class="line">        name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">95</span>   Gabriel    C  <span class="number">48</span>  <span class="number">59</span>  <span class="number">87</span>  <span class="number">74</span></span><br><span class="line"><span class="number">96</span>   Austin7    C  <span class="number">21</span>  <span class="number">31</span>  <span class="number">30</span>  <span class="number">43</span></span><br><span class="line"><span class="number">97</span>  Lincoln4    C  <span class="number">98</span>  <span class="number">93</span>   <span class="number">1</span>  <span class="number">20</span></span><br><span class="line"><span class="number">98</span>       Eli    E  <span class="number">11</span>  <span class="number">74</span>  <span class="number">58</span>  <span class="number">91</span></span><br><span class="line"><span class="number">99</span>       Ben    E  <span class="number">21</span>  <span class="number">43</span>  <span class="number">41</span>  <span class="number">74</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.tail(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<h3 id="查看样本-df.sample">查看样本 df.sample()</h3>
<p><code>df.sample()</code> 会随机返回一条样本数据。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.sample()</span><br><span class="line">out:</span><br><span class="line">     name team  Q1  Q2  Q3  Q4</span><br><span class="line"><span class="number">79</span>  Tyler    A  <span class="number">75</span>  <span class="number">16</span>  <span class="number">44</span>  <span class="number">63</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可指定数量</span></span><br><span class="line">df.sample(<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<p>数据截取：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 去掉索引之前和之后的数据</span></span><br><span class="line">df.truncate(before=<span class="number">2</span>, after=<span class="number">4</span>) <span class="comment"># 只要索引 2-4</span></span><br><span class="line">s.truncate(before=<span class="string">&quot;60&quot;</span>, after=<span class="string">&quot;66&quot;</span>)</span><br><span class="line">df.truncate(before=<span class="string">&quot;A&quot;</span>, after=<span class="string">&quot;B&quot;</span>, axis=<span class="string">&quot;columns&quot;</span>) <span class="comment"># 选取列</span></span><br></pre></td></tr></table></figure>
<h2 id="操作列">操作列</h2>
<p>以下两种方法都可以代表一列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># 会返回本列的 Series</span></span><br><span class="line">df.name</span><br><span class="line">df.Q1</span><br><span class="line"><span class="comment"># df.1Q 即使列名叫 1Q 也无法使用</span></span><br><span class="line"><span class="comment"># df.my name 有空格也无法调用，可以处理加上下划线</span></span><br></pre></td></tr></table></figure>
<p>注意，当列名为一个合法的 python 变量时可以直接作为属性去使用。</p>
<h2 id="选择行列部分">选择行列部分</h2>
<p>有时我们需要按条件选择部分列、部分行，一般常用的有：</p>
<table>
<thead>
<tr class="header">
<th>操作</th>
<th>语法</th>
<th>返回结果</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>选择列</td>
<td><code>df[col]</code></td>
<td>Series</td>
</tr>
<tr class="even">
<td>按索引选择行</td>
<td><code>df.loc[label]</code></td>
<td>Series</td>
</tr>
<tr class="odd">
<td>按数字索引选择行</td>
<td><code>df.iloc[loc]</code></td>
<td>Series</td>
</tr>
<tr class="even">
<td>使用切片选择行</td>
<td><code>df[5:10]</code></td>
<td>DataFrame</td>
</tr>
<tr class="odd">
<td>用表达式筛选行</td>
<td><code>df[bool_vec]</code></td>
<td>DataFrame</td>
</tr>
</tbody>
</table>
<p>接下来我们将重点介绍一下这些查询的方法。</p>
<h2 id="切片">切片 []</h2>
<p>我们可以像列表那样利用切片功能选择部分行的数据，但是不支持索引一条：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[:<span class="number">2</span>] <span class="comment"># 前两行数据</span></span><br><span class="line">df[<span class="number">4</span>:<span class="number">10</span>]</span><br><span class="line">df[:] <span class="comment"># 所有数据，一般没这么用的</span></span><br><span class="line">df[:<span class="number">10</span>:<span class="number">2</span>] <span class="comment"># 按步长取</span></span><br><span class="line">s[::<span class="number">-1</span>] <span class="comment"># 反转顺序</span></span><br></pre></td></tr></table></figure>
<p>也可以选择列：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># 只要一列，Series</span></span><br><span class="line">df[[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 选择两列</span></span><br><span class="line">df[[<span class="string">&#x27;name&#x27;</span>]] <span class="comment"># 选择一列，返回 DataFrame，注意和上例区别</span></span><br></pre></td></tr></table></figure>
<h2 id="按标签-.loc">按标签 .loc</h2>
<p><code>df.loc()</code> 的格式为 df.loc[<索引表达式>, <列表达式>]，表达式支持以下形式：</列表达式></索引表达式></p>
<p>单个标签:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 代表索引，如果是字符需要加引号</span></span><br><span class="line">df.loc[<span class="number">0</span>] <span class="comment"># 选择索引为 0 的行</span></span><br><span class="line">df.loc[<span class="number">8</span>]</span><br></pre></td></tr></table></figure>
<p>单个列表标签：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[[<span class="number">0</span>,<span class="number">5</span>,<span class="number">10</span>]] <span class="comment"># 指定索引 0，5，10 的行</span></span><br><span class="line">df.loc[[<span class="string">&#x27;Eli&#x27;</span>, <span class="string">&#x27;Ben&#x27;</span>]] <span class="comment"># 如果索引是 name</span></span><br><span class="line"><span class="comment"># 真假选择，长度要和索引一样</span></span><br><span class="line">df.loc[[<span class="literal">False</span>, <span class="literal">True</span>]*<span class="number">50</span>] <span class="comment"># 为真的列显示，隔一个显示一个</span></span><br></pre></td></tr></table></figure>
<p>带标签的切片（包括起始和停止）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[<span class="number">0</span>:<span class="number">5</span>] <span class="comment"># 索引切片, 代表0-5行，包括5</span></span><br><span class="line">df.loc[<span class="string">&#x27;2010&#x27;</span>:<span class="string">&#x27;2014&#x27;</span>] <span class="comment"># 如果索引是时间可以用字符查询</span></span><br><span class="line">df.loc[:] <span class="comment"># 所有</span></span><br><span class="line"><span class="comment"># 本方法支持 Series</span></span><br></pre></td></tr></table></figure>
<p>列筛选，必须有行筛选：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dft.loc[:, [<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 所有行，Q1 和 Q2两列</span></span><br><span class="line">dft.loc[:, [<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]] <span class="comment"># 所有行，Q1 和 Q2两列</span></span><br><span class="line">dft.loc[:<span class="number">10</span>, <span class="string">&#x27;Q1&#x27;</span>:] <span class="comment"># 0-10 行，Q1后边的所有列</span></span><br></pre></td></tr></table></figure>
<h2 id="按位置-.iloc">按位置 .iloc</h2>
<p><code>df.iloc</code> 与 <code>df.loc</code> 相似，但只能用自然索引（行和列的 0 - n 索引），不能用标签。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iloc[:<span class="number">3</span>]</span><br><span class="line">df.iloc[:]</span><br><span class="line">df.iloc[<span class="number">2</span>:<span class="number">20</span>:<span class="number">3</span>]</span><br><span class="line">s.iloc[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<h2 id="取具体值-.at">取具体值 .at</h2>
<p>类似于 loc, 但仅取一个具体的值，结构为 at[<索引>,<列名>]：</列名></索引></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 注：索引是字符需要加引号</span></span><br><span class="line">df.at[<span class="number">4</span>, <span class="string">&#x27;Q1&#x27;</span>] <span class="comment"># 65</span></span><br><span class="line">df.at[<span class="string">&#x27;lily&#x27;</span>, <span class="string">&#x27;Q1&#x27;</span>] <span class="comment"># 65 假定索引是 name</span></span><br><span class="line">df.at[<span class="number">0</span>, <span class="string">&#x27;name&#x27;</span>] <span class="comment"># &#x27;Liver&#x27;</span></span><br><span class="line">df.loc[<span class="number">0</span>].at[<span class="string">&#x27;name&#x27;</span>] <span class="comment"># &#x27;Liver&#x27;</span></span><br><span class="line"><span class="comment"># 指定列的值对应其他列的值</span></span><br><span class="line">df.set_index(<span class="string">&#x27;name&#x27;</span>).at[<span class="string">&#x27;Eorge&#x27;</span>, <span class="string">&#x27;team&#x27;</span>] <span class="comment"># &#x27;C&#x27;</span></span><br><span class="line">df.set_index(<span class="string">&#x27;name&#x27;</span>).team.at[<span class="string">&#x27;Eorge&#x27;</span>] <span class="comment"># &#x27;C&#x27;</span></span><br><span class="line"><span class="comment"># 指定列的对应索引的值</span></span><br><span class="line">df.team.at[<span class="number">3</span>] <span class="comment"># &#x27;C&#x27;</span></span><br></pre></td></tr></table></figure>
<p>同样 iat 和 iloc 一样，仅支持数字索引：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.iat[<span class="number">4</span>, <span class="number">2</span>] <span class="comment"># 65</span></span><br><span class="line">df.loc[<span class="number">0</span>].iat[<span class="number">1</span>] <span class="comment"># &#x27;E&#x27;</span></span><br></pre></td></tr></table></figure>
<p>.get 可以做类似字典的操作，如果无值给返回默认值（例中是0）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.get(<span class="string">&#x27;name&#x27;</span>, <span class="number">0</span>) <span class="comment"># 是 name 列</span></span><br><span class="line">df.get(<span class="string">&#x27;nameXXX&#x27;</span>, <span class="number">0</span>) <span class="comment"># 0, 返回默认值</span></span><br><span class="line">s.get(<span class="number">3</span>, <span class="number">0</span>) <span class="comment"># 93, Series 传索引返回具体值</span></span><br><span class="line">df.name.get(<span class="number">99</span>, <span class="number">0</span>) <span class="comment"># &#x27;Ben&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="表达式筛选">表达式筛选</h2>
<p><code>[]</code> 切片里可以使用表达式进行筛选：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># Q1 等于8</span></span><br><span class="line">df[~(df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>)] <span class="comment"># 不等于8</span></span><br><span class="line">df[df.name == <span class="string">&#x27;Ben&#x27;</span>] <span class="comment"># 姓名为Ben</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] &gt; <span class="number">90</span>, <span class="string">&#x27;Q1&#x27;</span>:]  <span class="comment"># Q1 大于90，只显示 Q1</span></span><br><span class="line">df.loc[(df.Q1 &gt; <span class="number">80</span>) &amp; (df.Q2 &lt; <span class="number">15</span>)] <span class="comment"># and 关系</span></span><br><span class="line">df.loc[(df.Q1 &gt; <span class="number">90</span>) | (df.Q2 &lt; <span class="number">90</span>)] <span class="comment"># or 关系</span></span><br><span class="line">df[df.Q1 &gt; df.Q2]</span><br></pre></td></tr></table></figure>
<p><code>df.loc</code> 里的索引部分可以使用表达式进行数据筛选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># 等于8</span></span><br><span class="line">df.loc[df.Q1 == <span class="number">8</span>] <span class="comment"># 等于8</span></span><br><span class="line">df.loc[df[<span class="string">&#x27;Q1&#x27;</span>] &gt; <span class="number">90</span>, <span class="string">&#x27;Q1&#x27;</span>:] <span class="comment"># Q1 大于90，只显示 Q1</span></span><br><span class="line"><span class="comment"># 其他表达式与切片一致</span></span><br><span class="line"></span><br><span class="line">df.loc[:, <span class="keyword">lambda</span> df: df.columns.str.len()==<span class="number">4</span>] <span class="comment"># 真假组成的序列</span></span><br><span class="line">df.loc[:, <span class="keyword">lambda</span> df: [i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> <span class="string">&#x27;Q&#x27;</span> <span class="keyword">in</span> i]] <span class="comment"># 列名列表</span></span><br><span class="line">df.iloc[:<span class="number">3</span>, <span class="keyword">lambda</span> df: df.columns.str.len()==<span class="number">2</span>] <span class="comment"># 真假组成的序列</span></span><br></pre></td></tr></table></figure>
<p>逻辑判断和函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.eq() <span class="comment"># 等于相等 ==</span></span><br><span class="line">df.ne() <span class="comment"># 不等于 !=</span></span><br><span class="line">df.le() <span class="comment"># 小于等于 &gt;=</span></span><br><span class="line">df.lt() <span class="comment"># 小于 &lt;</span></span><br><span class="line">df.ge() <span class="comment"># 大于等于 &gt;=</span></span><br><span class="line">df.gt() <span class="comment"># 大于 &gt;</span></span><br><span class="line"><span class="comment"># 都支持  axis&#123;0 or ‘index’, 1 or ‘columns’&#125;, default ‘columns’</span></span><br><span class="line">df[df.Q1.ne(<span class="number">89</span>)] <span class="comment"># Q1 不等于8</span></span><br><span class="line">df.loc[df.Q1.gt(<span class="number">90</span>) &amp; df.Q2.lt(<span class="number">90</span>)] <span class="comment"># and 关系 Q1&gt;90 Q2&lt;90</span></span><br></pre></td></tr></table></figure>
<p>其他函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># isin</span></span><br><span class="line">df[df.team.isin([<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>])] <span class="comment"># 包含 AB 两组的</span></span><br><span class="line">df[df.isin(&#123;<span class="string">&#x27;team&#x27;</span>: [<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>], <span class="string">&#x27;Q1&#x27;</span>:[<span class="number">36</span>,<span class="number">93</span>]&#125;)] <span class="comment"># 复杂查询，其他值为 NaN</span></span><br></pre></td></tr></table></figure>
<h2 id="函数筛选">函数筛选</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="keyword">lambda</span> df: df[<span class="string">&#x27;Q1&#x27;</span>] == <span class="number">8</span>] <span class="comment"># Q1为8的</span></span><br><span class="line">df.loc[<span class="keyword">lambda</span> df: df.Q1 == <span class="number">8</span>, <span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q2&#x27;</span>] <span class="comment"># Q1为8的, 显示 Q1 Q2</span></span><br></pre></td></tr></table></figure>
<h2 id="where-和-mask">where 和 mask</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s.where(s &gt; <span class="number">90</span>) <span class="comment"># 不符合条件的为 NaN</span></span><br><span class="line">s.where(s &gt; <span class="number">90</span>, <span class="number">0</span>) <span class="comment"># 不符合条件的为 0</span></span><br><span class="line"><span class="comment"># np.where, 大于80是真否则是假</span></span><br><span class="line">np.where(s&gt;<span class="number">80</span>, <span class="literal">True</span>, <span class="literal">False</span>)</span><br><span class="line">np.where(df.num&gt;=<span class="number">60</span>, <span class="string">&#x27;合格&#x27;</span>, <span class="string">&#x27;不合格&#x27;</span>)</span><br><span class="line"></span><br><span class="line">s.mask(s &gt; <span class="number">90</span>) <span class="comment"># 符合条件的为 NaN</span></span><br><span class="line">s.mask(s &gt; <span class="number">90</span>, <span class="number">0</span>) <span class="comment"># 符合条件的为 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 例：能被整除的显示，不能的显示相反数</span></span><br><span class="line">m = df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>] % <span class="number">3</span> == <span class="number">0</span></span><br><span class="line">df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>].where(m, -df.loc[:,<span class="string">&#x27;Q1&#x27;</span>:<span class="string">&#x27;Q4&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 行列相同数量，返回一个 array</span></span><br><span class="line">df.lookup([<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>], [<span class="string">&#x27;Q1&#x27;</span>,<span class="string">&#x27;Q2&#x27;</span>,<span class="string">&#x27;Q3&#x27;</span>]) <span class="comment"># array([36, 96, 61])</span></span><br><span class="line">df.lookup([<span class="number">1</span>], [<span class="string">&#x27;Q1&#x27;</span>]) <span class="comment"># array([36])</span></span><br></pre></td></tr></table></figure>
<h2 id="query">query</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.query(<span class="string">&#x27;Q1 &gt; Q2 &gt; 90&#x27;</span>) <span class="comment"># 直接写类型 sql where 语句</span></span><br><span class="line">df.query(<span class="string">&#x27;Q1 + Q2 &gt; 180&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 == Q2&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;(Q1&lt;50) &amp; (Q2&gt;40) and (Q3&gt;90)&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; Q2 &gt; Q3 &gt; Q4&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;team != &quot;C&quot;&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;team not in (&quot;E&quot;,&quot;A&quot;,&quot;B&quot;)&#x27;</span>)</span><br><span class="line"><span class="comment"># 对于名称中带有空格的列，可以使用反引号引起来</span></span><br><span class="line">df.query(<span class="string">&#x27;B == `team name`&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 支持传入变量，如：大于平均分40分的</span></span><br><span class="line">a = df.Q1.mean()</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; @a+40&#x27;</span>)</span><br><span class="line">df.query(<span class="string">&#x27;Q1 &gt; `Q2`+@a&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># df.eval() 用法与 df.query 类似</span></span><br><span class="line">df[df.eval(<span class="string">&quot;Q1 &gt; 90 &gt; Q3 &gt; 10&quot;</span>)]</span><br><span class="line">df[df.eval(<span class="string">&quot;Q1 &gt; `Q2`+@a&quot;</span>)]</span><br></pre></td></tr></table></figure>
<h2 id="filter">filter</h2>
<p>使用 filter 可以对行名和列名进行筛选。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.filter(items=[<span class="string">&#x27;Q1&#x27;</span>, <span class="string">&#x27;Q2&#x27;</span>]) <span class="comment"># 选择两列</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;Q&#x27;</span>, axis=<span class="number">1</span>) <span class="comment"># 列名包含Q的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;e$&#x27;</span>, axis=<span class="number">1</span>) <span class="comment"># 以 e 结尾的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;1$&#x27;</span>, axis=<span class="number">0</span>) <span class="comment"># 正则, 索引名包含1的</span></span><br><span class="line">df.filter(like=<span class="string">&#x27;2&#x27;</span>, axis=<span class="number">0</span>) <span class="comment"># 索引中有2的</span></span><br><span class="line"><span class="comment"># 索引中2开头列名有Q的</span></span><br><span class="line">df.filter(regex=<span class="string">&#x27;^2&#x27;</span>, axis=<span class="number">0</span>).filter(like=<span class="string">&#x27;Q&#x27;</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>上面两个来自于https://www.gairuo.com/</p>
<h1 id="合并与新增行列">合并与新增行列</h1>
<h2 id="新增列">新增列</h2>
<p>假设原始数据如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;num_legs&#x27;</span>: [<span class="number">4</span>, <span class="number">2</span>], <span class="string">&#x27;num_wings&#x27;</span>: [<span class="number">0</span>, <span class="number">2</span>]&#125;,</span><br><span class="line">                  index=[<span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;hawk&#x27;</span>])</span><br><span class="line">slen = len(df[<span class="string">&#x27;num_legs&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>1）直接赋值</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[<span class="string">&#x27;a&#x27;</span>] = pd.Series(np.random.randn(slen), index=df.index) <span class="comment"># index要记得添加</span></span><br><span class="line">df[<span class="string">&#x27;b&#x27;</span>] = <span class="literal">None</span> <span class="comment"># 添加一列值为None</span></span><br><span class="line">df[<span class="string">&#x27;c&#x27;</span>] = [<span class="number">2</span>, <span class="number">4</span>] <span class="comment"># 添加列表数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># c1和c3列的顺序是一样的， c2则与之相反，具体看下文</span></span><br><span class="line">df[<span class="string">&#x27;c1&#x27;</span>] = [<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>]</span><br><span class="line">df.index = [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">df[<span class="string">&#x27;c2&#x27;</span>] = pd.Series([<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>])</span><br><span class="line">df[<span class="string">&#x27;c3&#x27;</span>] = pd.Series([<span class="string">&#x27;no&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>], index=df.index)</span><br></pre></td></tr></table></figure>
<p>2）loc方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.loc[:,<span class="string">&#x27;d&#x27;</span>] = pd.Series(np.random.randn(slen), index=df.index)</span><br><span class="line">df.loc[:, <span class="string">&#x27;d&#x27;</span>] = [<span class="number">2</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>3）insert方法</p>
<p><em>insert方法使用的列名不能有重复值，连更新都不能</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.insert(len(df.columns), <span class="string">&#x27;e&#x27;</span>, pd.Series(np.random.randn(slen)), index=df.index)</span><br><span class="line">df.insert(len(df.columns), <span class="string">&#x27;ee&#x27;</span>, [<span class="number">1</span>,<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>4）assign方法</p>
<p>assign方法参数可以是Series、标量、列表，还可以同时添加多列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = df.assign(f=df.num_wings.mean())  <span class="comment"># 将num_wings这列的平均值作为新增列f的结果</span></span><br><span class="line">df = df.assign(A=df.num_wings.sum(), B=[<span class="number">1</span>,<span class="number">2</span>])  <span class="comment"># 新增列A和B</span></span><br></pre></td></tr></table></figure>
<p>5）concat方法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.concat([df, pd.Series([<span class="string">&#x27;yes&#x27;</span>, <span class="string">&#x27;yes&#x27;</span>]).rename(<span class="string">&#x27;t&#x27;</span>)], axis=<span class="number">1</span>) <span class="comment"># 增加列t</span></span><br></pre></td></tr></table></figure>
<p>注意点：</p>
<ul>
<li>每个方法的参数都可以是Series、标量、列表</li>
<li>insert方法中新增的列名不能跟已有的一样，即使更新刚刚新增的列也会出错</li>
<li><code>df['a']=pd.Series(['no', 'yes']</code>的index顺序如果被修改，默认是以Series的index为准，可以通过<code>index=df.index</code>来指定按照原始DataFrame的index顺序</li>
</ul>
<h2 id="新增行">新增行</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建空白DataFrame</span></span><br><span class="line">df = pd.DataFrame(columns=[<span class="string">&#x27;lib&#x27;</span>, <span class="string">&#x27;qty1&#x27;</span>, <span class="string">&#x27;qty2&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>1）使用loc</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    df.loc[i] = [np.random.randint(<span class="number">-1</span>, <span class="number">1</span>) <span class="keyword">for</span> n <span class="keyword">in</span> range(<span class="number">3</span>)]</span><br><span class="line">    <span class="comment"># df.loc[i] = 5 添加一条数据都为5的记录</span></span><br></pre></td></tr></table></figure>
<p>2）使用append</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.append(&#123;<span class="string">&#x27;lib&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;qty1&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;qty2&#x27;</span>: <span class="number">4</span>&#125;, ignore_index=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># append也可以直接添加DataFrame</span></span><br><span class="line">df2 = pd.DataFrame([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]], columns=[<span class="string">&#x27;lib&#x27;</span>, <span class="string">&#x27;qty1&#x27;</span>, <span class="string">&#x27;qty2&#x27;</span>])</span><br><span class="line">df.append(df2, ignore_index=<span class="literal">True</span>)  <span class="comment"># ignore_index设置为True，index将会忽略df2的index</span></span><br></pre></td></tr></table></figure>
<p>3）重新生成DataFrame</p>
<p>循环将要添加的数据以字典的形式保存到一个列表中，在用列表创建出DataFrame</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">row_list = [] </span><br><span class="line">input_rows = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]] <span class="comment"># 待插入数据</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> input_rows:</span><br><span class="line">    dict1 = dict(lib=row[<span class="number">0</span>], qty1=row[<span class="number">1</span>], qty2=row[<span class="number">2</span>]) <span class="comment"># 将数据转为字典</span></span><br><span class="line">    row_list.append(dict1) <span class="comment"># 保存到列表中</span></span><br><span class="line">df = pd.DataFrame(row_list)</span><br></pre></td></tr></table></figure>
<p>以上两个来源于https://amberwest.github.io/</p>
<h2 id="合并">合并</h2>
<h3 id="append-vs.-concat">append() Vs. concat()</h3>
<p>连接或者合并DataFrame的时候一般有两种方式：纵向和横向。听起来总是觉得有点迷迷糊糊的。通俗的解释就是，纵向就是把两个或多个DataFrame纵向（从上到下）连接到一个DataFrame当中，index和column有重复情况也不进行任何操作，就是粗暴的纵向拼接DataFrame。横向就是会考虑如果有相同的index的话就会把相同index上所有列的数据合并在一起了，简单点理解就是相当于使用Excel中的V-lookup在两张有相同id但不同数据的表中进行了数据的融合。连接与合并DataFrame的常用函数有两个<code>append()</code>,<code>concat()</code>还有<code>merge()</code>。其中append()只能进行纵向连接，而<code>concat()</code>和<code>merge()</code>可以进行both。<code>concat()</code>默认是进行纵向连接，也就是跟<code>append()</code>效果一样，如果想要使用<code>concat()</code>进行横向合并则需要在<code>concat()</code>中声明变量axis。默认值：<code>concat(axis=0)</code>纵向连接，<code>concat(axis=1)</code>横向合并。下面举几个例子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: print(population)</span><br><span class="line">|               | <span class="number">2010</span> Census Population |</span><br><span class="line">|---------------|------------------------|</span><br><span class="line">| Zip Code ZCTA |                        |</span><br><span class="line">| <span class="number">57538</span>         | <span class="number">322</span>                    |</span><br><span class="line">| <span class="number">59916</span>         | <span class="number">130</span>                    |</span><br><span class="line">| <span class="number">37660</span>         | <span class="number">40038</span>                  |</span><br><span class="line">| <span class="number">2860</span>          | <span class="number">45199</span>                  |</span><br><span class="line">In [<span class="number">4</span>]: print(unemployment)</span><br><span class="line">|       | unemployment | participants |</span><br><span class="line">|-------|--------------|--------------|</span><br><span class="line">| Zip   |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br></pre></td></tr></table></figure>
<p>以上为两个数据文件中数据的情况，下面讲举例说明append()和concat(axis=0)默认值对DataFrame纵向连接的结果，两种方式得到的结果是完全相同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: population.append(unemployment)</span><br><span class="line">Out[<span class="number">5</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | NaN                                              | <span class="number">34447.0</span>      | <span class="number">0.11</span>         |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">4800.0</span>       | <span class="number">0.02</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">42.0</span>         | <span class="number">0.33</span>         |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">4310.0</span>       | <span class="number">0.07</span>         |</span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: pd.concat([population, unemployment], axis=<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>  | NaN                                              | <span class="number">34447.0</span>      | <span class="number">0.11</span>         |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">4800.0</span>       | <span class="number">0.02</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">42.0</span>         | <span class="number">0.33</span>         |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">4310.0</span>       | <span class="number">0.07</span>         |</span><br></pre></td></tr></table></figure>
<p>这里我们可以看到zip邮编下的”2860”出现了两次。如果我们想把相同zip下两个DataFrame的数据信息合并，我们就得用到横向合并，concat()提供了一个非常方便的办法就是concat(axis=1)或者concat(axis=’columns’)就可以实现横向合并了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">7</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>)</span><br><span class="line">Out[<span class="number">17</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br></pre></td></tr></table></figure>
<h3 id="concat-vs.-merge">concat() Vs. merge()</h3>
<p>在上面说完了<code>concat()</code>和<code>append()</code>横向纵向的连接与合并之后，下面要说一下<code>concat()</code>和<code>merge()</code>的区别和关系。上面我们说了<code>concat()</code>和<code>merge()</code>都可以进行横纵向的合并，在用法上和输出结果上两者有一些区别。这里要引入join的概念。<code>concat()</code>的默认join方式是outer join，而<code>merge()</code>的默认join方式是inner join。另外<code>concat()</code>和<code>merge()</code>在合并DataFrame的时候还有一个重要的区别就是，<code>concat()</code>是通过index来合并的，而<code>merge()</code>是通过列明（column label ）来合并的，如果列名设置成为了index的话需要把用来合并列名的index去掉之后再进行合并，否则会出现KeyError错误提示找不到列名。下面继续使用population和unemployment两个DataFrame来进行相关展示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">1</span>]: print(population)</span><br><span class="line">|               | <span class="number">2010</span> Census Population |</span><br><span class="line">|---------------|------------------------|</span><br><span class="line">| Zip Code ZCTA |                        |</span><br><span class="line">| <span class="number">57538</span>         | <span class="number">322</span>                    |</span><br><span class="line">| <span class="number">59916</span>         | <span class="number">130</span>                    |</span><br><span class="line">| <span class="number">37660</span>         | <span class="number">40038</span>                  |</span><br><span class="line">| <span class="number">2860</span>          | <span class="number">45199</span>                  |</span><br><span class="line">In [<span class="number">2</span>]: print(unemployment)</span><br><span class="line">|       | unemployment | participants |</span><br><span class="line">|-------|--------------|--------------|</span><br><span class="line">| Zip   |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>) <span class="comment">#pd.concat(join=&#x27;outer&#x27;)默认值为outer</span></span><br><span class="line">Out[<span class="number">3</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">1097</span>  | NaN                                              | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">37660</span> | <span class="number">40038.0</span>                                          | NaN          | NaN          |</span><br><span class="line">| <span class="number">46167</span> | NaN                                              | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">57538</span> | <span class="number">322.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span> | <span class="number">130.0</span>                                            | NaN          | NaN          |</span><br><span class="line">| <span class="number">80808</span> | NaN                                              | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: pd.concat([population, unemployment], axis=<span class="number">1</span>, join=<span class="string">&#x27;inner&#x27;</span>) <span class="comment">#pd.concat(join=&#x27;outer&#x27;)默认值为outer，这里把join设置成了inner</span></span><br><span class="line">Out[<span class="number">4</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population participants unemployment | participants | unemployment |</span><br><span class="line">|-------|--------------------------------------------------|--------------|--------------|</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                                          | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br></pre></td></tr></table></figure>
<p>接下来是对相同df进行merge操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">5</span>]: population = pd.read_csv(<span class="string">&#x27;population_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">In [<span class="number">5</span>]: unemployment = pd.read_csv(<span class="string">&#x27;unemployment_00.csv&#x27;</span>, index_col=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#这里的导入我们还是设置了第一列ZipCode和Zip为各df的index，然后看一下使用merge()的时候会出现什么情况</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">5</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>)</span><br><span class="line">Out[<span class="number">5</span>]: KeyError: <span class="string">&quot;None of [&#x27;ZipCode&#x27;] are in the columns&quot;</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#因为ZipCode被设置成了index所以merge找不到该列名，无法进行merge，我们可以.reset_index()，或者在导入数据的时候不设置index就可以解决该问题。</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: population = population.reset_index()</span><br><span class="line">In [<span class="number">6</span>]: unemployment = unemployment.reset_index()</span><br><span class="line">In [<span class="number">6</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment">#pd.merge(how=&#x27;inner&#x27;)默认值为inner，merge()的合并方式参数是how不是join</span></span><br><span class="line"></span><br><span class="line">Out[<span class="number">6</span>]:</span><br><span class="line">|   | ZipCode | <span class="number">2010</span> Census Population | Zip  | Unemployment | Participants |</span><br><span class="line">|---|---------|------------------------|------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">2860</span>    | <span class="number">45199</span>                  | <span class="number">2860</span> | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line"></span><br><span class="line"><span class="comment">#merge的join和concat的join出来的结果会有一些不同，concat出来的df没有index，merge出来的df会有默认index和两个df合并的的列ZipCode和Zip</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">7</span>]: pd.merge(population, unemployment, left_on=<span class="string">&#x27;ZipCode&#x27;</span>, right_on=<span class="string">&#x27;Zip&#x27;</span>,</span><br><span class="line">               how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">Out[<span class="number">7</span>]: </span><br><span class="line">|   | ZipCode | <span class="number">2010</span> Census Population | Zip     | Unemployment | Participants |</span><br><span class="line">|---|---------|------------------------|---------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">57538.0</span> | <span class="number">322.0</span>                  | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">1</span> | <span class="number">59916.0</span> | <span class="number">130.0</span>                  | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">2</span> | <span class="number">37660.0</span> | <span class="number">40038.0</span>                | NaN     | NaN          | NaN          |</span><br><span class="line">| <span class="number">3</span> | <span class="number">2860.0</span>  | <span class="number">45199.0</span>                | <span class="number">2860.0</span>  | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">4</span> | NaN     | NaN                    | <span class="number">46167.0</span> | <span class="number">0.02</span>         | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">5</span> | NaN     | NaN                    | <span class="number">1097.0</span>  | <span class="number">0.33</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">6</span> | NaN     | NaN                    | <span class="number">80808.0</span> | <span class="number">0.07</span>         | <span class="number">4310.0</span>       |</span><br><span class="line"><span class="comment">#这里有点奇怪，ZipCode和Zip经过outer join之后变成了float类型。</span></span><br></pre></td></tr></table></figure>
<p>我暂且认为更改ZipCode和Zip的这个行为是个bug，并且已经提交给git了。可以看下之后的反馈：https://github.com/pandas-dev/pandas/issues/34017</p>
<p>当然还是有一些办法去解决这个问题，可是使用会concat()方法来进行合并，或者我们可以通过统一两个DataFrame邮编的label来使用on= [‘Zip’]来进行合并，实验表明通过on= [‘Zip’]进行合并不会出现上述问题：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">8</span>]: population.rename(columns=&#123;<span class="string">&#x27;ZipCode&#x27;</span>:<span class="string">&#x27;Zip&#x27;</span>&#125;, inplace=<span class="literal">True</span>) <span class="comment">#更改population中的column label</span></span><br><span class="line">In [<span class="number">8</span>]: merge_2 = pd.merge(population, unemployment, on=[<span class="string">&#x27;Zip&#x27;</span>], how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">print(merge_2)</span><br><span class="line">Out[<span class="number">8</span>]:</span><br><span class="line">|   | Zip   | <span class="number">2010</span> Census Population | Unemployment | Participants | Participants |</span><br><span class="line">|---|-------|------------------------|--------------|--------------|--------------|</span><br><span class="line">| <span class="number">0</span> | <span class="number">57538</span> | <span class="number">322.0</span>                  | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">1</span> | <span class="number">59916</span> | <span class="number">130.0</span>                  | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">2</span> | <span class="number">37660</span> | <span class="number">40038.0</span>                | NaN          | NaN          | NaN          |</span><br><span class="line">| <span class="number">3</span> | <span class="number">2860</span>  | <span class="number">45199.0</span>                | <span class="number">0.11</span>         | <span class="number">34447.0</span>      | <span class="number">34447.0</span>      |</span><br><span class="line">| <span class="number">4</span> | <span class="number">46167</span> | NaN                    | <span class="number">0.02</span>         | <span class="number">4800.0</span>       | <span class="number">4800.0</span>       |</span><br><span class="line">| <span class="number">5</span> | <span class="number">1097</span>  | NaN                    | <span class="number">0.33</span>         | <span class="number">42.0</span>         | <span class="number">42.0</span>         |</span><br><span class="line">| <span class="number">6</span> | <span class="number">80808</span> | NaN                    | <span class="number">0.07</span>         | <span class="number">4310.0</span>       | <span class="number">4310.0</span>       |</span><br></pre></td></tr></table></figure>
<h3 id="join-vs.-concat">join() Vs. concat()</h3>
<p>join有四种合并方法，分别是<code>how='left</code>‘, <code>how='right'</code>, <code>how='inner'</code>和<code>how='outer'</code>。当然这些合并方法<code>merge()</code>也是全部都有的。所以看到这里也应该对<code>append()</code>, <code>concat()</code>, <code>join()</code>和<code>merge()</code>有很充分的理解了。<code>merge()</code>是四个函数里面最强大的，但是在使用原则上来讲并不是每次对数据操作都要用<code>merge()</code>，有时候<code>append()</code>和<code>concat()</code>使用起来可能会更加方便，在最后会总结一下这四个函数的分类和原则。这里先看一下<code>join()</code>的实际操作：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">1</span>]: population.join(unemployment) <span class="comment">#join的默认合并方式是how=&#x27;left&#x27;</span></span><br><span class="line">Out[<span class="number">1</span>]:</span><br><span class="line">|         | <span class="number">2010</span> Census Population | unemployment | participants |</span><br><span class="line">|---------|------------------------|--------------|--------------|</span><br><span class="line">| ZipCode |                        |              |              |</span><br><span class="line">| <span class="number">57538</span>   | <span class="number">322</span>                    | NaN          | NaN          |</span><br><span class="line">| <span class="number">59916</span>   | <span class="number">130</span>                    | NaN          | NaN          |</span><br><span class="line">| <span class="number">37660</span>   | <span class="number">40038</span>                  | NaN          | NaN          |</span><br><span class="line">| <span class="number">2860</span>    | <span class="number">45199</span>                  | <span class="number">0.11</span>         | <span class="number">34447.0</span>      |</span><br></pre></td></tr></table></figure>
<p>df1.join(df2, how=’left’)的意思是指以左边的DataFrame为准进行合并，population在unemployment左边，所以这个合并就会以population的index也就是ZipCode为准进行合并。所以df1.join(df2, how=’right’)就会以unemployment的index进行合并：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: population.join(unemployment, how= <span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">Out[<span class="number">2</span>]:</span><br><span class="line">|       | <span class="number">2010</span> Census Population | unemployment | participants |</span><br><span class="line">|-------|------------------------|--------------|--------------|</span><br><span class="line">| Zip   |                        |              |              |</span><br><span class="line">| <span class="number">2860</span>  | <span class="number">45199.0</span>                | <span class="number">0.11</span>         | <span class="number">34447</span>        |</span><br><span class="line">| <span class="number">46167</span> | NaN                    | <span class="number">0.02</span>         | <span class="number">4800</span>         |</span><br><span class="line">| <span class="number">1097</span>  | NaN                    | <span class="number">0.33</span>         | <span class="number">42</span>           |</span><br><span class="line">| <span class="number">80808</span> | NaN                    | <span class="number">0.07</span>         | <span class="number">4310</span>         |</span><br></pre></td></tr></table></figure>
<p>join和concat都是要以index来进行合并，所以在合并时，必须要有对应的index。concat相比join缺少了left和right两种合并方式，但是在outer和inner合并方式来讲得到的结果是一模一样的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">population.join(unemployment, how=<span class="string">&#x27;outer&#x27;</span>)</span><br><span class="line">pd.concat([population, unemployment], join=<span class="string">&#x27;outer&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#以上两者结果相同</span></span><br><span class="line">population.join(unemployment, how=<span class="string">&#x27;inner&#x27;</span>)</span><br><span class="line">pd.concat([population, unemployment], join=<span class="string">&#x27;inner&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#以上两者结果相同</span></span><br></pre></td></tr></table></figure>
<h3 id="append-concat-join和merge总结">append(), concat(), join()和merge()总结</h3>
<h4 id="append">append()</h4>
<p>语法：<code>df1.append(df2)</code></p>
<p>说明：<code>append()</code>就是简单的把两个DataFrame纵向罗列起来，<strong>不需要index</strong>。</p>
<h4 id="concat">concat()</h4>
<p>语法：<code>pd.concat([df1, df2])</code></p>
<p>说明：<code>concat()</code>可以横纵向合并多行或者多列，可以使用inner或者outer方式来合并，<strong>需要index</strong>。</p>
<h4 id="join">join()</h4>
<p>语法：<code>df1.join(df2)</code></p>
<p>说明：<code>join()</code>可以使用多种合并方式，除了inner和outer之外还可以用left和right，这些操作同样<strong>需要index</strong>。</p>
<h4 id="merge">merge()</h4>
<p>语法：<code>pd.merge([df1, df2])</code></p>
<p>说明：方式最多的合并函数。<strong>不需要index。</strong></p>
<h3 id="merge_order函数">merge_order()函数</h3>
<p><code>merge_order()</code>函数可以用一个函数进行两个操作，即<code>merge()</code>和<code>sort_value()</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pd.merge_ordered(hardware, software, on=[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>], suffixes=[<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>]，fill_method=<span class="string">&#x27;ffill&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>来自于https://mingju.net/2020/05/merging-dataframes-with-pandas/</p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Annotated Bibliography 2020 11.30-12.6</title>
    <url>/posts/adc0cb59.html</url>
    <content><![CDATA[<p>重新加油</p>
<p>这周可以说是IOP专题了</p>
<a id="more"></a>
<h1 id="variations-of-light-absorption-by-suspended-particles-with-chlorophyll-a-concentration-in-oceanic-case-1-waters-analysis-and-implications-for-bio-optical-models"><a class="markdownIt-Anchor" href="#variations-of-light-absorption-by-suspended-particles-with-chlorophyll-a-concentration-in-oceanic-case-1-waters-analysis-and-implications-for-bio-optical-models"></a> Variations of light absorption by suspended particles with chlorophyll a concentration in oceanic (case 1) waters: Analysis and implications for bio-optical models</h1>
<p>This is a fairly old paper.</p>
<p>The importance of this paper for my research is these figures.</p>
<p>![image-00021201104954518](/Users/zhenjia/Library/Application Support/typora-user-images/image-00021201104954518.png)</p>
<p>Although the data is obtained from oceanic(case 1) water, but we can see that the range of chlorophyll is relative high. So the parameteration of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>p</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{ph}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> might also could be used for case 2 water.</p>
<p>This is the parameteration for <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>p</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{ph}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021201105305213.png" alt="image-00021201105305213"></p>
<p>Compared with former Bricaud 1995, the r2 is better.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/image-00021201105504185.png" alt="image-00021201105504185"></p>
<p>The author put the data here <span class="exturl" data-url="aHR0cHM6Ly9kb2kucGFuZ2FlYS5kZS8xMC4xNTk0L1BBTkdBRUEuNzM5ODc5">https://doi.pangaea.de/10.1594/PANGAEA.739879<i class="fa fa-external-link-alt"></i></span></p>
<p>But I use the data from herehttps://github.com/BrandonSmithJ/MDN/blob/abad4338f495f801b88a32c141b6639e7b7989ad/IOP/bricaud_1998_aph.txt</p>
<p>But when I tried this parameteratzation, this actually also produce some strange shape.</p>
<p><img src="https://raw.githubusercontent.com/lifeodyssey/Figurebed/master/Bricaud1998.png" alt="Bricaud1998"></p>
<p>I think this is not only the problem of QAA, because when I use in-situ chia, the aph shape is also strange.</p>
<p>I think the reparameterazation is needed.</p>
<h1 id="inversion-of-in-situ-light-absorption-and-attenuation-measurements-to-estimate-constituent-concentrations-in-optically-complex-shelf-seas"><a class="markdownIt-Anchor" href="#inversion-of-in-situ-light-absorption-and-attenuation-measurements-to-estimate-constituent-concentrations-in-optically-complex-shelf-seas"></a> Inversion of In Situ Light Absorption and Attenuation Measurements to Estimate Constituent Concentrations in Optically Complex Shelf Seas</h1>
<p>Packaging effect:</p>
<p>It is well known that the chlorophyll-specific phytoplankton absorption coefficient decreases with increasing Chl concentration due to the pigment packaging effect (Bricaud et al., 1995).</p>
<p>This paper suggest that ‘linear regression can be performed for the ranges of chlorophyll concentration values that are relevant for shelf seas as the effect of pigment packaging will be relatively limited for these values’</p>
<p>It just assumes that the <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>a</mi><mrow><mi>p</mi><mi>h</mi></mrow><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">a^*_{ph}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1079119999999998em;vertical-align:-0.4192159999999999em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">h</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4192159999999999em;"><span></span></span></span></span></span></span></span></span></span> is constant.</p>
<p>So it could fix the value…</p>
<p>But one thing for me is that may be I can try water classification.</p>
<p>There are a lot of things I think.</p>
<p>By now, especially before AWOC. I do not want to solving these problems.</p>
<h1 id="light-scattering-and-chlorophyll-concentration-in-case-1-waters-a-reexamination"><a class="markdownIt-Anchor" href="#light-scattering-and-chlorophyll-concentration-in-case-1-waters-a-reexamination"></a> Light scattering and chlorophyll concentration in case 1 waters: A reexamination</h1>
<h2 id="intro-and-mm"><a class="markdownIt-Anchor" href="#intro-and-mm"></a> Intro and MM</h2>
<p>This analysis, restricted to case 1 waters, aims at reassessing a previous nonlinear relationship established between the particle scattering coefficient, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">b_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> (very close<br>
to the particle attenuation coefficient, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">c_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>), and the chlorophyll concentration, [Chl]. This paper also suggested a modified criterion for turbid case 2 water.</p>
<p>In Gordon and Morel 1983,</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mi>p</mi></msub><mo stretchy="false">(</mo><mn>550</mn><mo stretchy="false">)</mo><mo>=</mo><mi>A</mi><mo stretchy="false">[</mo><mi>C</mi><mi>h</mi><mi>l</mi><msup><mo stretchy="false">]</mo><mn>0.62</mn></msup></mrow><annotation encoding="application/x-tex">b_{p}(550)=A[Chl]^{0.62}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">5</span><span class="mord">5</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord mathdefault">A</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">6</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>A, which is on average 0.30 within the upper oceanic layer, may vary between 0.12 and 0.45 to account for the lowest and highest particle scattering coefficients found at various depths in waters sat- isfying the criterion for belonging to case 1 waters</p>
<p>The importance of Gordon and Morel 1983 is the finding of this nolinear characteristics. But is lacks tightness expressed by the wide possible variation of A.</p>
<p>The Chl is measured by HPLC. The whole dataset has been seperated into several subsets for different purpose. For my research, I just need to focus on the surface, which is the <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>N</mi><mrow><mi>s</mi><mi>a</mi><mi>t</mi></mrow></msub><mi mathvariant="normal">/</mi><msub><mi>Z</mi><mn>90</mn></msub></mrow><annotation encoding="application/x-tex">N_{sat}/Z_{90}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">Z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">9</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<p>![image-00021130141721276](/Users/zhenjia/Library/Application Support/typora-user-images/image-00021130141721276.png)</p>
<p>The author also use Bricaud 1995 to model phytoplankton absorption in order to study the contribution of absorption to attenuation coefficient.</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mrow><mi>p</mi><mi>h</mi></mrow></msub><mo stretchy="false">(</mo><mn>660</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.012</mn><mo stretchy="false">[</mo><mi>C</mi><mi>h</mi><mi>l</mi><msup><mo stretchy="false">]</mo><mn>0.878</mn></msup></mrow><annotation encoding="application/x-tex">a_{ph}(660)=0.012[Chl]^{0.878}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span><span class="mord mathdefault mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">6</span><span class="mord">6</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord">2</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">8</span><span class="mord mtight">7</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>a</mi><mi>p</mi></msub><mo stretchy="false">(</mo><mn>660</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.014</mn><mo stretchy="false">[</mo><mi>C</mi><mi>h</mi><mi>l</mi><msup><mo stretchy="false">]</mo><mn>0.817</mn></msup></mrow><annotation encoding="application/x-tex">a_{p}(660)=0.014[Chl]^{0.817}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">6</span><span class="mord">6</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">1</span><span class="mord">4</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">8</span><span class="mord mtight">1</span><span class="mord mtight">7</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>But the coefficient of determination(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>r</mi><mn>2</mn></msup><mo>=</mo><mn>0.27</mn></mrow><annotation encoding="application/x-tex">r^2=0.27</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">7</span></span></span></span>) is relative low.</p>
<p>They found the contribution is negligible. <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">c_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> could be considered as same as <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>b</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">b_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></p>
<h2 id="result-and-discussion"><a class="markdownIt-Anchor" href="#result-and-discussion"></a> Result and discussion</h2>
<p>For the near surface layer,</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>p</mi></msub><mo stretchy="false">(</mo><mn>660</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0.347</mn><mo stretchy="false">[</mo><mi>C</mi><mi>h</mi><mi>l</mi><msup><mo stretchy="false">]</mo><mn>0.766</mn></msup><mo stretchy="false">(</mo><msup><mi>r</mi><mn>2</mn></msup><mo>=</mo><mn>0.89</mn><mo separator="true">,</mo><msub><mi>N</mi><mrow><mi>s</mi><mi>a</mi><mi>t</mi></mrow></msub><mo>=</mo><mn>435</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">c_{p}(660)=0.347[Chl]^{0.766}(r^2=0.89, N_{sat}=435)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">6</span><span class="mord">6</span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.1141079999999999em;vertical-align:-0.25em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">3</span><span class="mord">4</span><span class="mord">7</span><span class="mopen">[</span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mord mathdefault">h</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose"><span class="mclose">]</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span><span class="mord mtight">.</span><span class="mord mtight">7</span><span class="mord mtight">6</span><span class="mord mtight">6</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">8</span><span class="mord">9</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">4</span><span class="mord">3</span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span></p>
<h1 id="particulate-backscattering-ratio-at-leo-15-and-its-use-to-study-particle-composition-and-distribution"><a class="markdownIt-Anchor" href="#particulate-backscattering-ratio-at-leo-15-and-its-use-to-study-particle-composition-and-distribution"></a> Particulate backscattering ratio at LEO 15 and its use to study particle composition and distribution</h1>
<h2 id="intro"><a class="markdownIt-Anchor" href="#intro"></a> Intro</h2>
]]></content>
      <categories>
        <category>Annotated Bibliography</category>
      </categories>
      <tags>
        <tag>Research Basis</tag>
        <tag>Ocean Color</tag>
        <tag>Ocean Optics</tag>
        <tag>Inherent Optical Properties</tag>
      </tags>
  </entry>
  <entry>
    <title>Publishable plot using python&amp;R</title>
    <url>/posts/cd046c9b.html</url>
    <content><![CDATA[<p>这将会是一个长篇。</p>
<p>长到我也不知道要多久才能把他写完</p>
<p>天下人苦matplotlib已久</p>
<p>立个flag，这个月（2020年12月）结束它。</p>
<p>主要包括以下几个图的画法</p>
<ol>
<li>
<p>站位图</p>
</li>
<li>
<p>海洋环境要素分布图</p>
</li>
<li>
<p>散点图</p>
</li>
<li>
<p>密度散点图</p>
</li>
<li>
<p>Bar</p>
</li>
<li>
<p>带CI的Lineplot</p>
<p>其中第一个会用R，后面的因为我需要在处理数据的时候直接调用，所以是python。</p>
<p>不过第二个我也在考虑把结果输出到nc文件后，用R来画。</p>
<p>还有这个我就懒得用中文了，因为主要是给自己用的代码备忘录。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Research</tag>
        <tag>python</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>two r2</title>
    <url>/posts/e45539ea.html</url>
    <content><![CDATA[<p>本科毕设就没搞懂的两个r现在终于弄明白了</p>
<p>大部分内容来自于维基百科</p>
<a id="more"></a>
<h1 id="pearsons-r">Pearson's r</h1>
<p>在<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv57uf6K6h5a2m">统计学<i class="fa fa-external-link-alt"></i></span>中，<strong>皮尔逊积矩相关系数</strong>（英语：Pearson product-moment correlation coefficient，又称作 <strong>PPMCC</strong>或<strong>PCCs</strong>[<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55qu5bCU6YCK56ev55+p55u45YWz57O75pWwI2NpdGVfbm90ZS0x">1]<i class="fa fa-external-link-alt"></i></span>, 文章中常用r或Pearson's r表示）用于度量两个变量X和Y之间的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv55u45YWz">相关<i class="fa fa-external-link-alt"></i></span>程度（线性相关），其值介于-1与1之间。</p>
<h2 id="定义">定义</h2>
<p>两个变量之间的皮尔逊相关系数定义为两个变量的<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5Y2P5pa55beu">协方差<i class="fa fa-external-link-alt"></i></span>除以它们<span class="exturl" data-url="aHR0cHM6Ly96aC53aWtpcGVkaWEub3JnL3dpa2kv5qCH5YeG5beu">标准差<i class="fa fa-external-link-alt"></i></span>的乘积： <span class="math display">\[
\rho_{X,Y}=\frac{cov(X,Y)}{\sigma_X\sigma_Y}=\frac{E[(X-\mu_x)(Y-\mu_Y)]}{\sigma_{X}\sigma{Y}}
\]</span></p>
<p>这个是总体相关系数，对于我们抽样的样本，我们可以得到样本相关系数 <span class="math display">\[
r=\frac{\sum_{i=1}^{n}(X_i-X)}{}
\]</span></p>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Statistics</tag>
      </tags>
  </entry>
</search>
